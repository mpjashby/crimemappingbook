[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learn crime mapping with R",
    "section": "",
    "text": "Welcome!\nThis book will give you the knowledge and skills to effectively communicate information about crime and related topics using maps. We will cover the principles of analysing geographic information and the strengths and weaknesses of different maps for communicating it."
  },
  {
    "objectID": "index.html#who-is-this-book-for",
    "href": "index.html#who-is-this-book-for",
    "title": "Learn crime mapping with R",
    "section": "Who is this book for?",
    "text": "Who is this book for?\nThis book is for you if you are:\n\nSomeone who wants to learn how to understand patterns of crime using maps and related forms of data analysis.\nSomeone who already knows how to map crimes and would like to learn how to programme in a familiar context."
  },
  {
    "objectID": "index.html#why-use-this-book",
    "href": "index.html#why-use-this-book",
    "title": "Learn crime mapping with R",
    "section": "Why use this book?",
    "text": "Why use this book?\nThere are several books available for learning crime mapping. The advantages of using this book are that:\n\nIt teaches up-to-date crime mapping techniques. Some of the most-popular books on crime mapping were written over a decade ago and do not reflect substantial developments in the field since then.\nIt teaches crime mapping using exclusively free software (R and RStudio). Some other books teach crime mapping in expensive proprietary software that most people who need to make crime maps do not have access to.\nIt is an online book, so includes videos to introduce theoretical concepts and walk you through the process of creating different maps.\nIt uses examples from across the world, so it is not only useful to readers from one country.\nIt’s completely free to read and redistribute!"
  },
  {
    "objectID": "index.html#why-learn-crime-mapping-in-r",
    "href": "index.html#why-learn-crime-mapping-in-r",
    "title": "Learn crime mapping with R",
    "section": "Why learn crime mapping in R?",
    "text": "Why learn crime mapping in R?\nWe could make crime maps in several different apps. This includes commercial geographic information systems such as ArcGIS or MapInfo, free software such as QGIS, and data analysis programmes such as Tableau. So why learn crime mapping in a programming language like R?\nThere are several reasons:\n\nMaking maps using a programming language makes your work much more efficient, especially if (as is common in crime analysis) you need to produce similar maps periodically using updated data, or need to produce multiple similar maps for different areas or crime types.\nR is free. This can be important for people working in agencies with very limited budgets for software for data analysis.\nR has extensive mapping capabilities, supported by a large team of friendly experts who provide online support.\nR is good for other types of data analysis, so everything you learn here can be used for analysing crime data using techniques that are unrelated to maps.\n\nLearning a programming language like R involves a little extra work at the start, but this book is written to make this as easy as possibly by gently introducing you to programming ideas a little at a time. Once you’ve got started, you’ll find mapping crime in this way makes it much easier to advance further in the future."
  },
  {
    "objectID": "index.html#how-to-use-this-book",
    "href": "index.html#how-to-use-this-book",
    "title": "Learn crime mapping with R",
    "section": "How to use this book",
    "text": "How to use this book\nThere are two ways to use this book.\n\nYou can read it as you would any other technical how-to book, by reading through each chapter and working through each exercise in RStudio on your computer or online.\nYou can work through each chapter as an interactive tutorial in RStudio, getting immediate feedback on each exercise. The interactive tutorials also include quizzes to help you check your understanding.\n\nIf you want to use the interactive tutorials, there are a few extra set-up steps to work through at the bottom of this page. They will only take a few minutes.\nI recommend using the interactive tutorials if you can. The interactive tutorials are used for teaching crime mapping to BSc Crime and Security Science students at University College London so they have been tested by hundreds of people learning crime mapping before you."
  },
  {
    "objectID": "00_setup/index.html#step-1-install-r",
    "href": "00_setup/index.html#step-1-install-r",
    "title": "Install the software needed for this book",
    "section": "Step 1: install R",
    "text": "Step 1: install R\nThe first step is to download and install R, a programming language designed for analysing and visualising data, including making maps. To install R, visit the R website and download R for either Windows or Mac, depending on what type of computer you are using. If you already have R installed on your computer, please update it to the latest release.\nThis video talks you through the process of installing R:"
  },
  {
    "objectID": "00_setup/index.html#step-2-install-rstudio",
    "href": "00_setup/index.html#step-2-install-rstudio",
    "title": "Install the software needed for this book",
    "section": "Step 2: install RStudio",
    "text": "Step 2: install RStudio\nThe next step is to download RStudio, an app that you can use to work with the R programming language more efficiently. Download RStudio Desktop for your computer from the Posit website (that’s the company that makes RStudio) and install. If you already have RStudio Desktop installed on your machine, please update it to the latest release.\nThis video talks you through the process of installing RStudio:"
  },
  {
    "objectID": "00_setup/index.html#step-3-install-rtools-windows-only",
    "href": "00_setup/index.html#step-3-install-rtools-windows-only",
    "title": "Install the software needed for this book",
    "section": "Step 3: install RTools (Windows only)",
    "text": "Step 3: install RTools (Windows only)\nIf you are using a Windows computer you should install Rtools, which will be needed by RStudio for some tutorials. If you are using a Mac or Linux computer, you do not need to install Rtools.\nTo install RTools:\n\nDownload the latest version from the R website and open the downloaded file.\nFollow the installation instructions (accept all the default options).\nOpen RStudio.\nFind the panel (in the bottom-left) marked Console.\nFind the > symbol at the bottom of that panel.\nCopy and paste the following code to the right of the > symbol:\n\nwrite('PATH=\"${RTOOLS40_HOME}\\\\usr\\\\bin;${PATH}\"', file = \"~/.Renviron\", append = TRUE)\n\nPress Enter."
  },
  {
    "objectID": "00_setup/index.html#if-you-cannot-install-software-on-your-computer",
    "href": "00_setup/index.html#if-you-cannot-install-software-on-your-computer",
    "title": "Install the software needed for this book",
    "section": "If you cannot install software on your computer",
    "text": "If you cannot install software on your computer\nYou may not be able to install software on the computer you want to use for crime mapping, or you may prefer not to for various reasons. In that case, you can run RStudio online using Posit Cloud. Posit Cloud is free for a certain number of hours each month, after which you can pay to continue using it.\nUsing Posit Cloud allows you to avoid the installation steps for R, RStudio and RTools above, but remember that since Posit Cloud operates online, you should not use it work on confidential or personal data unless you have the necessary permission to do so."
  },
  {
    "objectID": "00_setup/index.html#running-the-interactive-tutorials",
    "href": "00_setup/index.html#running-the-interactive-tutorials",
    "title": "Install the software needed for this book",
    "section": "Running the interactive tutorials",
    "text": "Running the interactive tutorials\nIf you are going to use this book as you would any other technical how-to book, you can move ahead to the next chapter now. If you are going to use the interactive tutorials that accompany this book, there is one final step to set them up:\n\nOpen RStudio.\nFind the panel (in the bottom-left) marked Console.\nFind the > symbol at the bottom of that panel.\nCopy and paste the following code to the right of the > symbol:\n\nsource(\"https://github.com/mpjashby/crimemapping/raw/main/inst/initialise.R\")\n\nPress Enter.\n\n\nIt will take a few minutes for the tutorials to be set up. Once the process is complete you will see a message telling you this."
  },
  {
    "objectID": "01_getting_started/index.html#welcome-to-this-course",
    "href": "01_getting_started/index.html#welcome-to-this-course",
    "title": "1  Getting started",
    "section": "1.1 Welcome to this course",
    "text": "1.1 Welcome to this course\nWelcome to this course on crime mapping! This course uses interactive tutorials like this one to help you learn about using maps and spatial analysis techniques to understand crime. Watch this video to learn more about the course."
  },
  {
    "objectID": "01_getting_started/index.html#why-put-crimes-on-maps",
    "href": "01_getting_started/index.html#why-put-crimes-on-maps",
    "title": "1  Getting started",
    "section": "1.2 Why put crimes on maps?",
    "text": "1.2 Why put crimes on maps?\nThis course is about how we can use maps and other spatial analysis tools to help understand, prevent and respond to crime. Watch this video to understand why spatial analysis is a useful tool for understanding crime.\n\n\nWeisburd, D. (2015). The law of crime concentration and the criminology of place. Criminology, 53(2), 133-157.\nJohnson, S. (2010). A brief history of the analysis of crime concentration. European Journal of Applied Mathematics, 21(4-5), 349.\nFarrell, G. (2015). Crime concentration theory. Crime Prevention and Community Safety, 17(4), 233-248."
  },
  {
    "objectID": "01_getting_started/index.html#why-is-crime-concentrated-in-space",
    "href": "01_getting_started/index.html#why-is-crime-concentrated-in-space",
    "title": "1  Getting started",
    "section": "1.3 Why is crime concentrated in space?",
    "text": "1.3 Why is crime concentrated in space?\nWhy is crime concentrated in space? Watch this video to find out more about how our environment influences opportunities for crime and how that causes clusters of different crimes.\n\n\nSantos, R. B. (2015). Routine Activity Theory: A Cornerstone of Police Crime Analyst Work. In The Criminal Act:\nCohen, L. E., and Felson, M. (1979). Social Change and Crime Rate Trends: A Routine Activity Approach. American Sociological Review, 44(4), 588–608."
  },
  {
    "objectID": "01_getting_started/index.html#finding-your-way-around-rstudio",
    "href": "01_getting_started/index.html#finding-your-way-around-rstudio",
    "title": "1  Getting started",
    "section": "1.4 Finding your way around RStudio",
    "text": "1.4 Finding your way around RStudio\nWe will use RStudio for almost all of this course. Watch this video to find your way around the different panels in the RStudio window.\n\n\n1.4.1 Slightly adjusting how RStudio works\nBefore we start using RStudio, we should make a few changes to how it is set up that will make it easier to fix any mistakes we make while coding. To do this, click on the Tools menu in RStudio and then on Global Options…. In the dialogue box that opens, click on General in the left-hand panel if General is not selected already.\n\n\n\nIn the “Workspace” section of the right-hand panel, find an option that says “Restore .RData into workspace at startup” and make sure the check box to the left of that option is not checked. On the next line down, click the drop-down menu labelled “Save workspace to .RData on exit:” and choose the option Never. Click Apply and then OK to close the dialogue box.\n\nThe RStudio IDE Cheat Sheet highlights some of the features available in RStudio and gives a list of available keyboard short-cuts.\nWriting Code in RStudio is a webinar that talks you through RStudio in more detail."
  },
  {
    "objectID": "01_getting_started/index.html#navigating-these-tutorials",
    "href": "01_getting_started/index.html#navigating-these-tutorials",
    "title": "1  Getting started",
    "section": "1.5 Navigating these tutorials",
    "text": "1.5 Navigating these tutorials\nThe tutorials that make up this course include short chunks of R code that you can run directly in the tutorial window. To run the code in each chunk, just click the Run Code button in the top-right corner of each chunk. If you want to re-run a chunk of code, you can click the Start Over button in the top-left corner of each chunk. Some of the chunks will have pre-filled code for you to run, while for others you will be asked to type the code needed to complete a task based on what you have already learned.\nWhen you click Run Code, the output of the chunk will appear below it (there may be a delay of a few seconds for more-complicated chunks).\n\nSome of the tutorials include boxes like this one that contain information that it is particularly important for you to know to avoid common mistakes in writing code. Pay special attention to these points and remember to ask questions if anything isn’t clear.\n\n\n\nMore information you might like to know <- click here\n\n\nIn these tutorials you will also see lines marked ‘Extra detail’ that you can click on to find out more information about a particular issue. This is generally information that you do not need to know to complete the tutorial, but which might be useful in other circumstances or which might answer some questions that you have. You can skip these boxes if you want to, or come back to them later if you have a question."
  },
  {
    "objectID": "01_getting_started/index.html#in-summary",
    "href": "01_getting_started/index.html#in-summary",
    "title": "1  Getting started",
    "section": "1.6 In summary",
    "text": "1.6 In summary\nNow that you know why crime mapping is useful for understanding crime, why crime is typically concentrated in space and how to find your way around RStudio, in the next tutorial we will produce our first crime map in R.\nIf you’re not feeling too confident at this point in the course, don’t worry – learning something new is always a bit of a roller coaster and there is lots of help available in subsequent tutorials.\n\n\n\n\nStats Illustrations by Allison Horst licensed under the Creative Commons Attribution licence."
  },
  {
    "objectID": "02_your_first_crime_map/index.html#introduction",
    "href": "02_your_first_crime_map/index.html#introduction",
    "title": "2  Your first crime map",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nIn this tutorial we will use R to produce a simple crime map. To do this we will skip over lots of the detail of how R works and what choices we should make in creating maps. We will return to all these details in future sessions, so for-now please don’t worry about understanding every single line of code. Everything will become clear as we work through the tutorials in this course.\nThe map we’re going to create shows the locations of four homicides in downtown Atlanta in 2019:\n\nTo start off with, watch this video that walks through the code needed to make this map. Don’t worry if there are things in the video that you don’t understand – the rest of this tutorial will explain each line of code in turn.\n\n\n2.1.1 Running code in the interactive tutorials\nIn the video above you saw code being run in RStudio, but to save switching between the interactive tutorials and the RStudio console, the the tutorials includes short chunks of R code that you can run directly in this window. We will use these chunks of code to walk through the code we need to produce a map. To run the code in each chunk, just click the Run Code button in the top-right corner of each chunk. If you want to re-run a chunk of code, you can click the Start Over button in the top-left corner of each chunk.\nWhen you click Run Code, the output of the chunk will appear below it (there may be a delay of a few seconds for more-complicated chunks)."
  },
  {
    "objectID": "02_your_first_crime_map/index.html#loading-crime-data",
    "href": "02_your_first_crime_map/index.html#loading-crime-data",
    "title": "2  Your first crime map",
    "section": "2.2 Loading crime data",
    "text": "2.2 Loading crime data\n\n2.2.1 Loading packages\nBefore we can work with our data, we first load packages of functions for use in the analysis. To load these packages, click Run Code. This will produce various messages, all of which you can safely ignore for now.\n# Load the R packages we need to analyse this data\nlibrary(ggspatial)\nlibrary(sf)\nlibrary(tidyverse)\n\n\nWhat do these messages mean?\n\n\nFor now you don’t need to worry about these messages, but if you really want to know what they mean …\n\n\n\n\nSome R packages make use of other apps and utilities on your computer. For example, the sf package makes use of a piece of software call GDAL that is used for managing spatial data. So that you know which version of GDAL is being used, sf prints a message telling you.\nThe tidyverse package itself loads several packages that are commonly used together for analysing data. When you load tidyverse, it will print a message telling you which packages it has loaded, along with the version number for each package. It also prints a message saying if any functions from the tidyverse packages have replaced (“masked”) any functions from packages that were previously loaded.\nIn general, R packages use start-up messages to remind you of information that is not likely to be critical to your work, but which it might be useful to know at some point in the future.\n\n\n\n\n\n2.2.2 Loading data\nThe first task in creating any crime map is to obtain the crime and other data necessary. In many cases preparing the data for analysis and mapping will be a substantial task, but in this case we are going to use some pre-prepared crime data together with a pre-drawn street map (which we will ask R to download automatically when it draws the final map).\nThe data we will use will be records of homicides in the Downtown neighbourhood of Atlanta, Georgia, in 2019. We can load the homicide data using the read_csv() function.\n# Download the data directly from a URL and store it as an object\nhomicides <- read_csv(\"https://github.com/mpjashby/crimemapping/raw/main/inst/extdata/downtown_homicides.csv\")\nThe read_csv() function loads data from a file and prints a message showing the name of each column in the data and the type of data (number, text etc.) in each column. Again, you can ignore this message for now.\nWe have stored the results of the read_csv() function in an R object called homicides. An object in R is anything that stores any type of data. There are many types of objects, but for this tutorial we don’t need to explore these in any more detail. All you need to remember for now is that objects store data and functions do things.\n\n\n2.2.3 Viewing the data\nTo check the data has been loaded correctly, we can view the loaded data using the head() function. By default, head() prints the first six rows of the data stored in an object.\n# Display the data\nhead(homicides)\nThe data contain four columns: a unique identifier for a homicide, a label describing when and where that homicide occurred, and the longitude and latitude of the homicide location. Depending on the width of your screen, you may need to click on the ‘▸’ symbol to view all the columns in the data. We can use this data to plot the homicides on a map.\n\nIn the code head(homicides), there are no quote marks around the word homicides.\nAlmost all programming languages will interpret words differently depending on whether they have quotes around them or not. In this case, if you type the code head(homicides) then R will print the first few rows of the data stored in the homicides object.\nOn the other hand, if you type the code head(\"homicides\") or head('homicides'), R will interpret this as an instruction to print the first few elements of the literal text ‘homicides’. Since the text ‘homicides’ contains only one element (more about that later), head(\"homicides\") will just print the word ‘homicides’."
  },
  {
    "objectID": "02_your_first_crime_map/index.html#processing-the-data",
    "href": "02_your_first_crime_map/index.html#processing-the-data",
    "title": "2  Your first crime map",
    "section": "2.3 Processing the data",
    "text": "2.3 Processing the data\nBefore we can plot the data on a map, we have to complete some pre-processing steps. Having to process data before being able to analyse or visualise it is common in all types of data analysis, but spatial analysis often involves additional processing that takes account of the special features of spatial data.\n\n2.3.1 Converting the data into a spatial format\nTwo data-processing tasks are needed to produce this map. The first is to convert the data into a simple features or SF object, which is a special type of R object that can be used by functions that process spatial data. We will cover the details of the st_as_sf() function that converts our data into into an SF object later on. Click Run Code to convert the data into SF format.\n# Convert the data to a simple features object, which we can use in functions \n# that work on spatial data\nhomicides_sf <- st_as_sf(\n  homicides, \n  coords = c(\"longitude\", \"latitude\"), \n  crs = \"EPSG:4326\"\n)\nWhen you ran the code above, it looked like nothing happened. This is because the results of the code are stored in the homicides_sf object. Do you remember what R code to use to view the first few rows of this object?\n\nIf you cannot remember how to view the contents of an object, you can click on the Solution button to get help.\nAs you go through these tutorials, try to avoid using the Solution button unless you have tried to input the correct code yourself. You will learn much more if you try to work out the answer by referring back to an earlier page in the tutorial or to your own notes.\nDon’t worry about getting the answer wrong – nothing bad will happen if you run the wrong code in this tutorial and you can have as many attempts as you like to get the answer right.\n\n# To view an object in R, use the `head()` function. To view the contents of the\n# homicides object, copy the next line into the box below and click Run Code.\nhead(homicides_sf)\nThe data looks identical to before running the function st_as_sf(), except that the two columns called longitude and latitude have disappeared and there is now an extra column called geometry. The geometry column is important because lots of functions in R can recognise that the geometry column represents a location on the surface of the earth that can be used to analyse and map data in space.\n\n\n2.3.2 Changing the data projection\nThe geometry column in the homicides_sf object represents locations on the surface of the earth using co-ordinates (pairs of numbers). In this case, the co-ordinates are expressed as longitudes and latitudes, but there are lots of other types of co-ordinates (known as co-ordinate reference systems).\nWe’ll learn more about co-ordinate reference systems in a future tutorial, but for now it’s enough to know that each different system has advantages and disadvantages. To make the homicide locations easier to add to a map, we are going to first transform the co-ordinates from longitudes and latitudes to a co-ordinate reference system that is specifically designed for mapping data for the US state of Georgia.\nTo do this, we will use the st_transform() function, together with a code representing the co-ordinate reference system we want to use (you don’t need to understand this code at this stage).\nhomicides_sf_trans <- st_transform(homicides_sf, \"EPSG:26967\")\n\nhead(homicides_sf_trans)\nAgain, the data looks almost identical, except that the values in the geometry column have changed (you don’t need to understand yet the details of how these numbers are different). Now that we’ve completed the data processing, we can go on to produce the map itself."
  },
  {
    "objectID": "02_your_first_crime_map/index.html#draw-the-map",
    "href": "02_your_first_crime_map/index.html#draw-the-map",
    "title": "2  Your first crime map",
    "section": "2.4 Draw the map",
    "text": "2.4 Draw the map\nWe are now ready to produce our map of homicides in downtown Atlanta. So that people viewing the map will understand where the homicides occurred, we will plot the homicides on top of a base layer showing streets, parks and other geographic features obtained from an online web mapping service. Click Run Code to create the map.\nggplot(homicides_sf_trans) + \n  annotation_map_tile(type = \"osm\", zoom = 15) + \n  geom_sf_label(\n    aes(label = label), \n    lineheight = 1, \n    size = 2.5, \n    hjust = 1, \n    vjust = 0\n  ) + \n  geom_sf(colour = \"white\", fill = \"orangered1\", size = 4, shape = 21) + \n  scale_x_continuous(expand = expansion(mult = 0.5)) + \n  scale_y_continuous(expand = expansion(mult = 0.2)) + \n  labs(\n    title = \"Homicides in Downtown Atlanta, 2019\",\n    caption = \"Background map by OpenStreetMap\"\n  ) +\n  theme_void()\nYou can change the appearance of the map by changing various parts of the code above and clicking Run Code again. For example, you can change the colour of the points that mark the homicides by changing the code fill = \"orangered1\" to fill = \"mediumblue\", or change the base map to a different style by changing the code type = \"osm\" to type = \"cartolight\". Each time you change part of the code, click Run Code to see what changes on the map."
  },
  {
    "objectID": "02_your_first_crime_map/index.html#putting-the-code-together",
    "href": "02_your_first_crime_map/index.html#putting-the-code-together",
    "title": "2  Your first crime map",
    "section": "2.5 Putting the code together",
    "text": "2.5 Putting the code together\nNow we have walked through the different parts of the code, we can create a map from scratch in a single block of code. In this example, we will map homicides from in Glenrose Heights neighbourhood of Atlanta, and a different style of base map. Since the area covered by the map is derived from the data itself, the extent of the map will update automatically.\n# Load the R packages we need to analyse this data\nlibrary(ggspatial)\nlibrary(sf)\nlibrary(tidyverse)\n\n# Download the data directly from a URL and store it as an object\nhomicides <- read_csv(\"https://github.com/mpjashby/crimemapping/raw/main/inst/extdata/glenrose_heights_homicides.csv\")\n\n# Convert the data to a simple features object, which we can use in functions \n# that work on spatial data\nhomicides_sf <- st_as_sf(\n  homicides, \n  coords = c(\"longitude\", \"latitude\"), \n  crs = \"EPSG:4326\"\n)\n\n# Transform the data to a co-ordinate reference system for the state of Georgia\nhomicides_sf_trans <- st_transform(homicides_sf, \"EPSG:26967\")\n\n# Plot the map\nggplot(homicides_sf_trans) + \n  annotation_map_tile(type = \"osm\", zoom = 15) + \n  geom_sf_label(\n    aes(label = label), \n    lineheight = 1, \n    size = 2.5, \n    hjust = 1, \n    vjust = 0\n  ) + \n  geom_sf(colour = \"white\", fill = \"mediumblue\", size = 4, shape = 21) + \n  scale_x_continuous(expand = expansion(mult = 1.5)) + \n  scale_y_continuous(expand = expansion(mult = 0.2)) + \n  labs(\n    title = \"Homicides in Glenrose Heights, 2019\",\n    caption = \"Background map by OpenStreetMap\"\n  ) +\n  theme_void()"
  },
  {
    "objectID": "02_your_first_crime_map/index.html#in-summary",
    "href": "02_your_first_crime_map/index.html#in-summary",
    "title": "2  Your first crime map",
    "section": "2.6 In summary",
    "text": "2.6 In summary\n\nWell done – you have finished your first mapping tutorial. You may not have understood every line of code in this tutorial, but we will cover them all in more detail over the rest of this course. By the end of the tutorials, you will be able to write code like this to create many different types of crime map.\n\nIn this tutorial you have learned how to load data into R, prepare it for use in making a map and then used it to make your first crime map of this course.\nThe map we have produced in this tutorial is effective for showing the locations of just a few crimes, but is too limited to show more complicated patterns or larger datasets. In the following tutorials, we will learn how to produce more sophisticated maps and spatial analysis. We will also learn how each of the functions that we have used in this tutorial work."
  },
  {
    "objectID": "03_data_wrangling/index.html#introduction",
    "href": "03_data_wrangling/index.html#introduction",
    "title": "3  Wrangling data",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\nA major step in using any data to make decisions or draw conclusions is data wrangling: the process of transforming data from the format in which we originally have it to the format needed to analyse and present it to our audience.\n\n\n\nStart off by watching this video that walks through the different steps in wrangling a dataset. We will cover all the steps in the video in more detail during the rest of this tutorial.\n\n\n3.1.1 Functions\nIn this tutorial we will learn how to wrangle data in R using functions – specialised pieces of code that do something to the data we give it. The code to use a function (sometimes called calling the function) has two parts: the function name followed by a pair of parentheses, inside which are zero or more arguments separated by commas. Arguments are a way of providing input that a function works on, or to fine-tune the way the function works (we will see many examples of this later). Remember that you can identify a function in R because the name will always have parentheses after it.\nOne basic R function is sqrt(), which calculates the square root of a number. The sqrt() function has only one argument: the number that we want to find the square root of.\nsqrt(2)\nWhen you run code in R, by default R prints the output of your code – in this case, just the number 1.414214.\n\n\n3.1.2 Packages\n\n\n\nR contains thousands of different functions that do different things. A few functions are contained in the default installation of R that you have already installed (this is sometimes referred to as base R). But most functions are contained in packages, which are extensions to base R. Most packages focus on a particular type of data analysis, so that there are packages devoted to time-series analysis, testing whether events are clustered in particular places, network analysis and thousands of other tasks. Packages are often developed by experts in the field, and are typically updated to introduce new features.\nTo use a package in R, we must do two things:\n\ninstall the package, which we have to do just once on each computer we want to use, then\nload the package, which we have to do each time we restart R (which happens when we open RStudio or switch between projects).\n\nThe install.packages() function downloads and installs packages from the Comprehensive R Archive Network (universally known as CRAN), which contains about 19,100 different packages. Some packages that are still in the early stages of development are not available on CRAN, but all the packages we will use are there.\n\nSo to install (for example) the package called tidyverse, which we will use extensively in this tutorial, we would run the R code:\ninstall.packages(\"tidyverse\")\nWe only have to install a package once for each computer that we will use to run R, although we would have to do it again if we updated to a new version of R. Once a package is installed on our computer, we have to load it so that we can use it in our code. We load packages using the library() function, which should probably have been called load_package() but isn’t. So to load the tidyverse package, we run the code:\nlibrary(tidyverse)\nMany packages are focused on specialist tasks and so are only used occasionally, but a few packages are likely to be useful in almost all the code we write. Fortunately, packages can themselves load other packages, and all the main packages we need are themselves loaded by the tidyverse package. That is why you will often see library(tidyverse) at the top of R code in subsequent tutorials – that short line of code loads several packages containing hundreds of functions that we can use in data analysis.\n\nStats Illustrations by Allison Horst licensed under the Creative Commons Attribution licence."
  },
  {
    "objectID": "03_data_wrangling/index.html#loading-data",
    "href": "03_data_wrangling/index.html#loading-data",
    "title": "3  Wrangling data",
    "section": "3.2 Loading data",
    "text": "3.2 Loading data\nBefore we can do anything with any data, we have to load it into R. In this course we will read tabular data in comma-separated values (CSV) and Excel formats, as well as spatial data in different formats (because there are lots of ways to store spatial data). We will learn how to read CSV and Excel data now, but leave loading spatial data until later.\nTabular data contains multiple columns where every column has the same number of rows. For example, crime data might have columns for the type of crime, date and address at which the crime occurred.\n\n\n\nCrime data in rectangular format\n\n\ntype\ndate\naddress\n\n\n\n\nhomicide\n31 Jan 2022\n274 Main St\n\n\nnon-residential burglary\n10 Sep 2022\n541 Station Rd\n\n\npersonal robbery\n13 Jan 2023\n10 North Av\n\n\n\n\n\n\n3.2.1 Loading CSV data\n\nData stored in CSV format is easy to load with the read_csv() function from the readr package. readr is one of the packages loaded by the tidyverse package, so all we need to do to use this package is include the code library(tidyverse) on the first line of our R script. We will use comments (lines of code beginning with #) to help explain as we go.\n# Load the tidyverse suite of packages, including the readr package \n# that contains the read_csv() function\nlibrary(tidyverse)\n\n# We can load data from a file in the same folder as our R script\nsan_fran_rob <- read_csv(\"san_francisco_robbery.csv\")\n\n# Or another folder on your computer ('../' is short for the parent \n# folder of the current folder)\nsan_fran_rob <- read_csv(\"../san_francisco_robbery.csv\")\n\n# Or directly from a file online\nsan_fran_rob <- read_csv(\"http://example.com/san_francisco_robbery.csv\")\nIn each of these examples, the code stores the result of the read_csv() function in an object named san_fran_rob. Objects are places where we can store data. To create an object and store our data in it, we use the assignment operator <- (a less-than sign followed by a dash). Continually typing <- can be tedious, so in RStudio we can use the keyboard short cut Option+- (on Mac) or Alt+- (on Windows or Linux) to insert the complete operator.\n\nWhen choosing object names, it is important to remember that if you assign a value (such as the number 1 or the result of the function read_csv()) to an object name, R will overwrite any existing value of that object name. We can see this in a simple example:\none_to_ten <- 1:10\none_to_ten <- sqrt(2)\nIf we were to run this code, the object one_to_ten would not actually hold the numbers from one to ten, but instead the value 1.414214 (the square root of two). There is also no way to undo assignment of a value to an object, so once you have run the code one_to_ten <- sqrt(2) it is not possible to recover any previous value that was assigned to the object one_to_ten.\n\nObjects come in several different types, with tabular data typically being stored as a data frame. The read_csv() function actually produces a modern variation on the data frame called (slightly strangely) a tibble, which makes use of some advances in how R handles data since the data-frame format was set 20 years ago. Tibbles behave just like data frames almost all of the time (so much so that people working with tibbles often call them data frames) except for a few occasions where they behave in a more-convenient way.\nWe can read_csv() to load data from https://github.com/mpjashby/crimemapping/raw/main/inst/extdata/san_francisco_robbery.csv and store it in an object called san_fran_rob.\nsan_fran_rob <- read_csv(\"https://github.com/mpjashby/crimemapping/raw/main/inst/extdata/san_francisco_robbery.csv\")\nIf the data are loaded successfully, R will list the columns in the data and the type of variable (numeric, date etc.) stored in each column. The format of this is somewhat esoteric, but if you are interested they are explained in the ‘Extra detail’ box below.\n\n\nWhat do the messages produced by read_csv() mean?\n\n\nBy default, the read_csv() function prints a message when it loads data to summarise the format of each data column. In the case of the san_fran_rob dataset, read_csv() tells us that:\n\nthere is one column called offense_type that contains character (chr) values,\nthere are three columns called uid, longitude and latitude containing numeric (dbl) values, and\nthere is one column called date_time that contains values stored as dates and times (dttm).\n\nThere are some other possible types of data, but we will learn about these later on. The numeric values are referred to as dbl values because they are stored in a format that can handle numbers that are not whole numbers (e.g. 123.456). This format for storing numbers is called the double-precision floating-point format, which is often known as the double format for short. Most numbers in R are stored in double format, so you can think of the format code dbl as meaning ‘numeric’.\n\n\n\nTo see the first few rows of data currently stored in an object, we can use the head() function.\nhead(san_fran_rob)\n\n\n3.2.2 Loading Excel data\n\nLoading data from Microsoft Excel files is very similar to loading CSV data, with a few important differences. Functions to load Excel data are contained in the readxl package, which was installed automatically when we installed the tidyverse package.\nThere are two main things we must do to import Excel data that are not required for importing CSV data. The first is that the readxl package cannot directly load files from a URL, instead only loading files that are present on your computer. To get round this, we will first download an Excel file and store it in a temporary directory (to avoid cluttering up our computers).\n\nUsing download.file() on Windows\nIf you are using a Windows computer, you may find that the download.file() function in the code below does not work as expected. This is because Windows handles files in a way that distinguishes between plain-text files such as .txt and .csv files and binary files, which includes most other file types (including compressed files). Since aggravated_assaults.xlsx is not a plain-text file, on Windows you need to specify that you want it to be downloaded as a binary file. To do this, add the argument mode = \"wb\" to the download.file() function so that it reads:\ndownload.file(\n  url = \"https://github.com/mpjashby/crimemapping/raw/main/inst/extdata/aggravated_assaults.xlsx\",\n  destfile = temp_file,\n  mode = \"wb\"\n)\nIf you are using a Mac or a Linux computer then you do not need to worry about this.\n\n# Specify the name of and location of our temporary file: it does not matter\n# what this file is called or where it is stored, so we use the tempfile()\n# function to create a file in the correct location automatically\ntemp_file <- tempfile(fileext = \".xlsx\")\n\n# Download the Excel file and store it in the temporary location\ndownload.file(\n  url = \"https://github.com/mpjashby/crimemapping/raw/main/inst/extdata/aggravated_assaults.xlsx\",\n  destfile = temp_file,\n  mode = \"wb\"\n)\nThe download.file() function does not produce any output if the file has been successfully downloaded, so you will not see any output when you run this code.\nNow we have downloaded our data, we can load it into R. Since Excel files can contain multiple sheets, we need to specify which sheet we would like to load into a tibble. We can use the excel_sheets() function to get a list of sheets in an Excel file:\n# Load the readxl package\nlibrary(readxl)\n\n# Get a list of sheets in an Excel file\nexcel_sheets(temp_file)\nWe can now load the sheet containing data for Austin and view the first few rows of the resulting object:\nagg_assault_data <- read_excel(temp_file, sheet = \"Austin\")\n\nhead(agg_assault_data)\nNow we have learned how to load our data into an object, we can use other R functions to work with that data in many different ways.\n\nLearn more about how to read data into R by reading this chapter of the free online book R for Data Science.\nExcel data can often be messy and the readxl package contains various other functions that can be used to deal with this. You can learn more about how to handle messy Excel data in this online tutorial."
  },
  {
    "objectID": "03_data_wrangling/index.html#selecting-columns",
    "href": "03_data_wrangling/index.html#selecting-columns",
    "title": "3  Wrangling data",
    "section": "3.3 Selecting columns",
    "text": "3.3 Selecting columns\nIn this section we will learn how to reduce the size of our data by selecting only the columns we need and discarding the rest. This can be particularly useful if we are working with a very-large dataset, or if we want to produce a table containing only some columns.\n\n\n\nWe can use the select() function from the dplyr package (one of the packages that is loaded automatically when we call the library(tidyverse) function) to select columns.\nIf we wanted to select just the date and location_type columns from the agg_assault_data we loaded in the previous section:\nselect(agg_assault_data, date, location_type)\n\nIn a previous section, we mentioned that the code needed to run (or call) a function in R has two parts: the function name followed by a pair of parentheses, inside which are zero or more arguments separated by commas. The arguments in the select() function (and many other functions in the dplyr package) work in a slightly different way to many other functions. Here, the first argument is the name of the data object that we want to select from. All the remaining arguments (here, date and location_type) are the names of the columns we want to select from the data.\nWe can select as many columns as we want, by just adding the names of the columns separated by commas. Write the code necessary to select the longitude and latitude columns from the agg_assault_data object:\nselect(agg_assault_data, longitude, latitude)\nThe columns in our new dataset will appear in the order in which we specify them in the select() function.\nWe can also use select() to rename columns at the same time as selecting them. For example, to select the columns date and location_type while also renaming location_type to be called type:\nselect(agg_assault_data, date, type = location_type)\nIf we want to rename a column while keeping all the columns in the data, we can instead use the rename() function (also from the dplyr package):\nrename(agg_assault_data, type = location_type)\nRemember that functions in R generally do not change existing objects, but instead produce (or return) new ones. This means if we want to store the result of this function so we can use it later, we have to assign the value returned by the function to a new object (or overwrite the existing object):\nagg_assault_locations <- select(agg_assault_data, lon = longitude, lat = latitude)\n\nhead(agg_assault_locations)\n\nYou can learn more about selecting, filtering and arranging data using the functions in the dplyr package by reading this Introduction to dplyr tutorial."
  },
  {
    "objectID": "03_data_wrangling/index.html#filtering-rows",
    "href": "03_data_wrangling/index.html#filtering-rows",
    "title": "3  Wrangling data",
    "section": "3.4 Filtering rows",
    "text": "3.4 Filtering rows\nOften in crime mapping we will only be interested in part of a particular dataset. In the same way that we can select particular columns in our data, we can filter particular rows using the filter() function from the dplyr package.\n\n\n\nIf we were only interested in offences in the agg_assault_data dataset that occurred in residences, we could use filter():\nfilter(agg_assault_data, location_type == \"residence\")\nNote that:\n\nthe column name location_type is not surrounded by quotes but the column value \"residence\" is, and\nthe == (equal to) operator is used, since a single equals sign = has another meaning in R.\n\nWe can filter using the values of more than one column simultaneously. To filter offences in which the location_category is ‘leisure’ and the location_type is ‘bar/club’:\nfilter(\n  agg_assault_data, \n  location_category == \"leisure\", \n  location_type == \"bar/club\"\n)\nAs well as filtering using the == operator, we can filter using the greater-than (>), less-than (<), greater-than-or-equal-to (>=) and less-than-or-equal-to (<=) operators. For example, we can choose offences that occurred in residences on or after 1 July 2019:\nfilter(\n  agg_assault_data, \n  location_type == \"residence\", \n  date >= as.Date(\"2019-07-01\")\n)\nSometimes we will want to filter rows that are one thing or another. We can do this with the | (or) operator. For example, we can filter offences that occurred either in leisure facilities or shopping malls on or after 1 July 2019:\nfilter(\n  agg_assault_data, \n  location_category == \"leisure\" | location_type == \"mall\", \n  date >= as.Date(\"2019-07-01\")\n)\nIf we want to filter offences that have any one of several different values of the same column, we can use the %in% (in) operator. To filter offences that occurred in either streets or publicly accessible open spaces:\nfilter(agg_assault_data, location_category %in% c(\"open space\", \"street\"))\nThe code c(\"open space\", \"street\") produces what is referred to in R as a vector (sometimes referred to as an atomic vector, especially in error messages). A vector is a one-dimensional sequence of values of the same type (i.e. all numbers, all character strings etc.). For example, a vector might hold several strings of text (as in the vector c(\"open space\", \"street\")) or a series of numbers such as c(1, 2, 3). There is lots we could learn about vectors, but for now it’s only necessary to know that we can create vectors with the c() or combine function.\nIf we wanted to re-use a vector of values several times in our code, it might make sense to store the vector as an object. For example:\n# Create vector of location types we are interested in\nlocation_types <- c(\"open space\", \"street\")\n\n# Filter the data\nfilter(agg_assault_data, location_category %in% location_types)\nFinally, you can filter based on the output of any R function that returns TRUE or FALSE. For example, missing values are represented in R as NA. We can test whether a value is missing using the is.na() function. If we wanted to remove rows from our data that had missing location types, we would filter for those rows that are not NA. We can do this by combining the is.na() function with the ! (not) operator:\nfilter(agg_assault_data, !is.na(location_type))\nWe will see lots more examples of how to use filter() in future tutorials.\n\nStats Illustrations by Allison Horst licensed under the Creative Commons Attribution licence."
  },
  {
    "objectID": "03_data_wrangling/index.html#transforming-values",
    "href": "03_data_wrangling/index.html#transforming-values",
    "title": "3  Wrangling data",
    "section": "3.5 Transforming values",
    "text": "3.5 Transforming values\nIt is often useful to create new columns in our data, or change the values of existing columns. The mutate() function in the dplyr package gives us a way to transform existing columns in our dataset using almost any R function.\n\n\n\n\nFor example, say we wanted to create a new column in our aggravated-assault dataset specifying the day of the week on which each crime occurred. We can do this using the wday() function from the lubridate package (using the label = TRUE argument to produce weekday names, rather than numbers):\nlibrary(lubridate)\n\nmutate(agg_assault_data, weekday = wday(date, label = TRUE))\nDepending on the width of your screen, you might need to click the ▸ button to see the new variable.\nWe can also categorise an existing variable, for example creating a variable to show whether an offence occurred in the northern or southern half of the city:\nmutate(\n  agg_assault_data, \n  region = if_else(latitude > median(latitude), \"northern\", \"southern\")\n)\nWe can change existing columns, although (as with objects) there is no way to undo this so you should only replace columns if you are sure you will not need them. For example, if we wanted to remove the time portion of the date variable (which may sometimes be useful, as shown in the next section) using the as_date() function (also from the lubridate package) and at the same time create the weekday variable:\nmutate(\n  agg_assault_data, \n  date = as_date(date),\n  weekday = wday(date, label = TRUE)\n)\nYou may sometimes want to change only some values in a column. We can do this in various ways, depending on which values we want to change:\nmutate(\n  agg_assault_data,\n  # Change a single value with a new value (and otherwise keep the existing \n  # value) using the if_else() function\n  location_type = if_else(location_type == \"street\", \"road\", location_type),\n  # Change multiple values in a categorical variable using the recode() \n  # function, in which values are changed using arguments in the format\n  # old_value = new_value\n  location_category = recode(\n    location_category, \n    \"open space\" = \"public open space\",\n    \"street\" = \"street or road\"\n  )\n)\nWe could also make changes based on more-complicated sets of criteria using the case_when() function, but we will return to that in a future tutorial.\nThe R functions that you use inside mutate() must return the same number of values as there are rows in the dataset. This is true for most R functions (which are referred to as vectorised functions), but there are some – such as mean() and max() – that return a single value. These summarising functions cannot be used inside mutate() (you will see an error message if you try) but are instead used with the next data-wrangling function we will learn about: summarise().\n\nStats Illustrations by Allison Horst licensed under the Creative Commons Attribution licence."
  },
  {
    "objectID": "03_data_wrangling/index.html#summarising-rows",
    "href": "03_data_wrangling/index.html#summarising-rows",
    "title": "3  Wrangling data",
    "section": "3.6 Summarising rows",
    "text": "3.6 Summarising rows\nSummarising data is often useful in crime analysis. We can use the summarise() function from the dplyr package to produce summaries of different columns in our data. There is an identical function called summarize() so that you do not have to remember whether to use the US or British spelling.\nBy default, summarise() collapses data into a single row, with each column summarised using a function that you specify. For example, suppose you want to find out which police station a specialist squad should be based at to most easily respond to reports of serious assaults. You might do this by working out the weighted centre of all the offence locations, i.e. the means of the longitudes and latitudes for all the crimes. You could then base the squad at the police station that was closest to the weighted centre.\nsummarise(\n  agg_assault_data, \n  mean_lng = mean(longitude, na.rm = TRUE),\n  mean_lat = mean(latitude, na.rm = TRUE)\n)\n\n\nWhat does the argument na.rm = TRUE do?\n\n\nLots of functions in R have an argument called na.rm that can be set to either TRUE or FALSE. Setting na.rm = TRUE in this case specifies that the mean() function should remove (rm) any missing (NA) values before calculating the mean.\nIf we do not specify this and our data contain any missing values, the mean() function will return NA. Functions in R do this because it is not possible to completely answer the question ‘what is the mean of these values?’ if some of the values are missing.\nThis logic applies in lots of cases. For example, if you create an R object called value with the code value <- 2 and then run the R code value > 1, you will get the answer TRUE. But if you set the object value to be NA using the code value <- NA, when you run the R code value > 1 you will get the answer NA. This is because there is no way to know if the missing value represented by NA is greater than 1 or not. This is why it is often useful to calculate statistics such as a mean value after removing any missing values using the na.rm = TRUE argument.\n\n\n\nsummarise() becomes more useful if we first divide our data into groups, since we then get a summary for each group separately. We can use the group_by() function to specify which columns denote which group each row is in. So if we wanted to repeat the calculation above, but separately for each value of location_category:\nsummarise(\n  group_by(agg_assault_data, location_category),\n  mean_lng = mean(longitude, na.rm = TRUE),\n  mean_lat = mean(latitude, na.rm = TRUE)\n)\nThis code might be slightly difficult to read, since the group_by() function is called inside summarise(), but we will learn a way of writing this code that might be easier to read in the final section of this tutorial.\nYou can add multiple grouping variables if you want to generate summary values for groups within groups:\nsummarise(\n  group_by(agg_assault_data, location_category, location_type),\n  mean_lng = mean(longitude, na.rm = TRUE),\n  mean_lat = mean(latitude, na.rm = TRUE)\n)\n\n\nDid you see a message saying `summarise()` has grouped output by 'location_category'?\n\n\nYou might have noticed the that code above produced a message specifying how groups have been handled by summarise(). This message reminds you that by default the summarise() functions strips the final level of grouping added by group_by(). This allows us to summarise data using a detailed set of groups and then summarise those summaries using more-general groups. In practice, this ability has been a source of some confusion, so R now prints a message to remind you that the data are still grouped after you run summarise(). If you want to hide this message then you can add .groups = \"drop\" to the summarise() function to remove all the groups in the data.\n\n\n\n\n3.6.1 Counting rows\nOne form of summarising grouped data is so common that it gets its own function: count(). This simply counts the number of rows of data in each group. So if you wanted to know how many aggravated assaults had occurred in each location category and type:\ncount(group_by(agg_assault_data, location_category, location_type), sort = TRUE)\nThe sort = TRUE argument sorts the counts in descending order. You can do more-sophisticated sorting using the arrange() function, which we will learn about in the next section."
  },
  {
    "objectID": "03_data_wrangling/index.html#arranging-rows",
    "href": "03_data_wrangling/index.html#arranging-rows",
    "title": "3  Wrangling data",
    "section": "3.7 Arranging rows",
    "text": "3.7 Arranging rows\nIt is sometimes useful to be able to place rows in a dataset into a particular order. We can do this using the arrange() function from the dplyr package. For example, we can sort the aggravated-assault data by date:\narrange(agg_assault_data, date)\nBy default, arrange() sorts rows in ascending order, i.e. it sorts numeric values from the smallest to the largest, dates from earliest to latest and character values alphabetically. We can instead sort values in descending order by wrapping the name of a column in the desc() function:\narrange(agg_assault_data, desc(date))\nWe can also sort the data based on multiple columns – the data are sorted first on the first column that you specify, with tied rows then sorted on the subsequent columns in order.\narrange(agg_assault_data, date, desc(location_type), location_category)\n\n3.7.1 Check your understanding\nType the code necessary to arrange agg_assault_data in order of latitude, in descending order (from largest to smallest)\nRun your code using the Run Code button, then (if necessary) correct your code and run it again. Once you are happy that your code does what it is intended to do, click the Solution button to check.\narrange(agg_assault_data, desc(latitude))"
  },
  {
    "objectID": "03_data_wrangling/index.html#saving-data",
    "href": "03_data_wrangling/index.html#saving-data",
    "title": "3  Wrangling data",
    "section": "3.8 Saving data",
    "text": "3.8 Saving data\nOnce we have finished wrangling a particular dataset, it is often useful to save it to a file so that we can use it again in future without going through all the steps of data wrangling again.\nMost R functions that begin with read_ (like read_csv() and read_excel()) have equivalent functions that begin write_ and which save data into a particular file format. In this example, we will use the write_csv() function from the readr package, which is loaded when we load the tidyverse package.\n# We can write data to a file in the same folder as our R script\nwrite_csv(agg_assault_data, \"fort_worth_agg_assault.csv\")\n\n# Or another folder on your computer ('../../' is short for the parent folder of\n# the parent folder of the current folder)\nwrite_csv(agg_assault_data, \"../../fort_worth_agg_assault.csv\")\nFor very large datasets, we can save a compressed version of the file by adding .gz (for gzip) to the end of the file name, which tells R to compress the file after creating it.\nwrite_csv(agg_assault_data, \"fort_worth_agg_assault.csv.gz\")\nread_csv() can read gzipped CSV files, but some other programs (such as Excel) cannot, so only use this option if you are sure you will only need to open the file in software that can handle it.\nThere are corresponding write functions for other types of data (which we will come back to when we learn how to handle spatial data), but in this course we will store all non-spatial data in CSV format because it can be read by many different programs."
  },
  {
    "objectID": "03_data_wrangling/index.html#stringing-functions-together",
    "href": "03_data_wrangling/index.html#stringing-functions-together",
    "title": "3  Wrangling data",
    "section": "3.9 Stringing functions together",
    "text": "3.9 Stringing functions together\nIn this tutorial we have learned how to use the dplyr functions select(), filter(), mutate(), summarise() and arrange() to wrangle data from one format to another. Data wrangling is part of almost all data analysis, so these are skills we will use frequently.\nData wrangling often involves multiple steps. For example, we might want to load some data, select certain columns, filter some rows, mutate some of the variables, summarise the dataset and save the result. We can do each of these steps separately, assigning the result of each step to a new object.\n# Load the lubridate package, since we will need it below\nlibrary(lubridate)\n\n# Read San Francisco robbery data\nrobbery1 <- read_csv(\"https://github.com/mpjashby/crimemapping/raw/main/inst/extdata/san_francisco_robbery.csv\")\n\n# Select only the columns we need\nrobbery2 <- select(robbery1, date_time)\n\n# Filter only those offences that occurred in the first quarter of 2019\nrobbery3 <- filter(robbery2, as.Date(date_time) <= as.Date(\"2019-03-31\"))\n\n# Create a new weekday variable\nrobbery4 <- mutate(robbery3, weekday = wday(date_time, label = TRUE))\n\n# Count how many offences occurred on each weekday\nq1_weekday_counts <- count(robbery4, weekday)\n\n# Print the first few rows of the result\nhead(q1_weekday_counts, n = 7)\nThis code works, but involves creating six new objects, even though we only need the final object for our analysis. You may notice that the first argument expected by select(), filter(), mutate() and count() is always the data tibble produced by the previous step. This means we can skip saving the result of each step as a new object, and just run the previous function inside the first function. This approach produces the following code, which produces exactly the same result as the code above.\nq1_weekday_counts <- count(\n  mutate(\n    filter(\n      select(\n        read_csv(\"https://github.com/mpjashby/crimemapping/raw/main/inst/extdata/san_francisco_robbery.csv\"),\n        -offense_type\n      ), \n      as.Date(date_time) <= as.Date(\"2019-03-31\")\n    ),\n    weekday = wday(date_time, label = TRUE)\n  )\n)\n\nhead(q1_weekday_counts, n = 7)\nThis code works and takes up less space, but it’s quite difficult to read – which can be a problem for finding and fixing problems with your code. For example, it’s quite hard (without counting pairs of parentheses) to work out that the reference to the column weekday on line 13 of this code belongs to the group_by() function on line 2.\nIt’s possible to write this code so that it is readable and does not require us to create multiple different objects to store the result of each step in our code. This method uses the |> (or pipe) operator. The pipe operator works by using the result of the code on the left-hand side of the pipe as the first argument to a function on the right-hand side. So the code x  |> fun1()  |> fun2(y) is the same as the code fun2(fun1(x), y), but it is much easier to see that fun1() is run before fun2(). It may be useful to read the pipe operator as ‘and then’, since piped code does the first thing and then the second thing with the result and then the third thing with the result of that, and so on. Piped code (sometimes called a pipeline) is a lot like the series of steps in a recipe.\nSince each function we are using returns the new data, and the first argument to all of those functions is the name of the input data object, the pipe means we can just omit the first argument to all except the first function.\nsan_fran_rob <- read_csv(\"https://github.com/mpjashby/crimemapping/raw/main/inst/extdata/san_francisco_robbery.csv\")\n\nq1_weekday_counts <- san_fran_rob |> \n  select(-offense_type) |> \n  filter(as.Date(date_time) <= as.Date(\"2019-03-31\")) |> \n  mutate(weekday = wday(date_time, label = TRUE)) |> \n  count(weekday)\n\nhead(q1_weekday_counts, n = 7)\nThis code strikes a good balance between being easy to read and not requiring us to manage lots of intermediate variables. You might not find the pipe operator completely intuitive at the moment, but it will become easier as you see more examples in future tutorials.\n\n\nWhat about the %>% pipe operator?\n\n\nIf you have learned any R coding before, you might have learned to use the %>% pipe operator from the magrittr package. The %>% pipe operator was introduced several years ago to allow people to construct pipelines of code in R. The %>% operator was so widely used that the team that writes the R programming language decided to provide a pipe operator in R itself, to avoid the need to load the magrittr package.\nYou will still see the %>% pipe operator used in lots of R code examples online. In almost all cases, when you see %>% you can replace it with the R pipe operator |>, since they both work in very similar ways.\n\n\n\n\nYou can find out more about how to use the pipe operator in the Introducing magrittr online tutorial."
  },
  {
    "objectID": "03_data_wrangling/index.html#in-summary",
    "href": "03_data_wrangling/index.html#in-summary",
    "title": "3  Wrangling data",
    "section": "3.10 In summary",
    "text": "3.10 In summary\n\nIn this tutorial, you have learned how to wrangle data in R using functions from packages in the tidyverse suite of packages. You can now construct a complete pipeline of R code to take raw data and transform it into the format(s) we need to effectively map crimes.\n\n\nDeveloping your data wrangling skills will help you to produce better, faster analysis of crime (and other) data. If you would like to develop your skills further, you might be interested in:\n\nData Wrangling with R by Claudia Engel, a free online book that explains the functions introduced in this tutorial (and some others) in more detail.\nData transformation with dplyr cheat sheet by the team that makes RStudio, which provides a handy two-page guide to the main functions in the dplyr package, which is very useful for reminding you of the code needed to run each of the functions we have used in this tutorial.\nData wrangling with R and RStudio by Garrett Grolemund, a recording of a webinar covering the data-wrangling functions introduced in this tutorial and some other very-useful related functions.\nR for Data Science by Hadley Wickham and Garrett Grolemund, a free online book that is the bible for wrangling data in R."
  },
  {
    "objectID": "04_code_with_style/index.html#introduction",
    "href": "04_code_with_style/index.html#introduction",
    "title": "4  Code with style",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\nNow that you’re beginning to write code in R, it’s time to introduce a few conventions for how to write code so that it’s easier to read. This is important because “good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread”.\nWriting readable code is particularly important because it is much easier to find mistakes in well-written code, and your code will inevitably contain mistakes (everyone’s code contains mistakes!).\nWriting code has been compared to performing in a band:\n\nI liken the situation to a group of musicians trying to form a band. Each one comes in believing that their way of doing things is best (their “method” or “process”). The band will struggle so long as everyone is trying to do their own thing. It’s impossible to create good music unless everyone in the band agrees on the tempo, the style and who should take lead during a song. Anyone who has ever heard a high school band perform knows this to be true. Unless everyone is on the same page, you aren’t going to accomplish much.\n\nYou might be relaxing at this point, thinking “that isn’t a problem for me, because I’m the only person who is going to be working on my code”. If so, think again. It’s been said that in data science that there are always at least two people working on a project: the you who is working on the code now, and the past you who has worked on the same code previously. The problem is that past you does not answer emails. So you can save future you a lot of hassle later by writing readable code.\nThis tutorial introduces some basic guidelines on formatting your code. This is a condensed version of the The tidyverse style guide, which provides lots more detail. All the code you see in the tutorials in this course was written following this style guide.\n\n\n\n\nOn Perl from Three Panel Soul. Some content on this page contains public sector information licensed under the Open Government Licence v3."
  },
  {
    "objectID": "04_code_with_style/index.html#organising-your-code",
    "href": "04_code_with_style/index.html#organising-your-code",
    "title": "4  Code with style",
    "section": "4.2 Organising your code",
    "text": "4.2 Organising your code\nUp until now we have only written code in the code boxes within these interactive tutorials, but when you move on to make maps using your own R code you will typically write that code in the RStudio source panel. Your code will usually be in one or more files with the .R file extension. Whether you keep all your code for a specific project in one file or split it into multiple files is up to you. Generally you should do whatever makes it easier to understand how your code is structured.\n\n4.2.1 Leaving notes for future you\nWithin each .R file, you can make your code easier to understand in several ways. First, add a comment (one or more lines beginning with # followed by a space) at the top of the file to explain what the code in that file does. This will make it easier for you to know that you’ve found the right file if you are looking for it in a few weeks when you’ve forgotten (which you will) what file contains what code.\n# This code produces a density map of bike thefts in Vancouver in 2020\nComments should usually start with a capital letter and follow normal English rules of punctuation, spacing, etc.\n\n\n4.2.2 Letting your code breathe\nUnless your code is very simple, it will probably consist of several separate tasks that are completed one after another. For example your code might download some data, wrangle it and then plot it on a map. In that case, it can be useful to split your code up into blocks by leaving a blank line between the code needed for each task. For example, if we take the code:\nlibrary(lubridate)\nlibrary(tidyverse)\ncrimes <- read_csv(\"crime_data.csv\")\ncrimes <- janitor::clean_names(crimes)\nburglaries <- filter(crimes, type == \"burglary\")\nburglaries <- mutate(burglaries, month = month(date_time))\nggplot() + \n  geom_point(aes(x = lon, y = lat, colour = month)) +\n  theme_void()\nit becomes easier to read if we split the code up into four tasks: loading the necessary packages, reading the data, wrangling the data and plotting the data.\nlibrary(lubridate)\nlibrary(tidyverse)\n\ncrimes <- read_csv(\"crime_data.csv\")\n\ncrimes <- janitor::clean_names(crimes)\nburglaries <- filter(crimes, type == \"burglary\")\nburglaries <- mutate(burglaries, month = month(date_time))\n\nggplot() + \n  geom_point(aes(x = lon, y = lat, colour = month)) +\n  theme_void()\nSince data wrangling involves several steps and each function uses the result of the previous step, we could use the pipe operator |> to make that code a bit cleaner:\nlibrary(lubridate)\nlibrary(tidyverse)\n\ncrimes <- read_csv(\"crime_data.csv\")\n\nburglaries <- crimes |> \n  janitor::clean_names() |> \n  filter(type == \"burglary\") |> \n  mutate(month = month(date_time))\n\nggplot() + \n  geom_point(aes(x = lon, y = lat, colour = month)) +\n  theme_void()\n\n\n4.2.3 Header comments\nIf your code includes very long tasks (e.g. where the code takes up more than a full screen on your computer), you might want to use header comments to divide your code into sections. You can do this by writing a comment that is followed by four of more hyphens (----):\n# Load data ----\n\n… some code …\n\n\n# Wrangle data ----\n\n… some code …\n\n\n# Plot data ----\n\n… some code …\nRStudio will recognise lines that end in four or more hyphens as being headings, and will create a table of contents for your code. You can use this to move between headings by clicking on the Jump To menu at the bottom of the Source panel in RStudio:\n\n\n\n\n\n\n\n\n\nIn general, writing code that is readable is more important than writing the shortest code possible, so don’t be afraid to let your code breathe by using space to separate your code into meaningful chunks."
  },
  {
    "objectID": "04_code_with_style/index.html#naming-objects",
    "href": "04_code_with_style/index.html#naming-objects",
    "title": "4  Code with style",
    "section": "4.3 Naming objects",
    "text": "4.3 Naming objects\nR objects can have any name you like, as long as the name starts with a letter and contains only letters, numbers, dots (.) and underscores (_). That said, you will find coding easier if you follow a few conventions.\n\nUse only lower-case letters in the names of objects, which avoids you having to remember whether a particular letter was upper- or lower-case.\nUse snake case (object_name, with words separated by underscores) for object names rather than camel case (objectName) or kebab case (object-name).\nDon’t use dots in object names.\nDon’t give objects the same names as R functions, because re-using function names makes reading your code more difficult.\n\n\n\n\n\n\n\n\n\n\nJust as crime_data_atlanta_2020.csv is a more-useful file name than data_file_23.csv, you will find it easier to read your code if you give your objects meaningful names. So when you load data into R (e.g. with read_csv()) don’t just call it data (not least because there is a function named data()) but instead give it a name like atlanta_crimes if it contains (for example) crime data from Atlanta.\n\nStats Illustrations by Allison Horst licensed under the Creative Commons Attribution licence."
  },
  {
    "objectID": "04_code_with_style/index.html#spacing",
    "href": "04_code_with_style/index.html#spacing",
    "title": "4  Code with style",
    "section": "4.4 Spacing",
    "text": "4.4 Spacing\nSpacing out code makes it much easier to read, but (just as in any language) code is easiest to read if spaces are used where people expect them to be by convention.\nMostly in R, we use spaces where we would expect them in English: after commas but not before, outside parentheses but not inside, etc.\n# Good\nread_csv(\"crime_data.csv\", skip = 4)\n\n# Bad\nread_csv(\"crime_data.csv\",skip = 4)\nread_csv(\"crime_data.csv\" ,skip = 4)\nread_csv(\"crime_data.csv\" , skip = 4)\nDon’t put spaces inside parentheses, or between the names of functions and the parentheses:\n# Good\nmean(x, na.rm = TRUE)\n\n# Bad\nmean (x, na.rm = TRUE)\nmean( x, na.rm = TRUE )\nDo put spaces around most operators (==, +, -, <-, etc.), including either side of = when specifying the values of function arguments:\n# Good\nheight <- (feet * 12) + inches\nmean(x, na.rm = TRUE)\n\n# Bad\nheight<-feet*12+inches\nmean(x, na.rm=TRUE)\nAlthough there are some operators that shouldn’t have spaces around them: $, @, [, [[, ^, : and ?."
  },
  {
    "objectID": "04_code_with_style/index.html#functions",
    "href": "04_code_with_style/index.html#functions",
    "title": "4  Code with style",
    "section": "4.5 Functions",
    "text": "4.5 Functions\nWe’ve now got used to calling functions to do things in R, like calling read_csv() to load data from a CSV file or filter() to choose certain rows from a dataset. We know that we can change the behaviour of functions by using arguments. For example, we can wrap a a string of text into shorter lines using the str_wrap() function from the stringr package. str_wrap() needs two arguments: the text to be wrapped into multiple lines and the maximum length of a line of text before the next word is wrapped onto a new line. These arguments are called string and width, so we can call the function as:\nstr_wrap(string = \"some text to be wrapped\", width = 10)\nThe string argument provides the data that the str_wrap() function will work on, while the width argument provides the details of how that work should be done. Since the data argument to a function is typically required (the function makes no sense without it) and is often the first argument, you can omit the name of data arguments to functions. For all other arguments, it is best to give the argument name. So to use str_wrap(), you can write:\nstr_wrap(\"some text to be wrapped\", width = 10)\nIn general, you should keep lines of code to a maximum of 80 characters long, since they can easily fit on most screens and are easy to read. When calling a function, put all of the parameters on a single line if they will fit into 80 characters or less:\ndo_something_simple(\"something\", with = \"only\", short, \"arguments\")\nBut if the function call is longer than 80 characters, use one line each for the function name, each argument, and the closing ), with the arguments indented by two spaces. This makes the code much easier to read.\n# Good\ndo_something_very_complicated(\n  something = \"that\",\n  requires = many,\n  arguments = \"some of which may be long\"\n)\n\n# Bad\ndo_something_very_complicated(\"that\", requires, many, arguments,\n                              \"some of which may be long\"\n                              )\ndo_something_very_complicated(\n  something = \"that\",\n  requires = many,\n  arguments = \"some of which may be long\")\nWhen combining multiple functions using the pipe operator (|>), put each function on a single line, with all but the first line indented by two spaces:\na_function() |> \n  another_function() |> \n  and_a_third_function()\nOnce you learn about other types of R code you will need to know how best to style it, but we will learn about those when we need to."
  },
  {
    "objectID": "04_code_with_style/index.html#styling-your-code-automatically",
    "href": "04_code_with_style/index.html#styling-your-code-automatically",
    "title": "4  Code with style",
    "section": "4.6 Styling your code automatically",
    "text": "4.6 Styling your code automatically\nYou can get help on styling your R code using the styler package, which can automatically format your code for you. After you install the styler package with the code install.packages(\"styler\"), you can style your code by:\n\nselecting the code you want to style,\nopening the Addins menu at the top of the Source panel in RStudio,\nclicking ‘Style selection’ in the ‘Styler’ section of the list of addins.\n\n\n\n\n\n\n\n\n\n\nRStudio will also try to help style your code as you type, for example by automatically indenting lines."
  },
  {
    "objectID": "04_code_with_style/index.html#in-summary",
    "href": "04_code_with_style/index.html#in-summary",
    "title": "4  Code with style",
    "section": "4.7 In summary",
    "text": "4.7 In summary\n\nYou now know how to write your R code so that it is easy to read, which makes it much easier to understand. Understanding code when you read it is important because it allows you to work out what the code is trying to achieve and because it makes it much easier to find and fix problems when your code is not behaving as you want it to.\n\n\nWriting readable, understandable code is important. To find out more about this, read some of these articles:\n\nWhy coding style matters by Nicholas Zakas.\nThe tidyverse style guide by Hadley Wickham, which is the basis for the rules outlined in this tutorial.\n\n\n\nThe tidyverse style guide licensed under the Creative Commons Attribution-ShareAlike licence."
  },
  {
    "objectID": "05_your_second_crime_map/index.html#introduction",
    "href": "05_your_second_crime_map/index.html#introduction",
    "title": "5  Your second crime map",
    "section": "5.1 Introduction",
    "text": "5.1 Introduction\nWe’ve already produced a simple map of crime in a neighbourhood, but we skipped over a lot of the details of how to do it. In this tutorial we will make another crime map, this time focusing more on each step in the process.\nIn this tutorial we will make a map of bicycle thefts in Vancouver in 2020. At the end of this tutorial, the final map will look something like this. We will then improve it further in a future tutorial on what makes a good map.\n\nBefore we get into the detail of how to make this map, watch this video that goes over the main points of the code we will use:"
  },
  {
    "objectID": "05_your_second_crime_map/index.html#handling-spatial-data",
    "href": "05_your_second_crime_map/index.html#handling-spatial-data",
    "title": "5  Your second crime map",
    "section": "5.2 Handling spatial data",
    "text": "5.2 Handling spatial data\nMaps are visual representations of spatial data. Spatial data is special because each row in the data is associated with some geographic feature such as a building, a street or the boundary of a neighbourhood. This adds some quirks that we have to understand to work with spatial data successfully.\n\n5.2.1 Vectors and rasters\nSpatial data can be represented in two general formats: vectors and rasters. Watch this video from the UK mapping agency Ordnance Survey to find out more about the advantages and disadvantages of using each type of data.\n\nAs you saw in the video, generally vector data gives you more control over the appearance of a map, but at the cost of your having to put together each part of the data yourself, choose the styles etc. In contrast, raster data (such as the base map of Atlanta we used in the first map we made for this course) gives you less control but allows you to add pre-formatted data to your map quickly.\n\n\n5.2.2 Spatial layers\nMaps are made up of multiple layers of spatial data that are styled to represent features of interest and then stacked on top of one another to make the finished map. Watch this video to learn more about spatial layers and the three different types of vector data that we can use in maps.\n\nPoints, lines and polygons in spatial data are known as geometric objects or simply geometries. Spatial data is data that has a geometric object associated with each row.\n\n\n5.2.3 Representing places on the earth\nSince maps are two-dimensional representations of the curved surface of the earth, map-makers must make choices about how to translate that curved surface onto a flat screen or piece of paper. This video introduces these choices, and explains why they are relevant to crime mapping.\n\nWith any spatial data, we need a way of describing where on the earth a particular point (such as the location of a crime or the corner of a building) is located. Watch this video to find out about the different co-ordinate systems we can use to do this."
  },
  {
    "objectID": "05_your_second_crime_map/index.html#spatial-data-in-r",
    "href": "05_your_second_crime_map/index.html#spatial-data-in-r",
    "title": "5  Your second crime map",
    "section": "5.3 Spatial data in R",
    "text": "5.3 Spatial data in R\n\n\n\nThere are several packages that handle raster map data from different sources – one of them is the ggspatial package that we have already used to load the base map of Atlanta for the homicide map we made in one of the earlier tutorials.\n\nVector data can be handled in R using functions from the sf package. SF stands for ‘simple features’, which is a standard for storing spatial data. SF objects are data frames that have a special column to hold the geometry (point, line or polygon) associated with each row in the data. SF objects also understand what co-ordinate system the geometry are described in. This means SF objects can be transformed between co-ordinate systems and combined together in layers on a map.\nThere a lots of functions in the sf package for handling spatial data. Almost all of these functions begin with the letters st_ (e.g. st_read()), which makes it easy to identify that those functions are designed to be used on SF objects.\n\n5.3.1 Reading spatial data\nThe special features of spatial data – needing to store geometries, details of the projection used etc. – mean that spatial data is often stored in special file formats. There are lots of spatial-data formats, but fortunately almost all of them can be read by the st_read() function. This means we do not need to learn a different function for each spatial-data format.\nWhile datasets with line or polygon geometries must almost always be stored in specific spatial-data formats, point data can also be stored in common data formats such as Excel and CSV files. The data for this tutorial is provided by the Vancouver Police Department in a CSV file (gzipped to reduce the file size). The file is located at:\nhttps://mpjashby.github.io/crimemappingdata/vancouver_thefts.csv.gz\nThinking back to the tutorial on data wrangling, we can use the read_csv() function from the readr package to load this data into a tibble called thefts\n# Since the data are stored in a regular CSV file, we can use the `read_csv()`\n# function from the readr package to read the file, and the assignment operator\n# `<-` to store the data in the object `thefts`. `read_csv()` can read directly\n# from a URL, so there is no need to download the data first.\nlibrary(tidyverse)\n\nthefts <- read_csv(\"https://mpjashby.github.io/crimemappingdata/vancouver_thefts.csv.gz\")\nNow that you have stored the data in the thefts object, we can use the head() function to view the first few rows of data.\nhead(thefts)\nThe data consists of 21,918 rows, each representing one theft. Before we can map this data, we will need to do some minor data wrangling to get it into the format we want.\n\n\n5.3.2 Cleaning column names\n\n\n\nIn a previous tutorial I recommended choosing snake_case object names, e.g. calling a data object atlanta_robberies_2020 rather than atlantarobberies2020, AtlantaRobberies2020 or ATLANTAROBBERIES2020. This makes your code easier to read and means you don’t have to remember whether you named a variable using upper- or lower-case letters, since you know that you only use lower case.\nThe same recommendation applies to variable names in datasets, for the same reasons. Doing this makes it much easier to refer to objects and columns in your code, without having to worry about whether a particular letter was upper- or lower-case, or whether it had an accent etc.\n\nAt the moment, the column names in the thefts dataset are upper-case letters. Rather than having to remember this, we can easily convert them to snake case using the clean_names() function from the janitor package. To use a function from a package, we usually first load the package using the library() function. In this case, we probably won’t want to use any other functions from the janitor package, so instead of loading the whole package we will use this one function directly. To do this, we write the function name with the package name added to the front, separated by two colons ::.\nthefts <- janitor::clean_names(thefts)\n\nhead(thefts)\nYou can see that the data has stayed the same but all the column names are now in snake case. clean_names() would also have replaced any spaces with underscores, tried to separate words in the variable names and cleaned up several other potential problems. For this reason it is common to call janitor::clean_names() straight away after loading a dataset so that you can be confident that the column names will be in the format you expect.\nIf we wanted to use the clean_names() function again, we would have to include the package name and :: each time, so if our code was going to make repeated use of the function then it would probably be easier to load the package using the library() function as we have done in previous tutorials.\n\n\n5.3.3 Converting our data to an SF object\nAt present, the data in the thefts object is just a regular tibble. We could not use it to make a map because R does not know which columns represent the geometry, or what co-ordinate system the locations are recorded in. We can deal with this by converting the data to an SF object using the st_as_sf() function from the sf package.\nThe data provided by the Vancouver Police use the UTM zone 10N co-ordinate system. UTM is a system for assigning co-ordinates to any location on earth relative to a local origin point for the UTM zone covering that part of the planet. It is therefore similar to the British National Grid that we have already learned about, but for any part of the globe. The ‘N’ at the end of the zone name refers to the northern hemisphere.\n\nIn almost all cases, co-ordinate reference systems only work for the part of the world that they were designed for. So we should not use the UTM zone 10N co-ordinate system to map data outside the area for which it was designed (broadly speaking, the west coast of North America from Los Angeles to Vancouver, and the part of Canada directly north of Vancouver extending as far as the north pole). If we were to use the UTM zone 10N co-ordinate system for data from another part of the world, we would be very likely to get error messages or strange results.\n\n\nWe can convert the thefts tibble to an SF object using the st_as_sf() function (remember, all functions in the sf package start with st_, which can sometimes make the function names a little confusing). We specify which columns in the data represent the geometry (in this case, the x and y columns), and what co-ordinate system the data uses.\nCo-ordinate systems can be specified in lots of ways (some very complicated), but the easiest is to specify the EPSG code for the relevant system. An EPSG code is a unique reference number for a particular co-ordinate system that R can look up in a database to get the information needed to display the data on a map. The EPSG code for the UTM zone 10N is EPSG:32610.\n\nlibrary(sf)\n\nthefts_sf <- st_as_sf(thefts, coords = c(\"x\", \"y\"), crs = \"EPSG:32610\")\n\nhead(thefts_sf)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 488991.7 ymin: 5450474 xmax: 497938.7 ymax: 5458985\nProjected CRS: WGS 84 / UTM zone 10N\n# A tibble: 6 × 9\n  type   year month   day  hour minute hundr…¹ neigh…²           geometry\n  <chr> <dbl> <dbl> <dbl> <dbl>  <dbl> <chr>   <chr>          <POINT [m]>\n1 Othe…  2020     1     1     0      0 11XX B… West E… (490320.3 5458607)\n2 Othe…  2020     1     1     0      0 13XX W… Marpole (489998.2 5450474)\n3 Othe…  2020     1     1     0      1 18XX E… Grandv… (495141.1 5458406)\n4 Othe…  2020     1     1     0      0 2X ALE… Centra… (492471.3 5458985)\n5 Thef…  2020     1     1     0      0 11XX S… Hastin… (497938.7 5457949)\n6 Thef…  2020     1     1     0     10 14XX L… Kitsil… (488991.7 5457823)\n# … with abbreviated variable names ¹​hundred_block, ²​neighbourhood\n\n\nIf you look at the contents of the thefts_sf object, you’ll see that there is a new column called geometry (you may need to use the ▸ button to see it). This column contains the co-ordinates of each bike theft in a format that R recognises represent locations on the surface of the earth, which means they can be used to make maps.\n\n\n5.3.4 Finding bike thefts in our data\nIf you look through the contents of the thefts_sf object, you will see that not all of the rows relate to bicycle thefts. The type column shows that the dataset also includes thefts from vehicles, for example. To choose only those rows containing bicycle thefts, which function from the dplyr package would we used? If you need help, you can think back to the data-wrangling tutorial or have a look at the Data transformation with dplyr cheat sheet.\nThinking back to the chapter on data wrangling, we can use the filter() function to choose only the rows of data that relate to bicycle thefts and store it in a new object called bike_thefts\nbike_thefts <- filter(thefts_sf, type == \"Theft of Bicycle\")\nOur data is now ready for us to make our crime map!\n\nStats Illustrations by Allison Horst licensed under the Creative Commons Attribution licence."
  },
  {
    "objectID": "05_your_second_crime_map/index.html#producing-maps-in-r",
    "href": "05_your_second_crime_map/index.html#producing-maps-in-r",
    "title": "5  Your second crime map",
    "section": "5.4 Producing maps in R",
    "text": "5.4 Producing maps in R\nNow that we have our data, we can use it to create a map of bicycle theft in Vancouver. Before we start, let’s take another look at our dataset so that we know which columns contain which data.\n\nhead(bike_thefts)\n\nSimple feature collection with 6 features and 10 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 488371.3 ymin: 5452696 xmax: 494295.1 ymax: 5458232\nProjected CRS: WGS 84 / UTM zone 10N\n# A tibble: 6 × 11\n  type              year month   day  hour minute hundre…¹ neigh…²      x      y\n  <chr>            <dbl> <dbl> <dbl> <dbl>  <dbl> <chr>    <chr>    <dbl>  <dbl>\n1 Theft of Bicycle  2020     1     1     0      0 12XX VE… Strath… 4.94e5 5.46e6\n2 Theft of Bicycle  2020     1     1     0      0 20XX MA… Kitsil… 4.89e5 5.46e6\n3 Theft of Bicycle  2020     1     1    13      0 7XX PAC… Centra… 4.92e5 5.46e6\n4 Theft of Bicycle  2020     1     1    20      0 53XX VI… Arbutu… 4.88e5 5.45e6\n5 Theft of Bicycle  2020     1     3    11     55 65XX AN… Kerris… 4.89e5 5.45e6\n6 Theft of Bicycle  2020     1     3    14      0 4XX E 1… Mount … 4.93e5 5.46e6\n# … with 1 more variable: geometry <POINT [m]>, and abbreviated variable names\n#   ¹​hundred_block, ²​neighbourhood\n\n\n\n5.4.1 Introduction to ggplot2\n\n\n\nA map is a specialised type of chart, so we can make maps using the ggplot2 package that is widely used to create other types of chart in R. ggplot2 charts are made up of layers, so they’re well suited to making maps.\n\nThe most-basic map that we can make simply plots the locations of crimes with no context. This almost never makes a good crime map, but we can use this type of map as the foundation around which we can build a better map.\nggplot2 plots work by building up a chart using different functions, each of which adds or modifies some part of the chart. Building a plot starts with calling the ggplot() function, with each subsequent function being added to the plot definition using the + operator. Note that while the package is called ggplot2, the function in that package used to create plots is called ggplot(), not ggplot2().\nThe most-important of the ggplot2 functions are those beginning with geom_, which add graphical elements to the chart. If you want to add a layer to your chart showing a scatter plot, you use the geom_point() function, while if you want to make a line chart you use geom_line().\n\n\n\n\n\n\n\n\n\nThere are lots of geom_ functions available for representing data on charts in different ways. For maps, the SF package includes the geom_sf() function that is designed to add spatial data (in the form of an SF object such as our bike_thefts data) to a chart, making it into a map. So to simply plot the points in our bicycle-theft data, we can use the code:\n\nlibrary(ggplot2)\n\nggplot() +\n  geom_sf(data = bike_thefts)\n\n\n\n\nBy convention, each function that we add to ggplot() to change the appearance of our map goes on a new line (this makes the code easier to read) and all but the first line is indented by two spaces. RStudio does this indenting automatically if the previous line ends with a + symbol, since RStudio then understands that there is more code to come on the next line.\nThis map shows the bike-theft data, but it is obviously not a very useful map. Fortunately, we can use the features of the ggplot2 package to build on this basic map.\n\n\n5.4.2 Controlling aesthetics\nWe can change the appearance of the points by specifying various arguments to the geom_sf() function. These arguments are called aesthetics, because they control the aesthetic appearance of the geometric objects (points, lines etc.) produced by a geom_ function. There are lots of aesthetics, but some of the most common are:\n\ncolour controls the colour of points and lines (for polygons, it controls the colour of the border around the polygon edge) – you can also use the spelling color for this argument and get an identical result,\nfill controls the colour used to fill polygons or points that use a shape capable of having different colours in the centre and around the edge (fill has no meaning for lines),\nshape controls the shape (circle, triangle, square etc.) of points (it has no meaning for lines or polygons),\nsize controls the size of points and text,\nlinewidth controls the width of lines, including the borders around the edges of polygons, and\nalpha controls the transparency of a layer (alpha = 1 equals fully opaque, alpha = 0 means fully transparent).\n\ncolour and fill can be specified using any one of 657 R colour names or using a hexidecimal (‘hex’) colour code. Values of size don’t relate to any unit of size (e.g. millimetres or points), so it’s easiest to set the size of points and text by trial and error.\nThere are 25 built-in shapes for points in R (shape 16 is the default):\n\n\n\n\n\n\n\n\n\nWe can change the code above so that the points on our map are red squares instead of black circles (red is one of the 657 R colour names).\n\n# Add the arguments `shape = 15` and `colour = \"red\"` to the `geom_sf()`\nggplot() +\n  geom_sf(data = bike_thefts, shape = 15, colour = \"red\")\n\n\n\n\nAs we have said, this basic map is not very useful. We can see that there seems to be a cluster of bike thefts towards the top (north) of the map, but it is difficult to see how important this cluster is because so many of the points overlap. Overlapping points are a particular problem in maps, because if there are multiple crimes at the same location then the points representing those crimes will be exactly on top of one another and it will be impossible to see whether there is one crime at a particular location or 100.\nOne way to deal with this problem is to make the points semi-transparent so that overlapping points appear darker. This often works better if we also make the points slightly smaller at the same time. We can use the alpha and size aesthetics to make the points smaller (relative to the default for points of size = 1) and semi-transparent.\n\n# Which values you chose will depend on your personal aesthetic preferences,\n# but these values produce a map that makes it easier to see the distribution of\n# points\nggplot() +\n  geom_sf(data = bike_thefts, size = 0.75, alpha = 0.1)\n\n\n\n\nMaking the points semi-transparent goes some way to making it easier to see where bike theft is most common in Vancouver, but the pattern is not clear and it is not possible to tell which darker points represent a handful of crimes at the same location and which represent hundreds of crimes at the same location. To make our map useful, we need to use a different technique."
  },
  {
    "objectID": "05_your_second_crime_map/index.html#mapping-crime-density",
    "href": "05_your_second_crime_map/index.html#mapping-crime-density",
    "title": "5  Your second crime map",
    "section": "5.5 Mapping crime density",
    "text": "5.5 Mapping crime density\n\nUnless we want to produce a map of only a very small number of crimes (like the Atlanta downtown homicides map we produced in a previous tutorial), it is unlikely that a point map will be very useful.\nIn fact, if you find yourself making map with each crime represented by a separate point, you should probably stop and ask yourself if that is really the best way to achieve your goal.\n\nA better way to show where crime is concentrated on a map is to work out the density of crime in each area and then map that density. By density in this context, we mean the relative concentration of points in each part of the area we are studying, i.e. how many points (representing bike thefts) are there in each part of the map relative to all the other areas of the map.\nTo estimate the density of points in different areas of the map, R uses a technique called kernel density estimation (KDE). To do this, R must:\n\ndivide the map into a grid of cells, each the same size,\ncount the number of points in each cell,\nfor each cell, count the number of points in nearby cells, but give less weight to (i.e. systematically undercount) those cells that are further away,\nfor each cell, total up the count of points in that cell and the (weighted) count of points in nearby cells – this is the estimate of the density of points in that cell.\n\nThis procedure has the effect of producing a smooth surface representing crime density.\n\nWe don’t need to worry at this point about the details of how the counts are used to estimate the density of crimes – we will return to this in a later tutorial.\n\nThere are several ways we can make density maps in R. In this course we will use the sfhotspot package because it makes reasonable decisions about how or density maps should look, while still giving us control over their appearance if we want it. sfhotspot also has other useful functions that we will use in future tutorials.\nTo create a density map using sfhotspot, we first use the hotspot_kde() function to convert a dataset of offence locations to an estimate of the density of offences for each cell in a grid. hotspot_kde() automatically chooses how big the cells in the grid should be (but we can set this ourselves if we want to).\nThe bike_theft_density object created by hotspot_kde() contains three columns: n contains the count of bike thefts in each cell, kde contains the estimate of the density of thefts in each cell, and geometry contains the outline of each grid cell.\nSince hotspot_kde() produces an SF object, we can add it to a map using the geom_sf() function. We can also use the fill aesthetic to specify that the fill colour of each grid cell should be determined based on the values of the kde column in the bike_theft_density object.\n\nggplot() +\n  geom_sf(aes(fill = kde), data = bike_theft_density, colour = NA)\n\n\n\n\nWe have already seen that we can set aesthetics such as colour and shape manually, but the aes() function allows us to specify that the values of different aesthetics should be controlled by columns in the data. The aes() function takes as its arguments pairs of values (combined with an = symbol) where the first value is an aesthetic and the second value is the name of a column in the data. For example, to use the colour of points on a map to represent different types of crime that were stored in a column in the data called type, we could use aes(colour = type).\n\nWhen should you specify the values of aesthetics inside aes() and when should you do it outside aes()?\n\nIf you want an aesthetic to have a constant value for all the points, lines or other shapes in a layer, control the aesthetic outside aes(). For example, you could use geom_sf(bike_thefts, colour = \"mediumblue\") to make all the shapes in that layer blue.\nIf you want to vary the appearance of shapes according to values in the data, you should control the aesthetic inside aes(). For example, you could use geom_sf(aes(colour = month), bike_thefts) to vary the colour of shapes in a layer according to values of the month column in the data.\n\naes() must be the first argument in the geom_*() function.\n\nIn this map, instead of seeing each crime as a separate point, we see the density of crime as the filled colour of cells in a grid. By comparing this density map to the point map we produced before, we can see that the density map makes the areas with the highest frequency of thefts easier to identify.\nYou can also see that our map now has a legend, showing that higher densities of bike thefts are shown on the map in dark blue and lower densities are shown in light blue. The exact values shown in the legend are not particularly meaningful, so we can ignore these for now.\n\n5.5.1 Fine-tuning density maps\nWe can control the appearance of KDE maps in several ways. For example, we can vary the number of cells in the grid and the definition of what cells the kernel density estimation process should consider to be ‘nearby’ for the purposes of calculating weighted counts. Cells are considered to be ‘nearby’ to a particular cell if they are closer to that cell than a distance known as the KDE bandwidth.\nBy default, hotspot_kde() chooses the cell size and the bandwidth automatically. The maps below show how changing these defaults changes the appearance of our map (with the legend and axes removed to make the small maps clearer).\n\nBy looking at the maps on the right-hand side, you can see that reducing the number of grid cells leads to a map that looks blocky and lacks information. Looking at maps higher up, you can see that increasing the bandwidth relative to the default makes the density surface smoother. The smoother the surface, the less detail we can see about where crime is most concentrated, until on the top row we can see almost no information at all. On the other hand, if we reduce the bandwidth too much (the bottom row of maps) then almost no ‘nearby’ cells are included in the count and so it becomes more difficult to identify patterns.\nIn most cases, you will not need to change the cell size used in calculating the density of points on a map, but if you do then you can do this using the cell_size argument to hotspot_kde().\nAlthough you can set the bandwidth manually using the bandwidth argument to hotspot_kde(), you will almost never want to do this. Instead, you can vary the bandwidth relative to the automatically chosen default bandwidth by using the bandwidth_adjust argument. For example, if you wanted to see more detail in your map by using a smaller bandwidth, you could use adjust = 0.5 or adjust = 1/2 to set the bandwidth to be half of the default bandwidth.\n# You can set either `bandwidth_adjust = 1/2` or `bandwidth_adjust = 0.5` to \n# get the same result\nhotspot_kde(bike_thefts, bandwidth_adjust = 1/2) |> \n  ggplot() +\n  geom_sf(aes(fill = kde), colour = NA)\n\n\n\n\n\nComparing this map to the first density map we produced, we can see that the slightly smaller bandwidth means we can see slightly more detail in the patterns of bike thefts.\n\nI recommend using a slightly smaller bandwidth than the default, so that your maps show a bit more detail. Try setting bandwidth_adjust = 0.5 whenever you produce a density layer using hotspot_kde(), but remember to look at the map to see if you are happy with the result.\n\nThe final way we can control the appearance of our density layer is to change the colour scheme used to represent density. To do this, we can use another type of ggplot2 function: scales. There are lots of scales available, but the scale_fill_distiller() function produces several different colour scales that are specifically designed to be effective on maps.\nAll the available colour schemes are on the Color Brewer website. Colour schemes can be divided into three types:\n\nsequential colour schemes are useful for showing values from low to high,\ndiverging colour schemes are useful for showing values relative to a meaningful central point, and\nqualitative colour schemes are useful for showing separate categories that can appear in any order and still be meaningful.\n\nIn crime mapping we’re usually interested in showing how crime varies from low to high, so we need to use a sequential colour palette. There are 18 sequential colour schemes (or palettes) available in scales_fill_distiller(), each with a name:\n\n\n\n\n\n\nIt is important to only use the right type of colour scale in the right circumstances, since using the wrong type of scale could end up misleading people reading your map. For example, a diverging colour scale gives the strong impression that the central point in the scale is meaningful.\nIn some circumstances this might be useful, for example if you wanted to show areas in which crime had increased in shades of one colour and areas in which crime had decreased in shades of another colour. In that case, a diverging scale would be appropriate because the central point represents something meaningful: no change in crime. If the central point is not meaningful, use a sequential colour scheme instead.\nIf you want to represent a categorical variable, you should use a categorical colour scale unless the categories have a natural order. For example, if you wanted to show ethnic groups on a map you would use a categorical colour scale since there is no one order of ethnic groups that is any more meaningful than any other. If you wanted to represent days of the week with colour, then you might want to use a sequential colour scheme since the days of the week have a meaningful order.\n\nBy default, scale_fill_distiller() sets the lowest values to have the darkest colour. This often does not work well, but we can change this by setting the argument direction = 1. I recommend doing this in all cases.\n\n\n\n\n\n\n\n\n\nYou can think of all the functions that we can add to ggplot() as being like a stack of pancakes, with each new function being placed on the top of the stack. To change the colour of our map, we just add scale_fill_distiller() to the existing stack.\n\nggplot() +\n  geom_sf(aes(fill = kde), data = bike_theft_density, colour = NA) +\n  scale_fill_distiller(palette = \"Oranges\", direction = 1)"
  },
  {
    "objectID": "05_your_second_crime_map/index.html#clipping-map-layers",
    "href": "05_your_second_crime_map/index.html#clipping-map-layers",
    "title": "5  Your second crime map",
    "section": "5.6 Clipping map layers",
    "text": "5.6 Clipping map layers\nThere is one limitation of the KDE layer on our map that we need to deal with. The area covered by the KDE layer is determined by the area covered by the point data that we provided to hotspot_kde(). More specifically, hotspot_kde() will calculate density values for every cell in the convex hull around the point data, i.e. for the smallest polygon that contains all the points in the data.\nThis can be a problem in some circumstances, because we do not necessarily have crime data for all the areas within the convex hull of the data, even though KDE values will be calculated for those areas. This could be misleading, since it will look like such areas have low crime density, when in fact we do not know what the density of crime in such areas is.\nFortunately, we can easily deal with this problem by clipping the KDE layer to the boundary of the area for which we have crime data. This means we will only show densities for cells for which we actually have data.\n\n\nA. We only have data on bike thefts from the City of Vancouver, so all the bike thefts in the data necessarily occurred within the city. We do not know what the density of crime outside the city is.\n\n\n\nB. The KDE function only knows the theft locations, not the area in which thefts could have occurred. So the convex hull created by the KDE layer will not necessarily match the area of the data.\n\n\n\n\n\nC. In this case, that means some areas (shaded) will be included in the KDE layer even though they happened outside the area covered by the data, which could be misleading.\n\n\n\nD. To avoid suggesting we know the density of crimes in areas for which we do not have data, we should clip the KDE layer to the boundary of the area for which we have data.\n\n\n\nWe can clip the KDE layer produced by hotspot_kde() to the boundary of the City of Vancouver using the st_intersection() function from the sf package. st_intersection() removes any rows from the dataset provided as the first argument that do not fall within the area covered by the dataset provided as the second argument. If we have the boundary of the City of Vancouver stored in an object called vancouver_boundary and the a KDE layer showing the density of bike thefts stored in the bike_theft_density object, we can use st_intersection() to remove any cells in bike_theft_density that are outside vancouver_boundary.\n\n# Before clipping the KDE layer, we can use the `nrow()` function to check how\n# many cells there are in the KDE grid (each grid cell is one row in the data)\nnrow(bike_theft_density)\n\n[1] 3318\n\n# Clip the density layer\nbike_theft_density_clip <- st_intersection(\n  bike_theft_density, \n  vancouver_boundary\n)\n\nWarning: attribute variables are assumed to be spatially constant throughout all\ngeometries\n\n# Now we can check the number of rows in the clipped layer, which will be\n# lower than in the original KDE layer\nnrow(bike_theft_density_clip)\n\n[1] 2927\n\n\nst_intersection() produces a warning message:\nWarning: attribute variables are assumed to be spatially constant throughout all\ngeometries\nAs long as you are simply using st_intersection() to remove parts of the data outside a boundary, you can ignore this message.\nIn most cases, we can use the pipe operator to clip a KDE layer just after we produce it with hotspot_kde():\nbike_theft_density_clip <- bike_thefts |> \n  hotspot_kde(bandwidth_adjust = 0.5) |> \n  st_intersection(vancouver_boundary)\n\nThe st_intersection() function requires that both spatial layers have the same co-ordinate system. If the two layers use different co-ordinate systems, you will need to transform one of the layers using st_transform() so that it uses the same co-ordinate system as the other layer.\nIf you do not know which co-ordinate systems the layers use, you can use the st_crs() function to extract the co-ordinate system from one layer and pass that value as the second argument to st_transform(). For example:\nst_transform(bike_theft_density, crs = st_crs(vancouver_boundary))"
  },
  {
    "objectID": "05_your_second_crime_map/index.html#adding-a-base-map",
    "href": "05_your_second_crime_map/index.html#adding-a-base-map",
    "title": "5  Your second crime map",
    "section": "5.7 Adding a base map",
    "text": "5.7 Adding a base map\nThe density map we have made is much more effective than a point map at allowing us to identify where the highest number of bike thefts in Vancouver occur. However, it’s still quite difficult to know where those places are, because we cannot easily work out where in the city these places are. We can make this much easier by adding a base map underneath the density layer.\nWe can add a base map using annotation_map_tile() function from the ggspatial package. We can add annotation_map_tile() to a ggplot() stack in the same way that we would add geom_*() functions.\n\nggplot() +\n  # We add the base map to the `ggplot()` stack *before* the density layer \n  # because we want the base map to appear below the density layer\n  annotation_map_tile(zoomin = 0) +\n  # When adding a base map, it is useful to make any filled layers (such as the\n  # density layer) semi-transparent so that readers can see the base map\n  geom_sf(\n    aes(fill = kde), \n    data = bike_theft_density_bw_half, \n    alpha = 0.67, \n    colour = NA\n  ) +\n  scale_fill_distiller(palette = \"Purples\", direction = 1) +\n  theme_void() +\n  # Suppress the map legend -- we will learn more about these next lines of code\n  # in a future tutorial\n  theme_void() + \n  theme(legend.position = \"none\")\n\nZoom: 12\n\n\n\n\n\nThe base maps returned by annotation_map_tile() are available at many different zoom levels, from level 1 that is useful for mapping the whole world in one map, to level 20 that can be used to map a single building. By default, annotation_map_tile() downloads tiles with slightly less detail than we might want, but we can fix this by using the argument zoomin = 0. We could also set a specific zoom level using the zoom argument.\nFor example, these maps show the same area around the UCL Jill Dando Institute with base maps at different zoom levels.\n\nChoosing the right zoom level is a matter of balancing the level of detail in the map and the clarity of the image. In the maps above, zoom levels less than 12 tend to have pixelated images because they do not contain enough detail, while zoom levels greater than 12 contain too much detail and so the information is hard to read. But if this map covered a smaller or larger area, a different zoom level might be better. In general, setting zoomin = 0 and not setting any value for the zoom argument – so that annotation_map_tile() chooses the zoom level automatically – will produce an acceptable map.\nannotation_map_tile() also gives us access to several different types of base map. The default style (seen in the maps above) is called ‘osm’ because it is the default style used by Open Street Map, the organisation that provides the map data. We can specify which style of base map we want using the type argument to annotation_map_tile()."
  },
  {
    "objectID": "05_your_second_crime_map/index.html#adding-more-layers",
    "href": "05_your_second_crime_map/index.html#adding-more-layers",
    "title": "5  Your second crime map",
    "section": "5.8 Adding more layers",
    "text": "5.8 Adding more layers\n\nAdding a base map underneath our density layer makes it much easier to understand where the highest densities of bike theft in Vancouver are. But our map could make it easier still to see where clusters of thefts occur. We could, for example, add the names of different neighbourhoods in the city, and show the city limits so that we can tell which areas have no crime because crimes in those areas are not included in our data.\nIn an earlier section I suggested we can think of ggplot charts, including maps, as being like stacks of pancakes – each function we use to amend the appearance of our chart is added to the top of the stack. So to add another layer to our map, we just add another geom_ function to our plot.\nThe City of Vancouver provides boundary data for city neighbourhoods on its website in GeoJSON format. This is a spatial data format, so it can be read by st_read(). We can then add the layer to our map using geom_sf() in the same way as for the point layer in our first map.\n\n# This is a version of the data saved from the City of Vancouver website, so \n# that this tutorial continues to work if the original data is ever removed\nnbhds <- st_read(\"https://mpjashby.github.io/crimemappingdata/vancouver_neighbourhoods.geojson\")\n\nReading layer `vancouver_neighbourhoods' from data source \n  `https://mpjashby.github.io/crimemappingdata/vancouver_neighbourhoods.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 22 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -123.2248 ymin: 49.19894 xmax: -123.0232 ymax: 49.29581\nGeodetic CRS:  WGS 84\n\n\n\nAt the same time, we can also add labels to the plot at the centre of each neighbourhood using the geom_sf_label() function. We use the aes() function to specify which column in the nbhds dataset we want to use for the label text. Normally, we would use the code aes(label = name) to do this, but in this case we want to wrap the labels so that they don’t overlap adjacent neighbourhoods, To do this we can use the str_wrap() from the stringr package (part of the tidyverse), so that our code instead becomes:\naes(label = str_wrap(name, width = 10))\nThe geom_sf_label() function in the map below uses quite a lot of arguments to control the appearance of the labels:\n\nalpha = 0.5 to make the label background semi-transparent so that we can see the density layer underneath it,\ncolour = \"seagreen3\" to slightly reduce the prominence of the label text to avoid distracting attention from the density layer,\nlineheight = 1 to reduce the gap between lines in each label,\nsize = 2.5 to slightly reduce the size of the label text,\nlabel.size = NA to remove the default border around the label background.\n\nPutting all this together, we get our final map:\n# Load packages\nlibrary(ggspatial)\nlibrary(sf)\nlibrary(sfhotspot)\nlibrary(tidyverse)\n\n# Load data\nbike_thefts <- read_csv(\"https://mpjashby.github.io/crimemappingdata/vancouver_thefts.csv.gz\") |> \n  janitor::clean_names() |> \n  st_as_sf(coords = c(\"x\", \"y\"), crs = \"EPSG:32610\") |> \n  filter(type == \"Theft of Bicycle\")\nnbhds <- st_read(\"https://mpjashby.github.io/crimemappingdata/vancouver_neighbourhoods.geojson\")\n\n# Create KDE layer\nbike_theft_density_clip <- bike_thefts |> \n  # Calculate density\n  hotspot_kde(bandwidth_adjust = 0.5) |> \n  # Transform the density data to use the same CRS as the neighbourhoods layer\n  st_transform(\"EPSG:4326\") |> \n  # Clip the density layer to the area for which we have data\n  st_intersection(nbhds)\n\n# Plot map\nggplot() +\n  # Add base map\n  annotation_map_tile(type = \"cartolight\", zoomin = 0) +\n  # Add density layer\n  geom_sf(\n    aes(fill = kde), \n    data = bike_theft_density_clip, \n    alpha = 0.75, \n    colour = NA\n  ) +\n  # Add neighbourhood boundaries (note `fill = NA` stops the neighbourhood\n  # shapes being filled with a colour, which would obscure the density layer\n  # underneath)\n  geom_sf(data = nbhds, colour = \"seagreen3\", fill = NA) +\n  # Add neighbourhood names\n  geom_sf_label(\n    aes(label = str_wrap(name, 10)), \n    data = nbhds, \n    alpha = 0.5,\n    colour = \"seagreen\", \n    lineheight = 1, \n    size = 2.5,\n    label.size = NA\n  ) +\n  # Set the colour scale\n  scale_fill_distiller(direction = 1) +\n  # Remove the axes, legend and other elements from the map that we don't need\n  theme_void()\n\n\nZoom: 12\n\n\n\n\n\nNow we can see that bike theft in Vancouver is heavily concentrated in a handful of neighbourhoods, particularly the Downtown and West End neighbourhoods. This map is much more useful than the first map that we produced in this tutorial showing only the point location of each crime, since in this latest map we can see not only the greatest concentrations of bike thefts but how they relate to the different areas of the city."
  },
  {
    "objectID": "05_your_second_crime_map/index.html#in-summary",
    "href": "05_your_second_crime_map/index.html#in-summary",
    "title": "5  Your second crime map",
    "section": "5.9 In summary",
    "text": "5.9 In summary\n\nIn this tutorial we have learned to produce a density map of crime. This type of map can be very useful in identifying where practitioners should focus efforts to respond to crime. For example, a map like this might help local police to decide where to send officers to carry out extra patrols, while a crime-prevention charity might decide to run events in particular areas to educate people on how best to protect their bikes.\n\nIn the next tutorial, we will learn how to improve this map further.\n\nYou can find out more about some of the things we have covered in this tutorial using these resources:\n\nUnderstand more about the history of trying to develop accurate map projections in this short video: Why all world maps are wrong.\nFind out more about making all sorts of charts (not just maps) with the ggplot2 package in the Data Visualisation chapter of R for Data Science by Hadley Wickham and Garrett Grolemund.\nLearn more about making maps using simple features in Chapter 1 of Spatial Data Science by Edzer Pebesma and Roger Bivand."
  },
  {
    "objectID": "06_map_context/index.html#introduction",
    "href": "06_map_context/index.html#introduction",
    "title": "6  Giving a map context",
    "section": "6.1 Introduction",
    "text": "6.1 Introduction\nIn this tutorial we will create this map of shootings in the Bronx borough of New York City in 2019. You’ll see that unlike the maps we have made so far, this map includes contextual elements such as a title, a legend and a scale bar.\n\n\n\n\n\nIn this tutorial we will learn to add important context to our maps using these elements."
  },
  {
    "objectID": "06_map_context/index.html#map-choices",
    "href": "06_map_context/index.html#map-choices",
    "title": "6  Giving a map context",
    "section": "6.2 Map choices",
    "text": "6.2 Map choices\nAmong the most important decisions you make when you are creating a map is what information to include and what to leave out. Watch this video to learn more about why this is important and how you can make those decisions.\n\nThe most important thing to remember when designing a map is to keep in mind the purpose that the map will be used for. Research on how people use maps has repeatedly shown that “the nature of the task or function to be performed by the map user is the single most important factor in determining how [someone] processes the information on the map”.\nAs explained in the video, when you create a crime map you should ask yourself:\n\nHow much does my audience know about this topic? so that you know how much information you should provide to help them understand it.\nHow well does my audience know this geographic area? so that you know what information to include to help people orient themselves, e.g. landmarks, main roads of natural features such as rivers.\nWhat will my audience use this map for? so that you can make sure everything on your map is relevant to that goal.\nIn what context will they be using this map? so that you can make the format of the map suitable to that context (e.g. if the map is going to be viewed by a large audience in a lecture hall, or by a police officer on their phone at night).\nWhat biases or opinions about this topic might my audience have? so that you can consider how the information (and your presentation of it) might influence those opinions or biases one way or another.\n\nMaps are powerful communication tools, which can sometimes knowingly or unknowingly mislead the reader. Watch this video to learn more about how maps can be misleading.\n\nWhenever you make a map, think about your own biases – are your own views on a topic likely to influence the results of your analysis? One way to test your own assumptions about a topic is to test them against other potential assumptions using an approach to crime analysis called hypothesis testing. To find out more about the hypothesis testing approach, read the paper Improving the explanatory content of analysis products using hypothesis testing"
  },
  {
    "objectID": "06_map_context/index.html#visual-hierarchy",
    "href": "06_map_context/index.html#visual-hierarchy",
    "title": "6  Giving a map context",
    "section": "6.3 Visual hierarchy",
    "text": "6.3 Visual hierarchy\nMaps are among the most complex types of data visualisation. Even if we have chosen wisely what to include and what to leave out, there is likely to be lots of information on our map. For all but the simplest maps, there is a risk of readers – especially those in a hurry – might be overwhelmed or mislead by competing pieces of information (such as different layers of data) on a map.\nTo help readers understand what parts of a map they should focus most of their attention on and which are of less importance, we can establish a visual hierarchy. Watch this video to learn more about visual hierarchies in mapping.\n\nWe have used some of the principles of visual hierarchy in the maps we have already made. For example, in the density map of bike thefts in Vancouver, we used strong colours to represent the data and shades of grey for the base map. This helped readers intuitively understand that they should focus most attention on the data."
  },
  {
    "objectID": "06_map_context/index.html#supporting-elements",
    "href": "06_map_context/index.html#supporting-elements",
    "title": "6  Giving a map context",
    "section": "6.4 Supporting elements",
    "text": "6.4 Supporting elements\nWe can often make our maps much more useful by adding supporting elements that explain the map content, give context or provide extra information. Watch this video to find out what elements you can add to your maps to make them more useful.\n\nWe will not need to include every supporting element mentioned in the video in all the maps we make. The visual hierarchy that you establish in your map by use of size, colour, etc. should make it clear which elements are most important. The data should always come first in the visual hierarchy, usually followed by the title and then the legend. Other elements should be lower down the hierarchy. In every map, the supporting elements should be designed so that they do not distract from the data.\n\n\n\nVisual hierarchy of elements in a crime map\n\n\nplace in hierarchy\nmap element\nhow often needed\n\n\n\n\n1st\ndata layers\nalways\n\n\n2nd\ntitle\nvirtually always\n\n\n3rd\nlegend\nusually\n\n\n4th\nbase map\nalmost always\n\n\n5th\nauthor and date\nvirtually always\n\n\n=6th\nscale\nsometimes\n\n\n=6th\nnorth arrow\nsometimes\n\n\n7th\ngrid\nrarely\n\n\n\n\n\nElements that are almost always needed on a crime map are not necessarily highest on the visual hierarchy. For example, the author name is virtually always needed but is relatively low on the visual hierarchy. This is because it is important information for readers who need it to judge the reliability of a map, or to get in touch to ask questions, but should not distract from the data for those readers who do not need it.\nBefore we start learning the code needed to add titles and legends to our maps, watch this video walk-though of the main steps."
  },
  {
    "objectID": "06_map_context/index.html#creating-and-storing-a-map",
    "href": "06_map_context/index.html#creating-and-storing-a-map",
    "title": "6  Giving a map context",
    "section": "6.5 Creating and storing a map",
    "text": "6.5 Creating and storing a map\nSince we will be adding various elements to a map in this tutorial, we will first create a map and save it as an R object. Any map or chart produced using the ggplot() function can be saved as an object using the assignment operator <-. Just as for the result of any other R function, if we save it to an object the result will not be printed to the screen, but we can easily see the plot by simply typing the object name in the R console.\n\n# Load packages\nlibrary(ggspatial)\nlibrary(sf)\nlibrary(sfhotspot)\nlibrary(tidyverse)\n\n# Load shootings data\nshootings <- read_csv(\"https://mpjashby.github.io/crimemappingdata/bronx_shootings.csv\") |> \n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = \"EPSG:4326\") |> \n  st_transform(\"EPSG:6538\")\n\nRows: 267 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl  (3): incident_key, longitude, latitude\nlgl  (1): murder\ndate (1): occur_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Load NYC police precincts data\nprecincts <- st_read(\"https://mpjashby.github.io/crimemappingdata/nyc_precincts.gpkg\") |> \n  janitor::clean_names() |> \n  # Filter just those precincts that are in the Bronx (40th to 52nd)\n  filter(precinct %in% 40:52) |> \n  st_transform(\"EPSG:6538\")\n\nReading layer `nyc_precincts' from data source \n  `https://mpjashby.github.io/crimemappingdata/nyc_precincts.gpkg' \n  using driver `GPKG'\nSimple feature collection with 77 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.25559 ymin: 40.49614 xmax: -73.70001 ymax: 40.91554\nGeodetic CRS:  WGS 84\n\n# Calculate KDE\nshootings_kde <- shootings |> \n  hotspot_kde(\n    grid = hotspot_grid(precincts, cell_size = 100), \n    bandwidth_adjust = 0.33\n  ) |> \n  st_intersection(precincts)\n\nBandwidth set to 2,890 metres automatically based on rule of thumb\n\n\n\nDone: [--------------------------------------------------------------------] .\nDone: [=======-------------------------------------------------------------] .\nDone: [========------------------------------------------------------------] .\nDone: [=========-----------------------------------------------------------] .\nDone: [==========----------------------------------------------------------] .\nDone: [===========---------------------------------------------------------] .\nDone: [============--------------------------------------------------------] .\nDone: [=============-------------------------------------------------------] .\nDone: [==============------------------------------------------------------] .\nDone: [===============-----------------------------------------------------] .\nDone: [================----------------------------------------------------] .\nDone: [=================---------------------------------------------------] .\nDone: [==================--------------------------------------------------] .\nDone: [===================-------------------------------------------------] .\nDone: [====================------------------------------------------------] .\nDone: [=====================-----------------------------------------------] .\nDone: [======================----------------------------------------------] .\nDone: [=======================---------------------------------------------] .\nDone: [========================--------------------------------------------] .\nDone: [=========================-------------------------------------------] .\nDone: [==========================------------------------------------------] .\nDone: [===========================-----------------------------------------] .\nDone: [============================----------------------------------------] .\nDone: [=============================---------------------------------------] .\nDone: [==============================--------------------------------------] .\nDone: [===============================-------------------------------------] .\nDone: [================================------------------------------------] .\nDone: [=================================-----------------------------------] .\nDone: [==================================----------------------------------] .\nDone: [===================================---------------------------------] .\nDone: [====================================--------------------------------] .\nDone: [=====================================-------------------------------] .\nDone: [======================================------------------------------] .\nDone: [=======================================-----------------------------] .\nDone: [========================================----------------------------] .\nDone: [=========================================---------------------------] .\nDone: [==========================================--------------------------] .\nDone: [===========================================-------------------------] .\nDone: [============================================------------------------] .\nDone: [=============================================-----------------------] .\nDone: [==============================================----------------------] .\nDone: [===============================================---------------------] .\nDone: [================================================--------------------] .\nDone: [=================================================-------------------] .\nDone: [==================================================------------------] .\nDone: [===================================================-----------------] .\nDone: [====================================================----------------] .\nDone: [=====================================================---------------] .\nDone: [======================================================--------------] .\nDone: [=======================================================-------------] .\nDone: [========================================================------------] .\nDone: [=========================================================-----------] .\nDone: [==========================================================----------] .\nDone: [===========================================================---------] .\nDone: [============================================================--------] .\nDone: [=============================================================-------] .\nDone: [==============================================================------] .\nDone: [===============================================================-----] .\nDone: [================================================================----] .\nDone: [=================================================================---] .\nDone: [==================================================================--] .\nDone: [===================================================================-] .\nDone: [====================================================================] .\n                                                                              \n\n\nWarning: attribute variables are assumed to be spatially constant throughout all\ngeometries\n\n# Create map object\nshootings_map <- ggplot() +\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  geom_sf(aes(fill = kde), data = shootings_kde, alpha = 0.75, colour = NA) +\n  geom_sf(data = precincts, colour = \"grey33\", fill = NA) +\n  geom_sf_label(\n    aes(label = scales::ordinal(precinct)), \n    data = precincts,\n    alpha = 0.5, \n    colour = \"grey33\", \n    size = 2.5, \n    label.size = NA\n  ) +\n  scale_fill_distiller(palette = \"PuBu\", direction = 1) +\n  theme_void() +\n  theme(legend.position = \"none\")\n\n# Display map\nshootings_map\n\n\n\n\nThe code used to create this map is very similar to the code we used in one of the previous tutorials to make a map of bike theft in Vancouver, although there are a few differences.\nLooking at the code above, we have used the grid argument to the hotspot_kde() function, specifying hotspot_grid(precincts, cell_size = 100). By default, hotspot_kde() calculates density estimates (KDE values) for every grid cell within the area covered by the crime data. This is fine when at least a few crimes have occurred in all the parts of the area for which we have data. But if crime is heavily concentrated in a few places and there are large areas with no crimes, the density layer will not cover the whole area for which we have data. In this case, it is important to extend the density layer manually to make it clear that the apparent low density of crime in some places is due to a genuine lack of crime there, rather than because we do not have data for those places.\nWe can do this by creating a grid of cells for which KDE values should be calculated, rather than letting hotspot_kde() do this automatically. In the code above, we have used the hotspot_grid() function to create a grid that covers all the precincts in the Bronx (the area we have data for), and then passed the resulting grid to the grid argument of hotspot_kde(). This ensures that KDE values are calculated for every part of the Bronx.\n\nThe only other difference from the Vancouver map is that we have used the ordinal() function from the scales package to convert the precinct numbers to ordinal numbers (1st, 2nd, 3rd, etc.) for the map labels. This is because police precincts in New York City are usually referred to using ordinal numbers (e.g. “the 1st Precinct” rather than “Precinct 1”) and it will be easier for people to read the map if it uses terms they are familiar with.\nThere are many other functions in the scales package that format numbers in different ways, including comma() to add thousands separators to numbers and dollar() to format numbers as values in dollars or other currencies. There is a full list of scales functions on the package website.\nWe now have a basic map of shootings in the Bronx. This map isn’t good enough on its own, but we can use it to learn how to add supporting elements to a map."
  },
  {
    "objectID": "06_map_context/index.html#titles",
    "href": "06_map_context/index.html#titles",
    "title": "6  Giving a map context",
    "section": "6.6 Titles",
    "text": "6.6 Titles\nA map title is one of the most important ways to add context to a map. Titles can either be descriptive or declarative. Descriptive titles simply state what data are shown on the map. For example, we might give our map the title “Shootings in the Bronx, 2019”. Declarative titles, on the other hand, state what you think the main conclusion should be that readers remember about the map. For example, we might use the title “Shootings are focused in the South Bronx”.\nDeclarative titles are usually more useful than descriptive titles because they help the reader to interpret the map. But writing a good declarative title is harder than writing a descriptive title, because it requires you to think about what is the main point that you want to make with the map. To help you come up with a good declarative title, you might want to try several different titles so that you can choose the one that communicates your message most clearly.\nWe can add a title to our map using the labs() (short for ‘labels’) function from the ggplot2 package. We can use labs() to add labels to various different parts of a map or plot, but for now we will just use the argument title to set the title.\n\nshootings_map + \n  labs(title = \"Shootings are focused in the South Bronx\")\n\n\n\n\nSometimes our preferred title might be too long to fit on a map. In this case, we can break the title across two or more lines. We can do this manually by adding the characters \\n (the character code for a new line) at the point where we want the text to start a new line. Alternatively, we can use the str_wrap() function from the stringr package to wrap the text automatically into lines of a given maximum length (specified using the wrap argument).\nWhen you use a declarative title for your map, it is often useful to provide a subtitle containing descriptive information. Adding a subtitle is very easy using the subtitle argument to the labs() function. Use the code above as a template to add a subtitle to your map explaining that the map shows fatal and non-fatal shootings in 2019.\n\nshootings_map + \n  labs(\n    title = \"Shootings are focused in the South Bronx\",\n    subtitle = \"Fatal and non-fatal shootings recorded by NYC Police, 2019\"\n  )\n\n\n\n\n\n6.6.1 Using captions to add author and other information\nThe labs() function has another argument that we can use to add text to our map for context. The caption argument is used to add information such as the author, date and source of the data to a map or chart. We can put any information we like into the caption, using str_wrap() or the new-line character \\n if necessary to stop the text overflowing the map.\n\nshootings_map + \n  labs(\n    title = \"Shootings are focused in the South Bronx\",\n    subtitle = \"Fatal and non-fatal shootings recorded by NYC Police, 2019\",\n    caption = str_glue(\n      \"Author: Joe Bloggs, Date produced: {lubridate::today()},\\n\",\n      \"Data: https://data.cityofnewyork.us/d/833y-fsy8\\n\",\n      \"Map data from OpenStreetMap\"\n    )\n  )\n\n\n\n\nThis code uses the str_glue() function from the stringr package to incorporate some automatically updated information (in this case, the current date) into the caption. str_glue() glues together any number of character strings separated by commas – in this case, the code includes two strings so that the lines of code do not become too long to easily read.\nstr_glue() can also include the values of R objects and the results of R functions that are placed inside braces {}. So the code {lubridate::today()} runs the function today() from the lubridate package and glues the result (the current date) into the text. If we had already loaded the lubridate library we could have just used the code {today()}, but since we do not need any other functions from lubridate for this analysis, we instead do not load the package but call the function by specifying which package it comes from using the :: operator as in the previous tutorial.\n\nWhen you use data to make maps, the data provider will often require you to acknowledge the source of that data. This is a legal requirement so it is important that you do this when required.\nThe base maps we use in this course use data from OpenStreetMap, which requires people using its data to acknowledge that they have done so. The easiest way to do this is to add the text “Map data from OpenStreetMap” to the caption of your maps if they use base maps from OpenStreetMap.\n\n\n\n6.6.2 Changing the appearance of titles and captions\nWe have added a title, subtitle and caption to our map, but you might not be happy with their appearance. You might want, for example, to move the caption down the visual hierarchy by making the text smaller and/or a lighter colour, or add some space between the subtitle and the map itself.\nWe can exercise almost complete control over the supporting elements of maps or charts made with ggplot() using the theme() function. One important thing to remember about theme() is that it only controls the non-data elements of a map – nothing you do with the theme() function will have any effect on the data elements of a map (in this case, the layer showing the density of shootings). To change the appearance of data layers within ggplot() maps, use the geom_, and scale_ families of functions as we have learned in previous tutorials.\nThe theme() function has a lot of potential arguments. If you need help using the theme() function (or any function in R) you can view a manual page (including a list of arguments) for the function by:\n\ntyping a question mark followed by the function name without parentheses (e.g. ?theme) into the R console,\ntyping the function name without parentheses into the search box in the Help panel in RStudio, or\nclicking on the function name anywhere in your R code to place the cursor on the function name, then pressing F1 on your keyboard.\n\nTry opening the manual page for theme() now to see the list of possible arguments it can take. Fortunately, we will not need most of these arguments most of the time – ggplot() has default values built in for every value that can be changed using theme(), and these defaults will be reasonable in almost all cases.\nTo reduce the visual prominence of the map caption, we can change the value of the plot.caption argument to theme(). Since the caption is a text element (rather than a polygon, line, etc.), we can use the helper function element_text() to do this. The following code changes the colour of the caption text to a lighter grey and makes the text smaller relative to the default using the helper function rel() (for relative sizing) – 0.7 means the text will be 70% as big as it would have been by default.\n\nshootings_map +\n  labs(\n    title = \"Shootings are focused in the South Bronx\",\n    subtitle = \"Fatal and non-fatal shootings recorded by NYC Police, 2019\",\n    caption = str_glue(\n      \"Author: Joe Bloggs, Date produced: {lubridate::today()},\\n\",\n      \"Data: https://data.cityofnewyork.us/d/833y-fsy8\\n\",\n      \"Map data from OpenStreetMap\"\n    )\n  ) +\n  theme(\n    plot.caption = element_text(colour = \"grey67\", size = rel(0.7))\n  )\n\n\n\n\nThe helper function element_text() has arguments to control the appearance of text in different ways. As well as colour (or color, either is fine) and size, there are:\n\nfamily controls the font used, e.g. Times New Roman or Helvetica,\nface controls the style of the font, i.e. ‘plain’, ‘italic’, ‘bold’ or ‘bold.italic’,\nhjust controls the horizontal justification of the text, where 0 means left aligned, 0.5 means centred and 1 means right aligned,\nvjust controls the vertical justification, and\nangle controls the angle (in degrees) of the text (0 means horizontal),\nlineheight controls the space between lines if you have created a value that has more than one line (e.g. using \\n or str_wrap()).\n\nThe margin argument controls the space around the text. It is easiest to specify the value of margin using the helper function margin() designed for that purpose. You specify the top, right, bottom and left margin separately in that order – to remember the order, think ‘trouble’.\nThe following code changes the margin around the map subtitle. Change this code so that it also makes the subtitle 80% of the default size and changes the caption so that it is left aligned.\nNow that we have finished setting the text elements for our map, we can save it as a new object that we can use as the basis for the other objects we want to add.\n\nshootings_map_titled <- shootings_map +\n  labs(\n    title = \"Shootings are focused in the South Bronx\",\n    subtitle = \"Fatal and non-fatal shootings recorded by NYC Police, 2019\",\n    caption = str_glue(\n      \"Author: Joe Bloggs, Date produced: {lubridate::today()},\\n\",\n      \"Data: https://data.cityofnewyork.us/d/833y-fsy8\\n\",\n      \"Map data from OpenStreetMap\"\n    )\n  ) +\n  theme(\n    # Make the plot subtitle smaller and adjust the margin around it\n    plot.subtitle = element_text(size = rel(0.8), margin = margin(3, 0, 6, 0)),\n    # Make the legend caption smaller, left-aligned and a lighter shade of grey\n    plot.caption = element_text(colour = \"grey67\", size = rel(0.7), hjust = 0)\n  )"
  },
  {
    "objectID": "06_map_context/index.html#legends",
    "href": "06_map_context/index.html#legends",
    "title": "6  Giving a map context",
    "section": "6.7 Legends",
    "text": "6.7 Legends\nLegends are important for all but the simplest crime maps because they help readers to interpret the points, lines and polygons used to represent data on a particular map. Except for point maps containing only a small number of crimes (such as the map of homicide in downtown Atlanta that we produced in the first tutorial), crime maps will almost always need a legend to help users interpret them.\nProducing a legend manually could be quite complicated, but fortunately ggplot() produces legends automatically. The reason the maps we have produced up to now haven’t included legends is that we have been suppressing the legends using the argument legend.position = \"none\" to the theme() function – look back at the code on the page ‘Creating and storing a map’ in this tutorial to see this code on the final line of the stack of functions added to ggplot().\nggplot() will add a legend to a map or chart whenever one or more layers of data are represented using an aesthetic property such as size, shape, colour or fill. In our current map, the density of shootings is represented using the fill colour of the polygons produced by the hotspot_kde() function, with darker colours representing more shootings.\nTo reveal the legend automatically generated, we can add another call to the theme() function to our existing ggplot() object. This overrides the previous code that set the legend position to none, instead placing the legend on the right-hand side of the plot. We only need to do this because we previously suppressed the legend – if we had not suppressed it, the legend would have appeared automatically.\n\nshootings_map_titled +\n  theme(\n    # Position the legend on the right-hand side of the plot\n    legend.position = \"right\"\n  )\n\n\n\n\nOur map now has a legend, but we may want to adjust its appearance by:\n\nchanging the default legend title from “kde” to something more meaningful,\nmoving the legend down the visual hierarchy by making it smaller (at the moment it is almost as visually prominent as the data),\nremoving the potentially confusing raw density values.\n\nWe can change the default legend title by once again using the labs() function. Since we want to change the title of the legend, you might reasonably think that we would do this using something like labs(legend = \"density\") but unfortunately that code would do nothing at all. Instead, we have to set the legend title using the aesthetic (colour, size, shape, etc.) that the legend represents. This makes it possible to specify multiple titles if there are separate legends for different layers that use different aesthetics. For example if a map used lines of different colours to show streets of different types and filled polygons to show the density of crime, it would be possible to have separate legends explaining each aesthetic. In this case, we’ve specified that the kde column in the data should control the fill aesthetic, so we can set the title for that legend using fill = \"title we want\".\n\nshootings_map_titled +\n  labs(fill = \"kernel density\\nof shootings\") +\n  theme(\n    # Position the legend on the right-hand side of the plot\n    legend.position = \"right\"\n  )\n\n\n\n\nTo make the legend smaller, we can use theme() in the same way as we did to change the appearance of the caption. We use the legend.title argument to format the legend title and the legend.text argument to format the labels for each value in the legend.\nWe will also make the colour bar in the legend (called the key by ggplot()) slightly smaller using the legend.key.width argument. To do this we will use the helper function unit(), which allows us to specify the size using any of several common units. In this case, we will specify the key size in lines (1 line = the height of one line of text) so that it is relative to the text size we have chosen.\nAt the same time, we will reduce the size of the legend title and the legend text (the numbers next to the colour bar), using the legend.text and legend.title arguments together with the the helper function element_text(). In both cases, we will set the text size relative to the default text size using the rel() helper function.\n\nshootings_map_titled +\n  labs(fill = \"kernel density\\nof shootings\") +\n  theme(\n    # Make the legend colour bar smaller\n    legend.key.width = unit(0.8, \"lines\"),\n    # Position the legend on the right-hand side of the plot\n    legend.position = \"right\",\n    # Make the legend text smaller\n    legend.text = element_text(size = rel(0.7)),\n    legend.title = element_text(size = rel(0.8))\n  )\n\n\n\n\nFinally, we want to remove the raw density values, since these are difficult to interpret and might distract readers from the key message that darker colours on the map represent higher densities of shootings.\nBy default, ggplot() sets the label for each legend key based on the data. To specify our own labels, we can use the labels argument to the scale_fill_distiller() function that we previously used to set the colour scheme of the density layer on the map.\nWhen we set colour bar labels manually, we have to also specify where on the colour bar we want those labels to appear. We do this using the breaks argument to scale_fill_distiller(), making sure the number of values we supply to the breaks argument is the same as the number of labels we’ve given to the labels argument (otherwise R will produce an error).\nIn this case, we want to add two labels (“higher” and “lower”), one at either end of the colour bar. We could look at kde column of the shootings_kde object to find the minimum and maximum values, but that would introduce the risk of us accidentally entering the wrong values. Instead, we can use the pull() function to extract the kde column from the shootings_kde dataset and then use the range() function to find the minimum and maximum values. Putting this together, we get breaks = range(pull(shootings_kde, \"kde\")).\nNow that we have finished formatting the legend, we can again store the map as an object that we can build on further.\n\nshootings_map_legend <- shootings_map_titled +\n  scale_fill_distiller(\n    palette = \"PuBu\", \n    direction = 1, \n    # Specify label positions as the minimum and maximum KDE values\n    breaks = range(pull(shootings_kde, \"kde\")), \n    labels = c(\"lower\", \"higher\")\n  ) +\n  labs(fill = \"kernel density\\nof shootings\") +\n  theme(\n    # Make the legend colour bar smaller\n    legend.key.width = unit(0.8, \"lines\"),\n    # Position the legend on the right-hand side of the plot\n    legend.position = \"right\",\n    # Make the legend text smaller\n    legend.text = element_text(size = rel(0.7)),\n    legend.title = element_text(size = rel(0.8))\n  )\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale."
  },
  {
    "objectID": "06_map_context/index.html#scales-and-north-arrows",
    "href": "06_map_context/index.html#scales-and-north-arrows",
    "title": "6  Giving a map context",
    "section": "6.8 Scales and north arrows",
    "text": "6.8 Scales and north arrows\nThe final elements we can add to our map are a scale bar and a north arrow, which can both be added using functions from the ggspatial package.\n\n6.8.1 Scale bars\nTo add a scale bar, we can add a call to the annotation_scale() function to our existing ggplot() object.\n\nshootings_map_legend +\n  annotation_scale()\n\n\n\n\nThe default scale bar is a little too visually dominant for the low place it should have in the visual hierarchy of our map, and the default placement in the bottom-left corner happens to overlap with the highest density of shootings. We can change the scale bar using arguments to the annotation_scale() function:\n\nwidth_hint = 1/5 changes the (approximate) proportion of the map width across which the scale bar stretches,\nstyle = \"ticks\" changes the style of the scale bar to the less visually prominent line-and-tick-marks style, and\nlocation = \"br\" moves the scale bar to the bottom-right corner of the map.\n\n\nshootings_map_legend +\n  annotation_scale(width_hint = 1/5, style = \"ticks\", location = \"br\")\n\n\n\n\n\n\n6.8.2 North arrows\nWe can add a north arrow using the annotation_north_arrow() function. The default arrow is too obtrusive to fit its position in the visual hierarchy, so we will change its appearance using the arguments:\n\nlocation = \"tr\" to move the north arrow to the top-right corner, since we have put the scale bar in the bottom-right where the north arrow would be placed by default,\nheight = unit(1.5, \"lines\") to make the arrow smaller, and\nstyle = north_arrow_minimal(text_size = 8) to use a smaller style of arrow, at the same time reducing the font size (measured in points) of the N symbol.\n\n\nshootings_map_legend +\n  annotation_scale(width_hint = 1/5, style = \"ticks\", location = \"br\") +\n  annotation_north_arrow(\n    location = \"tr\", \n    height = unit(1.5, \"lines\"), \n    style = north_arrow_minimal(text_size = 8)\n  )"
  },
  {
    "objectID": "06_map_context/index.html#saving-maps",
    "href": "06_map_context/index.html#saving-maps",
    "title": "6  Giving a map context",
    "section": "6.9 Saving maps",
    "text": "6.9 Saving maps\nOnce you have a complete map, it is often useful to save it as an image file so that you can share it with others or embed it into a report or presentation. You can save plots created with ggplot() using the ggsave() function.\nBefore we do that, lets create a final map that includes a base map as well as some supporting elements. We won’t include a north arrow because north is at the top of the map and it’s unlikely anyone will be using this map for navigation. We will include a scale bar so that people looking at the map can see the approximate size of shooting hotspots. Remember we have already loaded the necessary packages, as well as data stored in the shootings, precincts and shootings_kde objects.\n\nThere is usually no need to save the map into several different objects (e.g.  shootings_map_titled or shootings_map_legend) as we have done in this tutorial. We have only done that here so you could learn about the different contextual elements one by one.\nIt is usually much better to create a whole ggplot() stack in one go, since it is easier to keep track of all the elements that way. In the code below all the elements have been combined into a single ggplot() stack.\n\n\nshootings_map_final <- ggplot() +\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  geom_sf(aes(fill = kde), data = shootings_kde, alpha = 0.75, colour = NA) +\n  geom_sf(data = precincts, colour = \"grey33\", fill = NA) +\n  geom_sf_label(\n    aes(label = scales::ordinal(precinct)), \n    data = precincts,\n    alpha = 0.5, \n    colour = \"grey33\", \n    size = 2.5, \n    label.size = NA\n  ) +\n  annotation_scale(width_hint = 1/5, style = \"ticks\", location = \"br\") +\n  scale_fill_distiller(\n    palette = \"PuBu\",\n    breaks = range(pull(shootings_kde, \"kde\")), \n    labels = c(\"lower\", \"higher\"),\n    direction = 1\n  ) +\n  labs(\n    title = \"Shootings are focused in the South Bronx\",\n    subtitle = \"Fatal and non-fatal shootings recorded by NYC Police, 2019\",\n    caption = str_glue(\n      \"Author: Joe Bloggs, Date produced: {lubridate::today()},\\n\",\n      \"Data: https://data.cityofnewyork.us/d/833y-fsy8\\n\",\n      \"Map data from OpenStreetMap\"\n    ),\n    fill = \"kernel density\\nof shootings\"\n  ) +\n  theme_void() +\n  theme(\n    legend.key.width = unit(0.8, \"lines\"),\n    legend.text = element_text(size = rel(0.7)),\n    legend.title = element_text(size = rel(0.8)),\n    plot.subtitle = element_text(size = rel(0.8), margin = margin(3, 0, 6, 0)),\n    plot.caption = element_text(colour = \"grey67\", size = rel(0.7), hjust = 0)\n  )\n\n# Display map\nshootings_map_final\n\n\n\n\nggsave() can create image files in many different formats, including PNG, JPEG and PDF. ggsave() will determine which type of file to create according to the file extension of the file name that you specify. So ggsave(\"bronx_shootings_2019.pdf\", plot = shootings_map_legend) produces a PDF file, while ggsave(\"bronx_shootings_2019.jpg\", plot = shootings_map_legend) produces a JPEG image file.\nYou can specify the size of the image that will be saved using the height and width arguments. Note that for historical reasons these values are in inches by default, but you can change this to either centimetres (using units = \"cm\"), millimetres (using units = \"mm\") or pixels (using units = \"px\").\nTo share our map with others, lets save it as an A4-size PDF.\nggsave(\n  \"bronx_shootings_2019.pdf\", \n  plot = shootings_map_final, \n  width = 210,\n  height = 297,\n  units = \"mm\"\n)\nWe can now use share this file by email, upload it to a website or embed it in another document."
  },
  {
    "objectID": "06_map_context/index.html#in-summary",
    "href": "06_map_context/index.html#in-summary",
    "title": "6  Giving a map context",
    "section": "6.10 In summary",
    "text": "6.10 In summary\n\nIn this tutorial we have learned about the importance of understanding the purpose for which people will use a map when making decisions about map design. We have also learned about how establishing a visual hierarchy on our map can help steer readers towards the most-important elements and how to add titles, legends and scale bars to maps in R.\n\n\nYou can find out more about the topics we have covered in this tutorial:\n\nFor a short summary of research into how people read maps and what that tells us about how to design a map, see Cartography, visual perception and cognitive psychology by Amy Griffin.\nFor a more-detailed explanation of how visual hierarchy can be applied to maps, see Visual Hierarchy and Layout.\nFor more examples of how maps can mislead, read How to lie with maps by Alan Smith.\n\n\n\n\n\n\nXKCD.com comic ‘Geography’ licensed under the Creative Commons Attribution-NonCommercial license."
  }
]