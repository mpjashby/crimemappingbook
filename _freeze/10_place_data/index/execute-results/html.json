{
  "hash": "573c9e1e12cdc493fd627022a2fef0de",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexecute: \n  freeze: auto\n---\n\n\n\n\n\n# Using data about places {#sec-place-data}\n\n**Learn how to find and use extra data about places to improve your maps, including open data and data from OpenStreetMap**\n\n::: {.callout-important}\nThis chapter has not yet been updated for 2025, so some material is out of date. Check back for an update in mid-February 2025.\n:::\n\n\n\n\n\n\n\n\n\n\n## Introduction\n\nThe purpose of most crime maps is to help people make decisions, be they \nprofessionals working out how best to respond to crime problems or citizens\nholding local leaders to account. We can make it easier for people to make \ndecisions by putting crime data into a relevant context. We have already started \nto do this by adding base maps, titles, legends and so on to our maps.\n\nSince crime is concentrated in a few places, readers of our crime maps will \noften be interested in understanding what features of the environment are \nrelated to specific concentrations of crime in particular places. Where patterns \nof crime are related to particular facilities -- such as late-night violence \nbeing driven by the presence of bars selling alcohol -- it can be useful to \nhighlight specific features on our maps.\n\nAs an example, imagine you are the manager responsible for security on the metro\nnetwork in Medellin, Colombia. There are several mountains within Medellin, so \nthe city metro network consists of both railway lines in the valley and cable \ncars up the mountains. The security manager for the metro company will certainly \nanalyse violence on the company's stations and vehicles, but may also be \ninterested in which stations are in neighbourhoods that themselves have high \nlevels of violence.\n\nTo help with this, you might produce a map showing the density of homicides \nrecorded by local police.\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n<p class=\"full-width-image\"><img src=\"images/medellin_homicides_map1.jpg\" alt=\"Map of homicides in Medellin from 2010 to 2019\" style=\"max-height: 600px;\"></p>\n\nThis is an acceptable crime map: it shows the data in a reasonable way, places \nthe data layer at the top of the visual hierarchy and provides suitable context \nin the title, legend etc. But it is a much less useful map than it could be \nbecause it doesn't show where the metro stations are and this information is not\nincluded in the base map. A much better map would add extra layers of data \nshowing the metro stations and the line connecting them.\n\n<p class=\"full-width-image\"><img src=\"images/medellin_homicides_map2.jpg\" alt=\"Map of homicides in Medellin from 2010 to 2019 with metro stations and lines highlighted\" style=\"max-height: 600px;\"></p>\n\nFrom this second map, it is much easier to see that Parque Berrío and Prado \nstations are closest to an area with relatively high numbers of homicides.\n\nIn this tutorial we will learn how to find relevant data about places and add\nextra layers to our maps to help readers understand the context within which\ncrimes occur. \n\nTo get started, watch this video that walks through the code needed to download \ndata from OpenStreetMap for use on our maps.\n\n\n\n\n{{< video https://youtu.be/kcpiH6dDWLE >}}\n\n\n\n\n\n\n\n\n## Loading CSV data\n\nThroughout this tutorial, we will use homicides in the Colombian city of \nMedellin as an example. Data on the locations of homicides in Medellin from 2010 \nto 2019 is available at \n`https://mpjashby.github.io/crimemappingdata/medellin_homicides.csv`. \n\nIn previous tutorials, we have used the `read_csv()` function from the `readr`\npackage to load data from CSV files. The `read_csv()` function assumes that (as\nthe name 'comma-separated values' suggests) the columns in a CSV file are\nseparated by commas (`,`). But not all countries use commas as the column \nseparator in CSV files: some countries use semi-colons (`;`) instead. This is\nusually because those countries also use commas instead of periods as the \ndecimal separator inside numbers (so that the number three-point-one-four is\nwritten `3,14` instead of `3.14` as in English). If commas are used as decimal \nseparators in numbers in a file, commas cannot also be used to separate columns \nfrom one another -- otherwise there would be no way to know if a comma \nrepresented the decimal mark in a number or the boundary between two columns.\n\nIf we try to load a CSV file that uses semi-colon separators using the \n`read_csv()` function, all the data on each row will be loaded as a single\ncolumn:\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nmedellin_homicides <- read_csv(\"https://mpjashby.github.io/crimemappingdata/medellin_homicides.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 9360 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): fecha_hecho;longitud;latitud;sexo;edad;modalidad\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(medellin_homicides)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 1\n  `fecha_hecho;longitud;latitud;sexo;edad;modalidad`                            \n  <chr>                                                                         \n1 2019-04-23T12:30:00Z;-75,56985400000;6,25722555000;Mujer;50;Ahorcamiento o es…\n2 2019-05-12T00:51:00Z;-75,61036800000;6,22280611000;Hombre;24;Arma de fuego    \n3 2019-05-12T02:36:00Z;-75,62039100000;6,26238217000;Hombre;34;Arma de fuego    \n4 2019-05-12T03:03:00Z;-75,56176640000;6,26958878000;Hombre;20;Arma de fuego    \n5 2019-05-12T22:40:00Z;-75,53268500000;6,23627692000;Hombre;34;Arma de fuego    \n6 2019-05-12T19:30:00Z;-75,64195830000;6,19619536500;Hombre;25;Arma de fuego    \n```\n\n\n:::\n:::\n\n\n\n\nThis is obviously not what we want, so we need to use a different function to\nload this data. Fortunately, the `readr` package has another function that can\nhandle CSV files created using the conventions of countries that use semi colons\nto separate columns: `read_csv2()`.\n\nHow should you know when to use `read_csv2()` rather than `read_csv()`? If you\ndon't know whether a file uses commas or semi colons to separate columns, the \neasiest thing is probably to use `read_csv()` first. Now load the file and\nuse `head()` to look at the first few rows: if you see all the data has\nappeared in a single column that contains several semi colons, then you'll know\nto change your code to use `read_csv2()` instead.\n\nFor this dataset, if you load it with `read_csv2()` you should find that the\nstructure of the data is more as you'd expect it to be.\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nmedellin_homicides <- read_csv2(\"https://mpjashby.github.io/crimemappingdata/medellin_homicides.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 9360 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (2): sexo, modalidad\ndbl  (3): longitud, latitud, edad\ndttm (1): fecha_hecho\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(medellin_homicides)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  fecha_hecho         longitud latitud sexo    edad modalidad                   \n  <dttm>                 <dbl>   <dbl> <chr>  <dbl> <chr>                       \n1 2019-04-23 12:30:00    -75.6    6.26 Mujer     50 Ahorcamiento o estrangulami…\n2 2019-05-12 00:51:00    -75.6    6.22 Hombre    24 Arma de fuego               \n3 2019-05-12 02:36:00    -75.6    6.26 Hombre    34 Arma de fuego               \n4 2019-05-12 03:03:00    -75.6    6.27 Hombre    20 Arma de fuego               \n5 2019-05-12 22:40:00    -75.5    6.24 Hombre    34 Arma de fuego               \n6 2019-05-12 19:30:00    -75.6    6.20 Hombre    25 Arma de fuego               \n```\n\n\n:::\n:::\n\n\n\n\nIn the rest of this tutorial we will use data from different sources to better\nunderstand clusters of homicides in the La Candelaria neighbourhood of downtown \nMedellin. \n\n<!--\n\nUse this map (created with the `leaflet` package) to look around the\nLa Candelaria neighbourhood -- the markers show the locations of the metro\nstations inside the neighbourhood boundary.\n\n-->\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n### Check your understanding {.tutorial}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquiz(\n  caption = \"\",\n  \n  question(\n    \"Which function should you use to load a CSV file of crime locations that uses semi-colons to separate the columns?\",\n    answer(\"`read_csv2()` from the `readr` package\", correct = TRUE),\n    answer(\n      \"`read_csv()` from the `readr` package\",\n      message = \"`read_csv()` is used to load CSV files that use commas to separate columns.\"\n    ),\n    answer(\n      \"`read.csv2()` from the `base` package\",\n      message = \"While the `read.csv2()` function from the `base` package will load CSV files that use semi-colons to separate columns, it is better to use a function from the `readr` package so that the loaded data will be in a tibble rather than a data frame, and so that text values will not be silently changed to categorical values.\"\n    ),\n    answer(\n      \"`read_sf()` or `st_read()` from the `sf` package\",\n      message = \"CSV is not a spatial file format (even when it contains columns that represent co-ordinates), so it is best not to load them with functions from the `sf` package (which expect to handle spatial file formats). While `read_sf()` and `st_read()` can open CSV files, both functions assume all the columns contain text values, meaning you then have to use another function to convert column values to numbers, dates, etc.\"\n    ),\n    correct = random_praise(),\n    allow_retry = TRUE,\n    random_answer_order = TRUE\n  )\n  \n)\n```\n:::\n\n\n\n\n\n## Finding data\n\nIf you are producing crime maps on behalf of a particular organisation such as\na police agency or a body responsible for managing a place, it is likely that\nthey will hold spatial data that is relevant to the local area. For example, \nmany city governments will hold records of local businesses. It will sometimes\nbe necessary to track down which department or individual holds this data, and\nit may also be necessary to convert data into formats that are useful for \nspatial analysis.\n\nSome organisations may also have agreements to share data with others. For \nexample, both universities and public agencies such as police forces in the\nUnited Kingdom have agreements with the national mapping agency Ordnance Survey\nto share a wide variety of spatial data. If you are producing maps on behalf of\nan organisation, it will often be useful to ask what data they hold that might\nbe relevant, or ask for a specific dataset you think would help improve a map.\n\n\n### Open data\n\n*Open data* is data that is released by organisations or individuals that can be\nfreely used by others. Organisations such as local governments increasingly\nrelease data about their areas as open data -- almost all of the data we have\nused so far in this course is open data released by different local and national\ngovernments.\n\nOpen data is extremely useful because you can skip the often lengthy and painful\nprocess of getting access to data and wrangling it into a format you can use. \nThis means you can move on much more quickly to analysing data, reaching\nconclusions and making decisions. Watch this video to find out more about the\nvalue of open data.\n\n\n\n\n{{< video https://youtu.be/bwX5MAZ6zKI >}}\n\n\n\n\n\n\nOpen data is published in a wide variety of formats and distributed in different\nways. Some data might only be distributed by an organisation sending you a DVD\nor memory stick. Most of the time, however, data will be released online.\n\nMany cities (especially but not only in developed countries) now maintain \nopen-data websites that act as a repository for all their open data. For \nexample, the City of Bristol in England publishes the \n[Open Data Bristol website](https://opendata.bristol.gov.uk/pages/homepage/).\nAnyone can use this website to download data on everything from population\nestimates to politicians' expenses. Many of these datasets can be useful for\ncrime mapping. For example, you can download the locations of\n[CCTV cameras](https://opendata.bristol.gov.uk/explore/dataset/council-cctv-cameras/information/)\n(useful in criminal investigations),\n[street lights](https://opendata.bristol.gov.uk/explore/dataset/streetlights-and-street-furniture/information/)\n(relevant to designing out crime) and the [catchment areas of secondary schools](https://opendata.bristol.gov.uk/explore/dataset/secondary-school-areas-of-first-priority/information/)\n(helpful if a crime-prevention strategy includes visits to schools).\n\nDifferent local governments may use different terms for the same types of \ninformation, so it sometimes takes some trial and error to find if a particular\ndataset is available. Some data might also be held by organisations other than\nthe main local government agency for a particular place. For example, data on\nthe locations of electricity substations (useful if you are trying to prevent\nmetal thefts from infrastructure networks) might be held by a power company. All\nthis means that tracking down a particular dataset might require some detective\nwork.\n\nTo try to make this process easier, some countries have established national\nopen-data portals such as \n[Open Data in Canada](https://open.canada.ca/en/open-data/), \n[Open Government India](https://data.gov.in/),\n[data.gov.uk in the United Kingdom](https://data.gov.uk/) \nand [data.gov in the United States](https://www.data.gov/). There are also\ninternational repositories such as the \n[African Development Bank Data Portal](https://dataportal.opendataforafrica.org/),\n[openAfrica](https://africaopendata.org/), the \n[Open Data Network](http://www.opendatanetwork.com/) and \n[Data Portals](https://dataportals.org/), which seeks to list all the open data\nportals run by different governments and other organisations.\n\n\n### Citing data\n\nOrganisations that provide data often do so on condition that users of the data\nfollow certain rules. For example, you can use data on the Open Data Bristol \nwebsite as long as you follow the conditions of the \n[Open Government Licence](http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/).\nThe most-common requirement of an open-data licence is that anyone using the \ndata acknowledges the data source in any maps, reports or other outputs they \nproduce. In the case of the Open Government Licence, users of the data are \nrequired to add a declaration to any outputs declaring:\n\n> Contains public sector information licensed under the Open Government Licence\n> v3.0.\n\nComplying with open-data licences is a legal requirement, so it is important to\nmake sure you understand what obligations you are accepting when you use a \nparticular dataset. You can typically find the conditions for using a dataset on\nthe website that you download the data from. If you are required to add an\nattribution statement to your maps, a good place to do this is by adding it to\nany other information you place in the `caption` argument of the `labs()` \nfunction in a `ggplot()` stack.\n\n\n### Check your understanding {.tutorial}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquiz(\n  caption = \"\",\n  \n  question(\n    \"Which one of these statements about open data is true?\",\n    answer(\"We can use open data for any purpose as long as we comply with the requirements of the licence the data is released under.\", correct = TRUE),\n    answer(\n      \"We can use open data for any purpose -- there is no need to acknowledge the source of the data.\",\n      message = \"While we can often use open data for almost any purpose, it is important to comply with the requirements of the licence the data was released under. Most open-data licences include a requriement to acknowledge the source of the data.\"\n    ),\n    answer(\n      \"We can use open data, but only for non-commercial purposes.\",\n      message = \"Most open data licences allow us to use data for both commercial and non-commercial purposes, as long as we comply with the other requirements of the licence -- most often this includes a requriement to acknowledge the source of the data.\"\n    ),\n    answer(\n      \"We can download open data but we cannot use it for any project that will be published online.\",\n      message = \"Organisations usually publish open data to make it easier for other organisations and individuals to use that data to make products and analyse local issues. It would be extremely unusual for an open-data licence to stop people from using the data in a project that was going to be published online.\"\n    ),\n    correct = random_praise(),\n    allow_retry = TRUE,\n    random_answer_order = TRUE\n  )\n  \n)\n```\n:::\n\n\n\n\n\n\n## Shapefiles\n\nIn this course we have used spatial data provided in different formats including\ngeopackages (`.gpkg`) and geoJSON (`.geojson`) files, as well as creating \nspatial objects from tabular data in formats like CSV and Excel files. But there \nis one spatial-data format that we haven't yet learned to use: the *shapefile*.\n\nThe shapefile format was created by Esri, the company that makes the ArcGIS \nsuite of mapping software. It was perhaps the first spatial format that could be\nread by a wide variety of mapping software, which meant that lots of providers\nof spatial data began to provide data in shapefile format. Shapefiles are \nlimited in various ways that mean they are unlikely to be a good choice for \nstoring your own data, but it is important to know how to use them because many\nspatial datasets are still provided as shapefiles for historical reasons.\n\nOne of the complications of using shapefiles (and why they're not a good choice\nfor storing your own data) is that different parts of the data are stored in \nseparate files. So while the co-ordinates of the points, line or polygons are\nstored in a file with a `.shp` extension, the non-spatial attributes of each\nspatial feature (such as the date on which a crime occurred or the name of a\nneighbourhood) are stored in a separate file with a `.dbf` extension and details\nof the co-ordinate reference system are stored in a `.prj` file -- a single \ndataset might be held in up to 16 separate files on a computer. All the files \nthat make up a shapefile have the same file name, differing only in the file \nextension (e.g. `.shp`, `.dbf`, etc.). For example, if a `.shp` file is called\n`robberies.shp` then it will be accompanied by a file called `robberies.dbf` and\none called `robberies.prj`, as well as a `robberies.shx` index file and possibly\nseveral others. All these separate files make it more-complicated to manage \nshapefiles than other spatial file formats such as the geopackage.\n\nBecause storing spatial data in a shapefile requires multiple different files,\nshapefile data is usually distributed in a `.zip` file that contains all the\ncomponent files. This means that to access a shapefile will have to add a step \nto our usual routine for downloading and opening a data file. To minimise the\nhassle associated with using shapefiles, in general we will:\n\n  1. download the `.zip` file if we don't have a local copy already,\n  2. create a temporary directory where we can store the unzipped shapefile, so\n     we can save space on our computers by only permanently keeping the (often\n     much smaller) `.zip` file,\n  3. unzip the `.zip` file into the temporary directory,\n  4. load the shapefile data from the temporary directory.\n\nFor example, the routes of metro lines in Medellin are available in shapefile\nformat at: \n\n```\nhttps://mpjashby.github.io/crimemappingdata/medellin_metro_lines.zip\n```\n\n\nTo load the data from this file, we can use the process shown above.\n\n::: {.tutorial}\n\nUnfortunately it isn't possible to run this code within this interactive \ntutorial because of security restrictions on saving files on your computer from \nwithin a tutorial. You can test this code by copying it into a new R Script in \nRStudio and running the code from there. Note that this code assumes you have\nalready loaded the `sf` and `tidyverse` packages.\n\n:::\n\n\n```r\n# Step 1: download the .zip file to a temporary file\nmetro_lines_file <- tempfile(fileext = \".zip\")\ndownload.file(\n  url = \"https://mpjashby.github.io/crimemappingdata/medellin_metro_lines.zip\", \n  destfile = metro_lines_file\n)\n\n# Step 2: create a temporary directory\n# The `tempdir()` function returns a location on your computer that is used for\n# storing temporary files. *Any files stored in this temporary directory will be\n# deleted when you restart your computer*, so it's a useful place to put files\n# that you will only need for a short time so they won't clutter up your\n# computer. Since we want to store the shapefile in a sub-directory of the\n# temporary directory, we will use `str_glue()` to add a relevant sub-directory\n# name to the end of the temporary directory name -- `unzip()` will then\n# create this directory in the background at Step 3.\nmetro_lines_dir <- str_glue(\"{tempdir()}/metro_lines\")\n\n# Step 3: unzip file\nunzip(metro_lines_file, exdir = metro_lines_dir)\n\n# Step 5: load the data\nmedellin_metro_lines <- metro_lines_dir |> \n  str_glue(\"/medellin_metro_lines.shp\") |> \n  read_sf()\n```\n\n\n::: {.box .notewell}\n\nNote that although a shapefile consists of several different files, we only need\nto load the file with the extension `.shp` -- the `read_sf()` function will find\nall the data it needs from the other files.\n\nOnce we have loaded a shapefile into R using `read_sf()`, we can treat it in the\nsame way as any other spatial dataset -- it is only loading shapefiles that is\ndifferent from other spatial data formats.\n\n:::\n\n\n<div class=\"box extra-detail\">\n\n<h5 id=\"shapefile-box1-title\" class=\"box-title\">How did you know the name of the `medellin_metro_lines.shp` file?</h5>\n\n<div id=\"shapefile-box1\" class=\"box-content\">\n\nIf you need to find out the name of the shapefile within the zip file, you can\nuse the `list = TRUE` argument to the `unzip()` function to produce a list of\nfiles that are inside the zip file rather than unzip any files. For example, the\ncode `unzip(metro_lines_file, list = TRUE)` would produce a data frame of file\nnames:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Name                     | Length|Date                |\n|:------------------------|------:|:-------------------|\n|medellin_metro_lines.dbf |   2299|2023-02-06 22:46:00 |\n|medellin_metro_lines.prj |    145|2023-02-06 22:46:00 |\n|medellin_metro_lines.shp |  16076|2023-02-06 22:46:00 |\n|medellin_metro_lines.shx |    172|2023-02-06 22:46:00 |\n\n\n:::\n:::\n\n\n\n\n**Make sure you run `unzip(metro_lines_file, list = TRUE)` in the R console\nrather than in your script file, to minimise the amount of unnecessary output\nthat your script produces.**\n\n</div>\n\n</div>\n\n<script>\n$(\"#shapefile-box1-title\").click(function () { $(\"#shapefile-box1\").toggle(\"slow\") })\n</script>\n\n\n<!-- ### Check your understanding -->\n\n<!-- ```{r open-data-quiz} -->\n<!-- quiz( -->\n<!--   caption = \"\", -->\n\n<!--   question( -->\n<!--     \"\", -->\n<!--     answer(\"\", correct = TRUE), -->\n<!--     answer( -->\n<!--       \"\", -->\n<!--       message = \"\" -->\n<!--     ), -->\n<!--     answer( -->\n<!--       \"\", -->\n<!--       message = \"\" -->\n<!--     ), -->\n<!--     answer( -->\n<!--       \"\", -->\n<!--       message = \"\" -->\n<!--     ), -->\n<!--     correct = random_praise(), -->\n<!--     allow_retry = TRUE, -->\n<!--     random_answer_order = TRUE -->\n<!--   ) -->\n\n<!-- ) -->\n<!-- ``` -->\n\n\n\n## Data from OpenStreetMap\n\n<a href=\"https://www.openstreetmap.org/\"><img src=\"images/osm_logo.jpg\" alt=\"OpenStreetMap logo\" class=\"right-side-image\"></a>\n\nOften we can get map data from the organisation we are working for, or from \nopen-data portals run by governments or international organisations. But \nsometimes they won't hold the information we need.\n\nFortunately, there is another source of data: OpenStreetMap (OSM). This is a\nglobal resource of map data created by volunteers (and started at UCL), using a\nmixture of open data from governments, data contributed by charities and data \ncollected by the volunteers themselves. Watch this video to learn a bit more \nabout OpenStreetMap.\n\n\n\n\n{{< video https://youtu.be/d6n29CU2-Sg >}}\n\n\n\n\n\n\nWe have already used OSM data in this course: all of the base maps we have used\nwhen we create maps with `ggplot()` are based on data from OpenStreetMap. But\nwe have very little control over which information is and is not included in\nbase maps. Sometimes we need more control over the data, and that means \ndownloading data direct from OSM.\n\nWe can download OSM data into R using the `osmdata` package. This package allows \nus to choose particular features from the billions of features worldwide that \nare included in the OSM database. To choose features, we must:\n\n  1. specify the _bounding box_ of the area we want to download data for using \n     the `opq()` function,\n  2. specify what type of features we want to download using the\n     `add_osm_feature()` function,\n  3. download the data using the `osmdata_sf()` function, and\n  4. extract the type of spatial object (points, lines or polygons) that we are\n     interested in.\n\nImagine that in your analysis of homicides in Medellin, you have been asked\nto consider the question of whether homicides are clustered near to bus stops.\nTo answer this question, we need to know the locations of bus stops in the area\nwe are interested in. This information is not published as open data by the\nMedellin city authorities. Fortunately we can extract bus-stop locations from \nOpenStreetMap using the `osmdata` package.\n\nTo do this, we first need to calculate the bounding box of the La Candelaria \nneighbourhood that we are interested in. A bounding box is the smallest \nrectangle that a particular spatial shape will fit inside. For example, the\nred rectangle on this map shows the bounding box of the city of Medellin (shown\nin blue).\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n<p class=\"full-width-image\"><img src=\"images/medellin_bbox_map.jpg\" alt=\"Map of the boundary of Medellin and the corresponding bounding box\"></p>\n\n\nYou can calculate the bounding box of an SF object using the `st_bbox()` \nfunction.\n\n::: {.tutorial}\n\nAssuming we have already loaded the neighbourhood boundaries into an object \ncalled `medellin_comunas`, write the code needed to filter that object so that \nonly the boundary for the La Candelaria neighbourhood is included, then\ncalculate the bounding box for that layer and store it in an object called\n`la_candelaria_bbox`. \n\nNote that the `medellin_comunas` object uses the Colombia MANGA West Zone\nco-ordinate system (EPSG code 3115), but the `osmdata` package only works with\nbounding boxes specified as longitudes and latitudes. This means you will also\nneed to transform the dataset to use the WGS84 co-ordinate system (EPSG code\n4326) before you calculate the bounding box.\n\n\n\n\n\n::: {.cell exercise='true'}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# You can use the `filter()` function to filter only the rows of data that you \n# want to keep in the data\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remember to use `st_transform()` to make sure the data uses the correct\n# co-ordinate system. You can use the `st_bbox()` function to calculate the \n# bounding box of the 52nd division boundary.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# If you need to find out the name of the relevant variable in the \n# `medellin_comunas` object, you can use `head(medellin_comunas)` to see the \n# first few rows.\n```\n:::\n\n\n\n\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nla_candelaria_bbox <- medellin_comunas |> \n  filter(nombre == \"LA CANDELARIA\") |> \n  st_transform(\"EPSG:4326\") |> \n  st_bbox()\n\nhead(la_candelaria_bbox)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      xmin       ymin       xmax       ymax \n-75.580293   6.224509 -75.553850   6.265124 \n```\n\n\n:::\n:::\n\n\n\n\nThe second thing we need to know is what search terms to use in the \n`add_osm_feature()` function to return the locations of bus stops. \nOpenStreetMap has hundreds of feature categories, all in the format \n`key=value`. Sometimes we will only need to search for a particular \nkey (category of feature), such as the \n[`highway` key](https://wiki.openstreetmap.org/wiki/Key:highway) that \ncontains all the features that show roads (from motorways to winding lanes\nleading to farms in the countryside), tracks and paths. In other cases, we will \nwant to search for a particular value (type of feature within a category), such \nas searching for the value \n[`natural=water`](https://wiki.openstreetmap.org/wiki/Tag:natural%3Dwater) to\nsearch for lakes, rivers, etc. \n\nThe best place to find out how a feature you are interested in is recorded in \nthe OSM database is to look at the\n[OpenStreetMap Wiki](https://wiki.openstreetmap.org/wiki/Map_features). \nBus stops are recorded in OSM using the tag `highway=bus_stop`.\n\nNow that we know the bounding box of the area we are interested in and the tag\nfor the type of feature we want, we can download the data from OpenStreetMap.\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\n# Define the bounding box of the area we want to search\nbus_stops <- opq(la_candelaria_bbox) |> \n  # Define the features we want\n  add_osm_feature(key = \"highway\", value = \"bus_stop\") |> \n  # Download those features for that area\n  osmdata_sf()\n\n# Print the result (note the result is not a data frame, so we cannot use the\n# `head()` function)\nbus_stops\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nObject of class 'osmdata' with:\n                 $bbox : 6.22450932830104,-75.5802925457919,6.26512401936258,-75.5538503495463\n        $overpass_call : The call submitted to the overpass API\n                 $meta : metadata including timestamp and version numbers\n           $osm_points : 'sf' Simple Features Collection with 55 points\n            $osm_lines : NULL\n         $osm_polygons : 'sf' Simple Features Collection with 0 polygons\n       $osm_multilines : NULL\n    $osm_multipolygons : NULL\n```\n\n\n:::\n:::\n\n\n\n\nYou'll see that the object `bus_stops` has quite complicated structure, but \nthat nested within it is an object called `osm_points` that is an SF object with\n55 rows and another SF object called \n`osm_polygons`. Even within a particular type of feature, some places might be\nrepresented as points (e.g. a point placed at a bus stop) while others are \nrepresented as polygons (e.g. the outline of a bus station).\n\nWe can use the `pluck()` function from the `purrr` package (part of the \ntidyverse) to extract the parts of the `bus_stops` object that we want. If we \nextract the SF object called `osm_points` and look at the first few rows using \n`bus_stops |> pluck(\"osm_points\") |> head(n = 5)`, we can see:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbus_stops |> pluck(\"osm_points\") |> head(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 5 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -75.57696 ymin: 6.228165 xmax: -75.56289 ymax: 6.260205\nGeodetic CRS:  WGS 84\n               osm_id                 name access bench  bin  bus\n847830985   847830985                 <NA>   <NA>    no <NA>  yes\n1561073855 1561073855         La Alpujarra   <NA>  <NA> <NA> <NA>\n2418112357 2418112357                 <NA>   <NA>  <NA> <NA> <NA>\n3135948756 3135948756      Barrio Colombia   <NA>  <NA> <NA>  yes\n3346088239 3346088239 Carrera 33 Calle 29C   <NA>    no <NA> <NA>\n           check_date:shelter covered  highway  lit    local_ref name:en\n847830985                <NA>    <NA> bus_stop <NA>         <NA>    <NA>\n1561073855               <NA>    <NA> bus_stop <NA> La Alpujarra    <NA>\n2418112357               <NA>    <NA> bus_stop <NA>         <NA>    <NA>\n3135948756               <NA>    <NA> bus_stop <NA>         <NA>    <NA>\n3346088239               <NA>      no bus_stop <NA>         <NA>    <NA>\n             network              note          operator public_transport\n847830985       <NA>              <NA>              <NA>         platform\n1561073855      <NA>              <NA>              <NA>             <NA>\n2418112357      <NA>              <NA>              <NA>             <NA>\n3135948756 Metroplus Sentido Norte Sur Metro de Medellín         platform\n3346088239      <NA>              <NA> Metro de Medellín             <NA>\n           shelter source wheelchair                   geometry\n847830985      yes   <NA>       <NA> POINT (-75.57696 6.260205)\n1561073855    <NA>   <NA>       <NA> POINT (-75.57342 6.245391)\n2418112357    <NA>   <NA>       <NA>  POINT (-75.56893 6.24997)\n3135948756     yes   <NA>        yes POINT (-75.56982 6.228716)\n3346088239      no   <NA>       <NA> POINT (-75.56289 6.228165)\n```\n\n\n:::\n:::\n\n\n\n\nWe can see from this that most of the fields are blank, but there is a `name`\ncolumn and a `geometry` column that we can use to plot the locations of the\nbus stops.\n\nWe also need to check the contents of the `osm_polygons` layer inside the \n`bus_stops` object, to see if it contains details of a any more bus stops that\nare not included in the `osm_points` layer. \n\n\n::: {.tutorial}\n\nType the code needed to extract the `osm_polygons` layer and view the first few \nrows.\n\n\n\n\n::: {.cell exercise='true'}\n\n:::\n\n\n\n\n:::\n\n\n::: {.book}\n\nTo check this, we can again use the `pluck()` function:\n\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbus_stops |> pluck(\"osm_polygons\") |> head(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  WGS 84\n[1] osm_id   geometry\n<0 rows> (or 0-length row.names)\n```\n\n\n:::\n:::\n\n\n\n\nIn this case, we can see that there are \n0 rows in the `osm_polygons`\nobject. In cases where we have data contained in both the `osm_points` and \n`osm_polygons` layers, we need to merge the two layers by converting the polygon \nlayer to a point layer using the `st_centroid()` function and then  merging the \ntwo layers using the `bind_rows()` function from the `dplyr` package. We can put \nall this together into one piece of code.\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nbind_rows(\n  pluck(bus_stops, \"osm_points\"), \n  st_centroid(pluck(bus_stops, \"osm_polygons\"))\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 55 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -75.57967 ymin: 6.226014 xmax: -75.55641 ymax: 6.264754\nGeodetic CRS:  WGS 84\nFirst 10 features:\n               osm_id                          name access bench  bin  bus\n847830985   847830985                          <NA>   <NA>    no <NA>  yes\n1561073855 1561073855                  La Alpujarra   <NA>  <NA> <NA> <NA>\n2418112357 2418112357                          <NA>   <NA>  <NA> <NA> <NA>\n3135948756 3135948756               Barrio Colombia   <NA>  <NA> <NA>  yes\n3346088239 3346088239          Carrera 33 Calle 29C   <NA>    no <NA> <NA>\n3346088240 3346088240          Carrera 34 Calle 29C   <NA>    no <NA> <NA>\n3346088241 3346088241                    Carrera 34   <NA>    no <NA> <NA>\n3346088242 3346088242       Calle 29 Av. Las Palmas   <NA>    no <NA> <NA>\n3346088245 3346088245     Carrera 38 Av. Las Palmas   <NA>   yes   no <NA>\n3346088246 3346088246 Carrera 38 Avenida Las Palmas   <NA>    no <NA> <NA>\n           check_date:shelter covered  highway  lit    local_ref name:en\n847830985                <NA>    <NA> bus_stop <NA>         <NA>    <NA>\n1561073855               <NA>    <NA> bus_stop <NA> La Alpujarra    <NA>\n2418112357               <NA>    <NA> bus_stop <NA>         <NA>    <NA>\n3135948756               <NA>    <NA> bus_stop <NA>         <NA>    <NA>\n3346088239               <NA>      no bus_stop <NA>         <NA>    <NA>\n3346088240               <NA>      no bus_stop <NA>         <NA>    <NA>\n3346088241               <NA>      no bus_stop <NA>         <NA>    <NA>\n3346088242               <NA>      no bus_stop <NA>         <NA>    <NA>\n3346088245               <NA>      no bus_stop <NA>         <NA>    <NA>\n3346088246               <NA>      no bus_stop <NA>         <NA>    <NA>\n             network              note          operator public_transport\n847830985       <NA>              <NA>              <NA>         platform\n1561073855      <NA>              <NA>              <NA>             <NA>\n2418112357      <NA>              <NA>              <NA>             <NA>\n3135948756 Metroplus Sentido Norte Sur Metro de Medellín         platform\n3346088239      <NA>              <NA> Metro de Medellín             <NA>\n3346088240      <NA>              <NA> Metro de Medellín             <NA>\n3346088241      <NA>              <NA> Metro de Medellín             <NA>\n3346088242      <NA>              <NA> Metro de Medellín             <NA>\n3346088245      <NA>              <NA> Metro de Medellín             <NA>\n3346088246      <NA>              <NA> Metro de Medellín             <NA>\n           shelter source wheelchair                   geometry\n847830985      yes   <NA>       <NA> POINT (-75.57696 6.260205)\n1561073855    <NA>   <NA>       <NA> POINT (-75.57342 6.245391)\n2418112357    <NA>   <NA>       <NA>  POINT (-75.56893 6.24997)\n3135948756     yes   <NA>        yes POINT (-75.56982 6.228716)\n3346088239      no   <NA>       <NA> POINT (-75.56289 6.228165)\n3346088240      no   <NA>       <NA> POINT (-75.56364 6.229471)\n3346088241      no   <NA>       <NA>  POINT (-75.5649 6.227743)\n3346088242      no   <NA>       <NA> POINT (-75.56406 6.226646)\n3346088245      no   <NA>       <NA> POINT (-75.56695 6.233343)\n3346088246      no   <NA>       <NA> POINT (-75.56712 6.233176)\n```\n\n\n:::\n:::\n\n\n\n\n\n<div class=\"box extra-detail\">\n\n<h5 id=\"osm-box1-title\" class=\"box-title\">What does the warning `st_centroid assumes …` mean?</h5>\n\n<div id=\"osm-box1\" class=\"box-content\">\n\nYou might have seen a warning saying \n`st_centroid assumes attributes are constant over geometries of x`. You will see\nthis warning when you use the `st_centroid()` function. It is there to remind\nyou that columns in the original data (which the SF package refers to as the\n_attributes_ associated with each spatial feature) refer to the polygon as a \nwhole, but in the object produced by `st_centroid()` it will appear that the\ncolumns relate to the centroid point. In many cases this will not be a problem,\nbut it could expose you to the ecological fallacy so it is sometimes useful to \nbe reminded.\n\n</div>\n\n</div>\n\n<script>\n$(\"#osm-box1-title\").click(function () { $(\"#osm-box1\").toggle(\"slow\") })\n</script>\n\n\nThis code references the `bus_stops` object twice, which means we cannot use\nthis code within a pipeline in the usual way. This means it will be necessary to\nsave the result produced by `osmdata_sf()` in an object and then combine the\npoints and polygon centroids in a separate piece of code.\n\n\n::: {.tutorial}\n\nWe now have everything we need to map homicides in La Candelaria in relation to \nbus stops. Create a map showing a suitable base map, the density of \nhomicides in the La Candelaria neighbourhood, the locations of bus stop as \nindividual points and the boundary of the neighbourhood.\n\nYou will need to:\n\n  1. Create an object holding the boundary of the La Candelaria neighbourhood.\n     Remember the boundaries of Medellin neighbourhoods are contained in the\n     `medellin_comunas` object.\n  2. Estimate the density of homicides in the La Candelaria neighbourhood. The\n     homicide locations are stored in the `medellin_homicides` object, although\n     you will probably want to extract only those in La Candelaria before\n     estimating the density.\n  3. Extract the bounding box of the neighbourhood boundary and use that to get\n     the locations of bus stops, taking into account that some bus stops might \n     be stored in the OSM database as points and others as polygons.\n  4. Create a map showing the density of homicides, the locations of bus stops\n     and the boundary of the neighbourhood.\n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='68'}\n\n:::\n\n\n\n\n:::\n\n\n::: {.book}\n\nNow that we have everything we need, we can create a map of homicides in La\nCandelaria.\n\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# There are lots of design decisions you could make in producing a map -- the\n# following code is a minimal map, which you could improve on in several ways\n\n# Load data\nmedellin_comunas <- read_sf(\"https://mpjashby.github.io/crimemappingdata/medellin_comunas.gpkg\") |> \n  janitor::clean_names() |> \n  st_transform(\"EPSG:3115\") |> \n  select(nombre, geom)\nmedellin_homicides <- read_csv2(\"https://mpjashby.github.io/crimemappingdata/medellin_homicides.csv\") |> \n  remove_missing(vars = c(\"longitud\", \"latitud\")) |> \n  st_as_sf(coords = c(\"longitud\", \"latitud\"), crs = \"EPSG:4326\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 9360 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (2): sexo, modalidad\ndbl  (3): longitud, latitud, edad\ndttm (1): fecha_hecho\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 81 rows containing missing values or values outside the scale\nrange.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Create neighbourhood boundary\nla_candelaria <- medellin_comunas |> \n  filter(nombre == \"LA CANDELARIA\") |> \n  # This object needs to use the same co-ordinate system as `medellin_homicides`\n  # so we can use `st_intersection()`, so transform it first\n  st_transform(\"EPSG:3115\")\n\n# Estimate homicide density\nla_candelaria_homicide_density <- medellin_homicides |> \n  st_transform(\"EPSG:3115\") |> \n  # Extract only those homicides occurring within the La Candelaria \n  # neighbourhood boundary (otherwise `hotspot_kde()` will be very slow)\n  st_intersection(la_candelaria) |> \n  hotspot_kde(\n    grid = hotspot_grid(la_candelaria, cell_size = 100), \n    bandwidth_adjust = 0.33,\n    quiet = TRUE\n  ) |> \n  st_intersection(la_candelaria)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n```\n\n\n:::\n\n```{.r .cell-code}\n# Get bus stop locations\nbus_stops <- la_candelaria |> \n  # `opq()` needs longitude/latitude co-ordinates, so transform before \n  # calculating the bounding box\n  st_transform(\"EPSG:4326\") |> \n  st_bbox() |> \n  opq() |> \n  # Define the features we want\n  add_osm_feature(key = \"highway\", value = \"bus_stop\") |> \n  # Download those features for that area\n  osmdata_sf()\n\n# Extract bus stop locations as points\nbus_stop_points <- bind_rows(\n  pluck(bus_stops, \"osm_points\"), \n  st_centroid(pluck(bus_stops, \"osm_polygons\"))\n)\n\n# Plot map\nggplot() +\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  geom_sf(\n    aes(fill = kde), \n    data = la_candelaria_homicide_density, \n    alpha = 0.7, \n    colour = NA\n  ) +\n  geom_sf(data = la_candelaria, colour = \"grey40\", fill = NA, linewidth = 1.5) +\n  geom_sf(data = bus_stop_points, colour = \"darkred\") +\n  scale_fill_distiller(\n    direction = 1, \n    breaks = range(pull(la_candelaria_homicide_density, \"kde\")),\n    labels = c(\"lower\", \"higher\")\n  ) +\n  labs(\n    caption = str_glue(\n      \"Contains data from OpenStreetMap\\n\",\n      \"Homicide data: Alcaldía de Medellín (CC-BY-SA)\"\n    ),\n    fill = \"homicide\\ndensity\"\n  ) +\n  # We can add the `fixed_plot_aspect()` function to the `ggplot()` stack to\n  # force the map to be square, rather than a rectangle\n  fixed_plot_aspect() +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/osm-exercise5-solution-1.png){width=672}\n:::\n:::\n\n\n\n\nFrom this map, it looks like homicides do not cluster particularly around bus\nstops. This would probably be welcome information for the city's public \ntransport managers.\n\n\n::: {.box .notewell}\n\nJust as with other sources of map data, you are legally required to \n[cite data from OpenStreetMap](https://wiki.openstreetmap.org/wiki/Draft_Attribution_Guideline)\nif you use it. The code in the exercise above, for example, cites data from two\nsources:\n\n  * \"Contains data from OpenStreetMap\" acknowledges that both the base map and\n    the bus-stop locations were obtained from OpenStreetMap.\n  * \"Homicide data: Alcaldía de Medellín (CC-BY-SA)\" acknowledges that the\n    Medellin homicide data were released by the Mayor of Medellin under the\n    [Creative Commons Attribution Share-alike](https://opendefinition.org/licenses/cc-by-sa/) \n    (CC-BY-SA) licence.\n\n:::\n\n\n<p class=\"credits\">The OpenStreetMap logo is a trademark of the OpenStreetMap Foundation, and is used with their permission. This tutorial not endorsed by or affiliated with the OpenStreetMap Foundation.</p>\n\n\n\n## In summary\n\n\n::: {.box .welldone}\n\nIn this tutorial we have learned how to find open data, including data from\nOpenStreetMap, and add it to our maps to help readers better understand crime \npatterns. We will be able to use these skills to add data to future maps that\nwe make so that readers can gain more insight into crime patterns or other\nphenomena that we might be analysing.\n\n:::\n\n\n::: {.box .reading}\n\nTo find out more about the skills we have worked on in this tutorial, you may\nwant to read:\n\n  * [a paper exploring how open crime data can be used in researching crime](https://doi.org/10.1080/15230406.2014.972456), and\n  * [a more-detailed introduction to the `osmdata` package written by Mark Padgham and Robin Lovelace](https://docs.ropensci.org/osmdata/articles/osmdata.html).\n\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}