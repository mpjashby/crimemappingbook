{
  "hash": "3f629c0366e457c29ba65fac3e43dc98",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexecute:\n  freeze: auto\n---\n\n\n\n\n# Mapping hotspots {#sec-mapping-hotspots}\n\n\n**Learn what crime hotspots are, why they are important and how to map them.**\n\n\n::: {.box .load-tutorial}\nTo load the [interactive tutorial](../#how-to-use-this-book) for this chapter, copy and paste the following code into the RStudio console:\n\n```r\ncrimemapping::tutorial(\"11_mapping_hotspots\")\n```\n\nand press `Enter`.\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## What is a hotspot?\n\nCrime is heavily concentrated in several different ways. A small number of \noffenders commit a large proportion of crime (even though most people commit \nminor offences occasionally) and a small number of people are repeatedly \nvictimised. For most types of crime, a large proportion of crime occurs in a \nsmall number of places. **A hotspot is a specific location or small area where \nan unusual amount of criminal activity occurs**.\n\nCrime hotspots can occur in several different forms. Watch this video to \nunderstand why hotspots are important in understanding and responding to crime.\n\n\n\n\n{{< video https://youtu.be/ug-ZhvvQjmw >}}\n\n\n\n\n\n\nSome places are *chronic* hotspots -- they have more crime than surrounding\nareas over a sustained period (which may appear to be permanent). Chronic\nhotspots are often generated by a facility that draws vulnerable people into an\narea, such as a tourist attraction that draws crowds of people who are\nvulnerable to pickpocketing. Other places are *acute* hotspots, in which crime\nincreases in a place that previously experienced no or few crimes. This may be\nthe result of some change in the environment or how it's managed, such as new\nmanagement at a bar that ignores drug dealing that the previous owners would\nhave not permitted.\n\nWhen analysing hotspots, it is best to focus on *small* areas such as an\napartment block, a shopping centre, a park or a single street. Focusing on \nsmaller areas is important because resources to respond to crime are almost \nalways limited, so it is important that those resources are directed where the\nproblem is worst. \n\nAnalysing larger areas, such as a neighbourhood or a police sector, is much more \ndifficult because larger areas are always made up of many smaller areas, each of \nwhich might be quite different from one another. This means that the factors \ncausing one street to be a hotspot might be quite different from the factors \nthat make another street in the same district into a hotspot. Conflating \ndifferent problems with different causes makes it much harder to find effective \nways to reduce crime in any one place. \n\nThese difficulties can be avoided (at least partly) by keeping hotspots small: \nin an urban area, a useful rule of thumb is that you should be able to stand in \nthe middle of a hotspot and see the whole hotspot area.\n\nBeing able to identify hotspots using crime mapping is important because it \nforms a vital first step in many place-focused responses to crime. As an example\nof this, watch this video about how police in Philadelphia worked with \nresearchers to use crime mapping to identify where to deploy foot patrols to\nreduce crime.\n\n\n\n\n{{< video https://youtu.be/0NUQsK0vnnM >}}\n\n\n\n\n\n\n\nIn this tutorial we will learn how to make maps that could be useful in \nidentifying and responding to hotspots of crime. As an example, we will create\nthis map showing hotspots of robbery in Nottingham, England.\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n<p class=\"full-width-image\"><img src=\"images/nottingham_robbery_map.jpg\" alt=\"A hotspot map of robberies in Nottingham\" style=\"max-height: 700px;\"></p>\n\n\n### Check your understanding {.tutorial}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquiz(\n  caption = \"\",\n  question(\"Which *one* of these statements is true?\",\n    answer(\"Crime is very geographically concentrated – we can expect half of crime to be concentrated in about 5% of micro places\", correct = TRUE),\n    answer(\"Crime is usually not geographically concentrated at micro places\"),\n    answer(\"Crime is slightly geographically concentrated – we can expect half of crime to be concentrated in about one quarter of micro places\"),\n    answer(\"Crime is extremely geographically concentrated – we can expect half of crime to be concentrated in about 1% of micro places\"),\n    correct = \"That's correct – based on previous studies, we can expect half of crime to be concentrated in about 5% of micro places\",\n    incorrect = \"That's not correct – try re-watching the first video above and then try the question again.\",\n    allow_retry = TRUE,\n    random_answer_order = TRUE\n  )\n)\n```\n:::\n\n\n\n\n\n\n## Showing the density of risk\n\nIn the tutorial on mapping area data we learned how to produce maps showing the\n*incidence rate* of crime by dividing the number of crimes by a measure of the\npopulation at risk of being targeted. We will often only have population \nestimates for areas, such as census estimates of the number of people living in\nan area. But for some crimes we have access to estimates of the people (or,\nmore often, objects) at risk of being a target of a particular crime. In these\ncases, we can produce better maps of the risk of crime in different areas by\nproducing a *dual KDE* map that shows the density of crime *risk* in different\nplaces.\n\nTo create a dual KDE map, we must estimate the density of crime and compare it \nto an estimate the density of the population at risk. Since the incidence rate \nis calculated as the number of crimes divided by the number of people or objects \nat risk, we can calculate the density of risk by dividing the density of crime \nestimated for each cell in the grid by the density of population estimated for \nthe same cell. The `hotspot_dual_kde()` function from the `sfhotspot` package\ndoes this for us.\n\nTo illustrate making a dual KDE map, we will use reports of burglaries in three \nwards in Nottingham in 2020. Since the essential element of the crime of \nburglary in England is that an offender enters a _building_ as a trespasser in \norder to steal something, the best measure of the population at risk of burglary \nis the number of _buildings_ in each area (the definition of burglary is more \ncomplicated than this, but we don't need to worry about that here). \n\nBurglary is a good example of why the routine activities approach to thinking \nabout crime that we introduced in a previous tutorial emphasises thinking about \n_targets_ of crime rather than focusing only on crime _victims_. In the case of\nburglary, one person might be the owner of a large number of buildings (e.g. a \nfarm with lots of out-buildings) or lots of people might own a single building \n(such as a house converted into flats). By thinking about the targets that are \nattacked by offenders, we can identify that burglary rates should be calculated \nbased on buildings rather than, for example, residential population. Note that \nif our crime data only included _residential_ burglaries then we would want to\nuse _residential_ buildings as our denominator, but in this case we have data\nfor all burglaries, both residential and non-residential.\n\n\n### Data wrangling\n\nBefore we can create our dual KDE layer, we have to complete some data \nwrangling. We will extract the boundaries for the wards of interest from a \ndataset of boundaries for all wards in Nottingham using `filter()` as we have \ndone previously. To extract only the burglaries occurring in those three wards \nfrom a dataset of all burglaries in Nottingham, we will use `st_intersection()`.\nWe will also transform both datasets to use the British National Grid (EPSG code\n27700), since we will need to do that anyway before calculating the KDE values.\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nwards <- read_sf(\"https://mpjashby.github.io/crimemappingdata/nottingham_wards.gpkg\") |> \n  st_transform(\"EPSG:27700\") |> \n  filter(ward_name %in% c(\"Castle\", \"Lenton & Wollaton East\", \"Meadows\"))\n\nburglaries <- read_csv(\"https://mpjashby.github.io/crimemappingdata/nottingham_burglary.csv.gz\") |> \n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) |> \n  st_transform(\"EPSG:27700\") |> \n  st_intersection(wards)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 1795 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): location, lsoa_code\ndbl  (2): longitude, latitude\ndate (1): month\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n```\n\n\n:::\n:::\n\n\n\n\n\n::: {.box .notewell}\n\n`st_intersection()` can take longer to run than the maximum time limit for \nrunning code within this tutorial. If you see an error saying `Your code ran \nlonger than the permitted time limit for this exercise` or `reached elapsed time \nlimit`, you can continue with the rest of the tutorial as usual.\n\n:::\n\n\nWe do not have a source of open data for all the buildings in Nottingham, so we\nwill use the `osmdata` package to get the locations of buildings from \nOpenStreetMap (OSM). You may remember from a previous tutorial that to do this \nwe need to know which key (and possibly value) the OSM database uses for storing\nthe locations of buildings. The OSM feature key for a building is 'building' \nand it is not necessary to specify a value (since we want to capture all types \nof building). The `osmdata` package expects data to use the WGS84 co-ordinate \nreference system, so we must also make sure any data sources we use are \nprojected using that system (EPSG code 4326).\n\n\n\n::: {.tutorial}\n\nRun the code needed to download data from OSM for all the buildings in the three \nwards we are interested in and store it in an object called \n`nottingham_buildings`. \n\n\n\n\n::: {.cell exercise='true' exercise.lines='10'}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# To download OSM data, use:\n#   * `st_transform()` to transform the data to use the WGS84 co-ordinate system\n#   * `st_bbox()` to calculate the bounding box of the wards\n#   * `opq()` to set up the OSM query \n#   * `add_osm_feature()` to specify what type of features to download\n#   * `osmdata_sf()` to download the data as an SF object\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(osmdata)\n\nnottingham_buildings <- wards |> \n  st_transform(\"EPSG:4326\") |> \n  st_bbox() |> \n  opq() |> \n  add_osm_feature(key = \"?????\") |>  # <- specify type of data here\n  osmdata_sf()\n\nnottingham_buildings\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nObject of class 'osmdata' with:\n                 $bbox : 52.9173362670705,-1.21712477980417,52.9596833099217,-1.13020878819132\n        $overpass_call : The call submitted to the overpass API\n                 $meta : metadata including timestamp and version numbers\n           $osm_points : 'sf' Simple Features Collection with 0 points\n            $osm_lines : NULL\n         $osm_polygons : 'sf' Simple Features Collection with 0 polygons\n       $osm_multilines : NULL\n    $osm_multipolygons : NULL\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(osmdata)\n\nnottingham_buildings <- wards |> \n  st_transform(\"EPSG:4326\") |> \n  st_bbox() |> \n  opq() |> \n  add_osm_feature(key = \"building\") |> \n  osmdata_sf()\n\nnottingham_buildings\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nObject of class 'osmdata' with:\n                 $bbox : 52.9173362670705,-1.21712477980417,52.9596833099217,-1.13020878819132\n        $overpass_call : The call submitted to the overpass API\n                 $meta : metadata including timestamp and version numbers\n           $osm_points : 'sf' Simple Features Collection with 164398 points\n            $osm_lines : 'sf' Simple Features Collection with 44 linestrings\n         $osm_polygons : 'sf' Simple Features Collection with 30465 polygons\n       $osm_multilines : 'sf' Simple Features Collection with 2 multilinestrings\n    $osm_multipolygons : 'sf' Simple Features Collection with 69 multipolygons\n```\n\n\n:::\n:::\n\n\n\n\nLooking at the `nottingham_buildings` object, we can see that OSM contains data\non buildings stored as points, polygons and multipolygons (we can ignore the\nfew linestrings tagged as buildings, since it doesn't make sense for a building\nto be represented as a single line rather than a point or a polygon). \n\n\n<div class=\"box extra-detail\">\n\n<h5 id=\"risk-box1-title\" class=\"box-title\">What is a multipolygon?</h5>\n\n<div id=\"risk-box1\" class=\"box-content\">\n\nOpenStreetMap stores features in several different ways. The most basic types\nare points, lines and polygons. But there are also multipolygons (and\nmultilines). These are features that represent complex structures such as \nclusters of buildings that are separate structures but are related to each \nother. For example, a hospital with several buildings might be represented in\nOpenStreetMap as a single multipolygon feature.\n\n</div>\n\n</div>\n\n<script>\n$(\"#risk-box1-title\").click(function () { $(\"#risk-box1\").toggle(\"slow\") })\n</script>\n\n\nLet's plot these features on a base map to check that OSM has reasonable \ncoverage of the buildings in these three wards.\n\n\n\n\n::: {.cell exercise='true' exercise.lines='23'}\n\n```{.r .cell-code}\nggplot() +\n  annotation_map_tile(type = \"cartodark\", zoomin = 0, progress = \"none\") +\n  # Add building features stored as points\n  geom_sf(\n    data = pluck(nottingham_buildings, \"osm_points\"), \n    colour = \"green\",\n    size = 0.1\n  ) +\n  # Add building features stored as polygons\n  geom_sf(\n    data = pluck(nottingham_buildings, \"osm_polygons\"), \n    colour = NA,\n    fill = \"blue\"\n  ) + \n  # Add building features stored as multi-polygons\n  geom_sf(\n    data = pluck(nottingham_buildings, \"osm_multipolygons\"), \n    colour = NA,\n    fill = \"darkred\"\n  ) +\n  geom_sf(data = wards, colour = \"red\", fill = NA, linewidth = 1.25) +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/risk-exercise3-1.png){width=100%}\n:::\n:::\n\n\n\n\n\n::: {.box .notewell}\n\nRemember that `osmdata_sf()` gets OSM data for the area covered by the _bounding \nbox_ of the input feature, not the feature boundaries. This means some of the\nbuildings returned by the code above will be outside the wards we are interested\nin. We will deal with this in a minute.\n\n:::\n\n\nIt looks like almost all the streets in the three wards we are interested in are\nlined with buildings in the OSM data, which is what we would expect of streets\nin an urban area. There are some streets without buildings in the top-left of \nthe map, but these streets are outside our three wards so this does not matter.\n\nWe can also see from this map that the \n164,398 point \nfeatures in the OSM data (shown as green dots on the map) typically represent \nthe corners of buildings that are also represented as polygons, so we know we \ncan ignore the points layer within the OSM data.\n\nSince the `hotspot_dual_kde()` function works on points, we need to convert the \npolygon and multipolygon layers to points by calculating their centroids, then \nmerge the two layers together. This will generate a warning that \n`st_centroid does not give correct centroids for longitude/latitude data` but we\ncan ignore this because the calculated centroids will be good enough for our\npurposes (if we wanted to, we could transform the data to use the British \nNational Grid, calculate the centroids and then transform it back).\n\nSince we are only interested in those buildings in three particular wards, we\ncan also at this stage remove any buildings that are outside those wards using\n`st_intersection()`, as we have already done for the `burglaries` object. Since\nthe `wards` object uses the British National Grid and `st_intersection()`\nrequires both datasets to use the same co-ordinate system, we will transform\nthe building centroids before clipping them.\n\n\n\n\n::: {.cell exercise='true'}\n\n:::\n\n\n\n\n\n<div class=\"box extra-detail\">\n\n<h5 id=\"risk-box2-title\" class=\"box-title\">What does the warning `st_centroid assumes …` mean?</h5>\n\n<div id=\"risk-box2\" class=\"box-content\">\n\nYou might have seen a warning saying \n`st_centroid assumes attributes are constant over geometries of x`. You will see\nthis warning when you use the `st_centroid()` function. It is there to remind\nyou that columns in the original data (which the SF package refers to as the\n_attributes_ associated with each spatial feature) refer to the polygon as a \nwhole, but in the object produced by `st_centroid()` it will appear that the\ncolumns relate to the centroid point. In many cases this will not be a problem,\nbut it could expose you to the ecological fallacy so it is sometimes useful to \nbe reminded.\n\n</div>\n\n</div>\n\n<script>\n$(\"#risk-box2-title\").click(function () { $(\"#risk-box2\").toggle(\"slow\") })\n</script>\n\n\n<div class=\"box extra-detail\">\n\n<h5 id=\"risk-box3-title\" class=\"box-title\">What does the warning `attribute variables are assumed …` mean?</h5>\n\n<div id=\"risk-box3\" class=\"box-content\">\n\n`st_intersection()` produces a warning message whenever it is used:\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout all\ngeometries\n```\n\nAs long as you are simply using `st_intersection()` to remove parts of the data\noutside a boundary, you can ignore this message.\n\n</div>\n\n</div>\n\n<script>\n$(\"#risk-box3-title\").click(function () { $(\"#risk-box3\").toggle(\"slow\") })\n</script>\n\n\n### Calculating dual kernel density\n\nWe now have the object `burglaries` that contains the locations of each burglary\nin the three Nottingham wards that we are interested in, and the object\n`nottingham_building_centroids` that contains the centroids of each building in\nthose three wards. We can use these layers to estimate the density of burglaries\nand buildings, then combine these to estimate the density of burglary risk.\n\n`hotspot_dual_kde()` works in the same way as `hotspot_kde()`, except that it\nrequires two datasets. In this case, that means one dataset of crime locations \nand one dataset of building locations. `hotspot_dual_kde()` will set the cell \nsize and bandwidth automatically, but we can set them manually using the \n`cell_size`, `bandwidth_adjust` and `grid` arguments in the same way we have \ndone for `hotspot_kde()`. In this case, we will use the `hotspot_grid()` helper \nfunction to create a grid based on the boundaries of the wards we are interested \nin. All the spatial objects we are going to use here have co-ordinates specified \nusing the British National Grid because we have already transformed them, so we \ndo not need to do any transformation here.\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nburglary_risk <- hotspot_dual_kde(\n  burglaries, \n  nottingham_building_centroids, \n  bandwidth_adjust = 0.25, \n  grid = hotspot_grid(wards, cell_size = 100),\n  quiet = TRUE\n) |> \n  st_intersection(wards)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(burglary_risk)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 455826.6 ymin: 338782.9 xmax: 456354.2 ymax: 338909\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 6 × 5\n      n    kde ward_code ward_name                                      geometry\n  <dbl>  <dbl> <chr>     <chr>                                     <POLYGON [m]>\n1     0 0.0175 E05012277 Castle    ((456061.5 338809, 456061.5 338799.8, 456006…\n2     0 0.0172 E05012277 Castle    ((456061.5 338809, 456161.5 338809, 456161.5…\n3     0 0.0222 E05012277 Castle    ((456161.5 338809, 456261.5 338809, 456261.5…\n4     0 0.0271 E05012277 Castle    ((456261.5 338809, 456354.2 338809, 456261.5…\n5     0 0.0204 E05012277 Castle    ((455861.5 338909, 455861.5 338888.8, 455826…\n6     0 0.0264 E05012277 Castle    ((455861.5 338909, 455961.5 338909, 455961.5…\n```\n\n\n:::\n:::\n\n\n\n\nYou might recall from earlier in this tutorial that the value of the `kde`\ncolumn in the object produced by `hotspot_dual_kde()` is calculated by dividing\nthe density of burglary in each grid cell by the density of buildings in the\nsame grid cell. There are two cases where this will produce a result that is not\na finite number:\n\n  * If, for a particular cell, the density of burglaries and density of \n    buildings are both zero, dividing one by the other will produce the result \n    `NaN`, for 'not a number'.\n  * If the density of burglaries is greater than zero but the density of \n    buildings is exactly zero, the result will be `Inf`, for 'infinite'.\n\nSince it is not possible to calculate burglary risk in either of those cases, we\ncan exclude these cases from the `burglary_risk` object by using `filter()`\ntogether with the `is.finite()` function (R does not count `NaN` as a finite \nnumber):\n\n```r\nburglary_risk <- hotspot_dual_kde(\n  burglaries, \n  nottingham_building_centroids, \n  bandwidth_adjust = 0.25, \n  grid = hotspot_grid(wards, cell_size = 100)\n) |> \n  st_intersection(wards)\n\nburglary_risk_filtered <- filter(burglary_risk, is.finite(kde))\n```\n\nYou might wonder why we didn't simply add `filter()` to the existing pipeline\nthat creates the `burglary_risk` object. It is because we will need the \nunfiltered object in the next section. But for now …\n\nWe can plot the estimate of the density of burglary risk. By controlling\nfor the density of buildings, this map shows us where building owners *on \naverage* face the highest risk of being burgled. This might be useful in working\nout, for example, which building owners should be offered visits from a \ncrime-prevention advisor or funding to install crime-prevention measures.\n\n\n\n\n::: {.cell layout-align=\"center\" exercise='true' exercise.lines='36'}\n\n```{.r .cell-code}\nggplot() +\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  # Add burglary risk layer\n  geom_sf(\n    aes(fill = kde), \n    data = burglary_risk_filtered, \n    alpha = 0.8, \n    colour = NA\n  ) +\n  # Add ward boundaries\n  geom_sf(data = wards, fill = NA) + \n  scale_fill_distiller(\n    breaks = range(pull(burglary_risk_filtered, \"kde\")),\n    labels = c(\"lower\", \"higher\"),\n    direction = 1\n  ) +\n  labs(\n      title = \"Burglary risk in south-west Nottingham\",\n      subtitle = str_glue(\n        \"dual kernel density of burglary risk in Castle, Lenton & Wollaton \",\n        \"East and Meadows wards\"\n      ),\n      caption = str_glue(\n        \"Contains public sector information licensed under the Open \",\n        \"Government Licence v3.0\"\n      ),\n      fill = \"density of burglary risk, 2020\"\n  ) +\n  theme_void() +\n  theme(\n    legend.position = \"bottom\",\n    plot.caption = element_text(colour = \"grey40\"),\n    plot.subtitle = element_text(margin = margin(t = 6, b = 6)),\n    plot.title = element_text(colour = \"grey50\", face = \"bold\", size = 16)\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/risk-exercise6-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\n\n### Check your understanding {.tutorial}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquiz(\n  caption = \"\",\n\n  question(\"Which *one* of these statements is true?\",\n    answer(\"`hotspot_dual_kde()` requires co-ordinates to use a projected co-ordinate system (i.e. not longitude and latitude).\", correct = TRUE),\n    answer(\"`hotspot_dual_kde()` can work on any co-ordinates, whether they use a geographic co-ordinate system (i.e. longitude and latitude) or a projected system.\"),\n    answer(\"`hotspot_dual_kde()` requires co-ordinates to use a geographic co-ordinate system (i.e. longitude and latitude).\"),\n    answer(\"`hotspot_dual_kde()` does not work with co-ordinates, so it does not matter which type of co-ordinate system a dataset uses.\"),\n    allow_retry = TRUE,\n    random_answer_order = TRUE\n  ),\n  \n  question(\n    \"Why do we usually clip the result of `hotspot_dual_kde()` using `st_intersection()`?\",\n    answer(\"To eliminate any areas that we do not have data for, since displaying KDE values for such areas on a map might be misleading.\", correct = TRUE),\n    answer(\"To make our maps look nicer.\"),\n    answer(\"To transform the co-ordinate system our data uses from the system `hotspot_dual_kde()` uses to the one we need to produce a map.\"),\n    answer(\"To make it easier to see the other layers on our map.\"),\n    allow_retry = TRUE,\n    random_answer_order = TRUE\n  )\n)\n```\n:::\n\n\n\n\n\n\n## Finding hotspots\n\nWe now know how to produce a better map of the density of crime in different\nareas. But how do we know which areas count as hotspots and which don't? \n\nThere are several ways to answer this question. If we were planning a particular\nactivity to respond to a crime problem, we might know what resources we had\navailable to respond. For example, we might know that we have enough funding to\nprovide crime-prevention visits to 100 locations. In that case, we can order the\ncells in a KDE object according to which have the highest estimates of risk, \nthen count all the premises in each cell until we have reached our limit.\n\nTo do this, we need to know how many buildings are in each grid cell. We have\nalready learned how to count crimes in areas when we learned about mapping area\ndata. When we want to count crimes in each cell in a grid, we can use the \n`hotspot_count()` function from the `sfhotspot` package to count the number of\nbuildings in each grid cell. We will then be able to combine those building \ncounts to the estimates of burglary risk we have already calculated.\n\n\n::: {.box .notewell}\n\nSo that we can join the building counts to the burglary risk estimates, it is\nimportant that both layers are based on the same grid. In the code above we\ncreated a grid with the code `hotspot_grid(wards, cell_size = 100)`, so to make\nsure we use the same grid to count buildings we can either use that same code\nagain, or we could have saved the result of that code as an object (maybe called\n`nottingham_wards_grid`) and then provided that object to the `grid` argument of\nboth `hotspot_dual_kde()` and `hotspot_count()`.\n\nNote that the results of `hotspot_dual_kde()` and `hotspot_count()` will only\nhave the same structure before we wrangle then any further, for example by using\n`filter()` as in the previous section. This is why we saved an unfiltered \nversion of the dataset in the `burglary_risk` object.\n\n:::\n\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nbuilding_counts <- hotspot_count(\n  nottingham_building_centroids, \n  grid = hotspot_grid(wards, cell_size = 100)\n) |> \n  # Clip the result to the area for which we have data\n  st_intersection(wards)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(building_counts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 455826.6 ymin: 338782.9 xmax: 456354.2 ymax: 338909\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 6 × 4\n      n ward_code ward_name                                             geometry\n  <dbl> <chr>     <chr>                                            <POLYGON [m]>\n1     0 E05012277 Castle    ((456061.5 338809, 456061.5 338799.8, 456006.6 3388…\n2     0 E05012277 Castle    ((456061.5 338809, 456161.5 338809, 456161.5 338790…\n3     1 E05012277 Castle    ((456161.5 338809, 456261.5 338809, 456261.5 338786…\n4     1 E05012277 Castle    ((456261.5 338809, 456354.2 338809, 456261.5 338786…\n5     2 E05012277 Castle    ((455861.5 338909, 455861.5 338888.8, 455826.6 3389…\n6     4 E05012277 Castle    ((455861.5 338909, 455961.5 338909, 455961.5 338830…\n```\n\n\n:::\n:::\n\n\n\n\nThe `building_counts` and `burglary_risk` objects have the same structure: each\nrow represents a cell in the same grid, and the rows are in the same order \n(because both grids were created by identical calls to `hotspot_grid()`). This\nmeans we can combine the two objects using the `bind_cols()` function from the \n`dplyr` package (part of the tidyverse). \n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nburglary_risk_bldg <- bind_cols(burglary_risk, building_counts)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNew names:\n• `n` -> `n...1`\n• `ward_code` -> `ward_code...3`\n• `ward_name` -> `ward_name...4`\n• `geometry` -> `geometry...5`\n• `n` -> `n...6`\n• `ward_code` -> `ward_code...7`\n• `ward_name` -> `ward_name...8`\n• `geometry` -> `geometry...9`\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(burglary_risk_bldg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 9\n  n...1    kde ward_code...3 ward_name...4                    geometry...5 n...6\n  <dbl>  <dbl> <chr>         <chr>                           <POLYGON [m]> <dbl>\n1     0 0.0175 E05012277     Castle        ((456061.5 338809, 456061.5 33…     0\n2     0 0.0172 E05012277     Castle        ((456061.5 338809, 456161.5 33…     0\n3     0 0.0222 E05012277     Castle        ((456161.5 338809, 456261.5 33…     1\n4     0 0.0271 E05012277     Castle        ((456261.5 338809, 456354.2 33…     1\n5     0 0.0204 E05012277     Castle        ((455861.5 338909, 455861.5 33…     2\n6     0 0.0264 E05012277     Castle        ((455861.5 338909, 455961.5 33…     4\n# ℹ 3 more variables: ward_code...7 <chr>, ward_name...8 <chr>,\n#   geometry...9 <POLYGON [m]>\n```\n\n\n:::\n:::\n\n\n\n\nLooking at this object, we can see that `bind_cols()` has changed the column\nnames. This is because some of the column names were duplicated across the two\ndatasets. Some of these new column names, such as `ward_code...3` would be\ndifficult to work with, so lets go back and remove duplicate columns before we\ncombine the two datasets together.\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nburglary_risk_bldg <- burglary_risk |> \n  # Keep only the `n` and `kde` columns, renaming `n` to `burglary_count`\n  # because there is also a column called `n` in the `building_counts` object\n  select(burglary_count = n, kde) |> \n  # Remove the geometry column (since an identical one exists in \n  # `building_counts`). Note that we do this separately because we can't use\n  # `select()` to remove the `geometry` column.\n  st_drop_geometry() |> \n  bind_cols(building_counts) |> \n  # After calling `bind_cols()` it is safe to use `filter()` to wrangle the\n  # data\n  filter(is.finite(kde))\n```\n:::\n\n\n\n\nWe can now order the dataset with the cells with highest burglary risk at the \ntop and calculate the *cumulative total* (also called a running total) of \nbuildings using the `cumsum()` function. We can use this running total to find \nthe 100 buildings in the cells with highest burglary risk.\n\n\n\n\n::: {.cell exercise='true' exercise.lines='13'}\n\n:::\n\n\n\n\nWe could now plot the `cells_for_prevention` object on a map to show the grid\ncells containing the buildings that would receive the crime-prevention visits.\nWe could also use `st_join()` to join those cells to the dataset of buildings\nin the `nottingham_building_centroids` object, which would give us a list of\nbuildings to visit.\n\n\n\n### Distinguishing hotspots from random variation\n\nThe density maps below show density estimates based on 1,000 points placed \ncompletely at random on 16 different maps. There are no real patterns in the \ndata except for statistical noise. Nevertheless, the KDE process makes it appear \nthat there are patterns in the data (if you reload this tutorial, these maps \nwill change appearance completely, since the random numbers used for the x and y \nco-ordinates of the points will be regenerated).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntibble(\n  x = runif(n = 1000 * 16, min = 0, max = 100), \n  y = runif(n = 1000 * 16, min = 0, max = 100),\n  group = rep(1:16, each = 1000)\n)  |>  \n  ggplot() + \n  geom_density_2d_filled(aes(x, y), bins = 9) + \n  scale_fill_brewer(\n    labels = c(\"lower\", rep(\"\", 7), \"higher\"),\n    palette = \"Oranges\", \n    direction = 1,\n    guide = guide_legend(reverse = TRUE)\n  ) +\n  facet_wrap(vars(group), ncol = 4) +\n  coord_fixed() +\n  labs(fill = \"density\") +\n  theme_void() +\n  theme(strip.text = element_blank())\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/random-map-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\nThis is a problem because we might end up responding to an apparent problem that\nis nothing but an artefact of the random variation that we expect to see in many\nprocesses, including crime.\n\nIf the police and other agencies looked at these patterns and did nothing in\nresponse to them, it is likely that over time some of the areas with high\ndensity would become areas of low density, and _vice versa_. However, the harm\ncaused by crime means it is very hard for agencies to justify sitting back and\ndo nothing to respond to it -- many people would consider it immoral to do so.\nSo police and other agencies are very likely to try to respond to crime \npatterns, even if those patterns might have occurred by chance. This is very\nfrustrating, because if we were to go back and look at the same data in a few\nmonths time it is very likely that the apparent hotspots would have shifted to\nsomewhere different, making all the effort spent in responding to crime seem\nworthless (which, if the apparent patterns were actually artefacts of the KDE\nprocess, it may have been).\n\nYou might be thinking it's better safe than sorry, and that police should \nrespond to the apparent patterns just in case they represent real concentrations\nin crime. But police resources are always scarce, so responding to one problem \nin one place means not responding to another problem in another place. This is\nknown as the _opportunity cost_ of acting: if police focus their limited \nresources in one area, that comes at the cost of not being able to deploy those\nresources in other areas that might need it more.\n\nWe can try to avoid this problem of wasting resources responding to random\nvariation in crime by determining whether the number of crimes in an area is\nmore than the greatest number we would reasonably expect if there were no actual\npatterns in the data (if you have studied statistics before, you might recognise\nthis as a description of a *null hypothesis*, but you don't need to have studied\nstatistics to apply the techniques in this course).\n\nTo determine if the number of crimes in each area is greater than we would \nexpect by chance, we can use the *Getis-Ord Gi\\* statistic* (also called the\n*local G* statistic, spoken out-loud as the *G-I star statistic*). If the Gi* \nstatistic for an area is greater than a certain value, we can say that the \nnumber of crimes in that area is higher than we would expect if there were no \npatterns in the data. We will call areas with more crimes than we would expect\nby chance as _hotspots_.\n\nTo see how this is done, watch this video that walks through the code needed to \nmake a hotspot map using the Gi* statistic.\n\n\n\n\n{{< video https://youtu.be/VhVBfvfp8OY >}}\n\n\n\n\n\n\nWe can calculate the Gi* statistic using the `hotspot_gistar()` function from \nthe `sfhotspot` package. This works in a similar way to the `hotspot_kde()`\nfunction, in that it takes an SF object of the locations of crimes and returns \nan SF object with a grid of cells, along with the Gi* value for each grid cell.\nLike `hotspot_kde()`, `hotspot_gistar()` will choose default values for several\nways in which we could fine-tune the calculation of the Gi* statistic, but we \ncould over-ride these defaults if we wanted to.\n\nIn this example, we will find the hotspots of robbery in Nottingham in 2020,\nbased on a grid of 100-metre cells. We will store this in an object called\n`robbery`, transform it to use the British National Grid co-ordinate system (so\nwe can specify the cell size in metres) and then use the resulting object to \ncalculate the Gi* values.\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nrobbery <- read_csv(\"https://mpjashby.github.io/crimemappingdata/nottingham_robbery.csv.gz\") |> \n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) |> \n  st_transform(27700)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 555 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): location, lsoa_code\ndbl  (2): longitude, latitude\ndate (1): month\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nrobbery_gistar <- hotspot_gistar(robbery, cell_size = 100, quiet = TRUE)\n\n# Use the `sample_n()` function from the `dplyr` package to return a random\n# sample of 10 rows from the result\nsample_n(robbery_gistar, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 10 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 451367.5 ymin: 334874.1 xmax: 456867.5 ymax: 345774.1\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 10 × 5\n       n   kde gistar pvalue                                            geometry\n * <dbl> <dbl>  <dbl>  <dbl>                                       <POLYGON [m]>\n 1     0 32.9  -0.498  0.618 ((454667.5 344874.1, 454667.5 344974.1, 454767.5 3…\n 2     0 23.3   0.331  0.741 ((455267.5 339074.1, 455267.5 339174.1, 455367.5 3…\n 3     0  7.62 -0.498  0.618 ((455967.5 337774.1, 455967.5 337874.1, 456067.5 3…\n 4     0 14.7  -0.498  0.618 ((453067.5 344174.1, 453067.5 344274.1, 453167.5 3…\n 5     0  4.44 -0.407  0.684 ((452367.5 344774.1, 452367.5 344874.1, 452467.5 3…\n 6     0  4.71 -0.498  0.618 ((454567.5 335874.1, 454567.5 335974.1, 454667.5 3…\n 7     0 19.4  -0.498  0.618 ((454867.5 334874.1, 454867.5 334974.1, 454967.5 3…\n 8     0  5.66 -0.498  0.618 ((451367.5 339674.1, 451367.5 339774.1, 451467.5 3…\n 9     1 12.0   0.331  0.741 ((456767.5 345674.1, 456767.5 345774.1, 456867.5 3…\n10     0 15.8   0.331  0.741 ((452667.5 343074.1, 452667.5 343174.1, 452767.5 3…\n```\n\n\n:::\n:::\n\n\n\n\nThe `robbery_gistar` object contains one row for each cell in a grid of cells\ncovering the area of the robbery data. Each row has four columns:\n\n  * `n` shows the number of robberies that occurred in that grid cell,\n  * `kde` shows the density of robberies in that cell,\n  * `gistar` shows the Gi* value for that cell, and\n  * `pvalue` shows the $p$-value for that cell.\n\nThe Gi* statistic is an example of a more general group of statistics called\n$Z$ *scores*. Statisticians and data analysts compare the $Z$ scores produced by \nstatistical procedures such as `hotspot_gistar()` to reference values to decide \nif a $Z$ score is large enough to be treated as statistically significant, i.e. \nif it is large enough to conclude that it is larger than we would expect if \nthere were no actual patterns in the data. Deciding on the right reference value \nto compare a $Z$ score to can be difficult because of what's known as the \nmultiple comparison problem (which we don't need to go into detail about).\nFortunately, the values in the `pvalue` column have already been automatically\nadjusted to take account of the multiple comparison problem, so we can interpret \nthe $p$-values instead of interpreting the Gi* statistic directly.\n\n\n::: {.box .notewell}\n\nSince Gi* is a relative measure, if you have data for a large area (e.g. a \ncountry) but only want to show data for a smaller area (e.g. a city), the Gi* \nvalues will be influenced by the large areas with no crime and all of the city \nis likely to be identified as a hotspot. To prevent this, it is important to \nclip the dataset before calculating the Gi* values, as well as then clipping \nafterwards where necessary.\n\n:::\n\n\nBy convention, $p$-values are considered to be significant if they are _less \nthan 0.05_. So if $p<0.05$, we can say that the number of robberies occurring in \na given grid cell is significantly different from zero. Values of Gi* greater \nthan zero indicate cells with more robberies than expected and values of Gi* \nless than zero indicate cells with fewer robberies than expected. We can combine \nthese two values to find cells with significantly _more_ robberies than expected\nby chance, which are those cells for which $Z>0$ and $p<0.05$. To put that into\nR code, we would write `gistar > 0` and `p < 0.05`.\n\nWe could use this information in various ways. For example, if we wanted to give\nlocal police officers a printed map of which areas to patrol, we could simply\nshow the significant hotspot cells over a base map.\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\n# Plot a map\nggplot() +\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  geom_sf(\n    data = filter(robbery_gistar, gistar > 0, pvalue < 0.05), \n    fill = \"red\", \n    alpha = 0.75,\n    colour = NA\n  ) +\n  fixed_plot_aspect() +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/hotspot-exercise4-1.png){width=100%}\n:::\n:::\n\n\n\n\nSince `hotspot_gistar()` also estimates density for each grid cell, we could \nmore usefully show the density of robberies in each cell, but only for cells \nthat the Gi* values showed were significant hotspots.\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nggplot() +\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  geom_sf(\n    aes(fill = kde),\n    data = filter(robbery_gistar, gistar > 0, pvalue < 0.05), \n    alpha = 0.75,\n    colour = NA\n  ) +\n  scale_fill_distiller(direction = 1) + \n  fixed_plot_aspect() +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/hotspot-exercise5-1.png){width=100%}\n:::\n:::\n\n\n\n\nThis map could be very useful for police officers deciding where to conduct\nanti-robbery patrols, because it not only shows the areas with the highest\ndensity of robberies but only shows those areas if there are more robberies\nthan we would expect by chance. This makes it more likely that officers won't\nwaste time chasing apparent patterns that are actually the result of random\nvariation.\n\n\n### Check your understanding {.tutorial}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquiz(\n  caption = \"\",\n\n  question(\"`robbery_gi` is an object storing a result produced by the `hotspot_gistar()` function. Which of these pieces of code could be used to extract _only_ those rows in the data with significant p-values?\",\n    answer(\"`filter(robbery_gi, pvalue < 0.05)`\", correct = TRUE),\n    answer(\n      \"`filter(robbery_gi, pvalue > 0.05)`\",\n      message = \"That code would extract only _non-significant_ p-values. Try again!\"\n    ),\n    answer(\n      \"`filter(robbery_gi, pvalue <= 0.05)`\",\n      message = \"Almost right, but not quite. Try re-reading the section of the tutorial above.\"\n    ),\n    answer(\n      \"`filter(robbery_gi, pvalue == 0.05)`\",\n      message = \"That's not right. Try re-reading the section of the tutorial above.\"\n    ),\n    allow_retry = TRUE,\n    random_answer_order = TRUE\n  ),\n  \n  question(\"Which *one* of these statements is true about an SF object called `robberies_in_nottingham`?\",\n    answer(\"We cannot remove the `geometry` column of an SF object with `select()`, so we must use `st_drop_geometry()` instead.\", correct = TRUE),\n    answer(\"We can remove the `geometry` column with the code `select(robberies_in_nottingham, -geometry)`.\"),\n    answer(\"We can remove the `geometry` column with the code `filter(robberies_in_nottingham, -geometry)`.\"),\n    answer(\"There is no way to remove the `geometry` column from an SF object.\"),\n    allow_retry = TRUE,\n    random_answer_order = TRUE\n  )\n)\n```\n:::\n\n\n\n\n\n\n## Putting it all together\n\n::: {.box .welldone}\n\nIn this tutorial we have learned about hotspots, how to create dual KDE maps and \nhow to find significant hotspots using the Gi* statistic. We can put this all\ntogether to create a complete script for producing a map of robbery hotspots in\nNottingham\n\n:::\n\nThe following code is all that is needed to produce this map. Read through the\ncomments accompanying the code to see how what we have learned in this tutorial\nfits together, then run the code to produce the map. \n\n\n::: {.box .notewell}\n\nIt is possible that this code will not run in this tutorial window because of \nlimits on how long code can run in an R tutorial. If that happens, paste the \ncode below into a blank R script in RStudio and run it from there to see the \nmap.\n\n:::\n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='66'}\n\n```{.r .cell-code}\n# Prepare ----------------------------------------------------------------------\n\n# Load packages\nlibrary(ggspatial)\nlibrary(sf)\nlibrary(sfhotspot)\nlibrary(tidyverse)\n\n# Load data and transform to British National Grid, which is easier to work with\n# for functions that use spatial units such as metres\nrobbery <- read_csv(\"https://mpjashby.github.io/crimemappingdata/nottingham_robbery.csv.gz\") |> \n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = \"EPSG:4326\") |> \n  st_transform(\"EPSG:27700\")\nnottingham_wards <- read_sf(\"https://mpjashby.github.io/crimemappingdata/nottingham_wards.gpkg\") |> \n  st_transform(\"EPSG:27700\")\n\n\n# Find significant grid cells --------------------------------------------------\n\n# Calculate Gi* statistic, filter for only significant hotspot cells and clip to\n# the city boundary\nrobbery_gi <- robbery |> \n  hotspot_gistar(cell_size = 100, bandwidth_adjust = 0.25, quiet = TRUE) |> \n  filter(gistar > 0, pvalue < 0.05) |> \n  st_intersection(nottingham_wards)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n```\n\n\n:::\n\n```{.r .cell-code}\n# Plot map ---------------------------------------------------------------------\n\nggplot() + \n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  # Add density for significant cells\n  geom_sf(\n    aes(fill = kde), \n    data = robbery_gi, \n    alpha = 0.8,\n    colour = NA\n  ) +\n  # Add ward boundaries\n  geom_sf(data = nottingham_wards, colour = \"grey70\", fill = NA) +\n  scale_fill_distiller(\n    breaks = range(pull(robbery_gi, kde)),\n    labels = c(\"lower\", \"higher\"),\n    direction = 1\n  ) +\n  fixed_plot_aspect() +\n  labs(\n      title = \"Nottingham robbery hotspots\",\n      subtitle = str_glue(\n        \"density of robbery in places with more violence than expected by \",\n        \"chance\"\n      ),\n      # Don't forget to add the licence statement -- it's a legal requirement!\n      caption = str_glue(\n        \"Contains public sector information licensed under the Open \",\n        \"Government Licence v3.0. Map data from OpenStreetMap.\"\n      ),\n      fill = str_wrap(\"density of robbery at significant hotspots, 2022\", 15)\n  ) +\n  theme_void() +\n  theme(\n    plot.caption = element_text(colour = \"grey40\", hjust = 0),\n    plot.subtitle = element_text(margin = margin(t = 6, b = 6)),\n    plot.title = element_text(colour = \"grey50\", face = \"bold\", size = 16)\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/final-exercise1-1.png){width=100%}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}