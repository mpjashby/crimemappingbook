{
  "hash": "42413b2f67c1c9291ed9fee140dc35cc",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexecute:\n  freeze: auto\n---\n\n\n\n\n# Mapping crime over time {#sec-mapping-time}\n\n\n::: {.abstract}\nUnderstanding how crime varies over time is essential for effective crime analysis. This chapter introduces techniques for readers identifying short-term and long-term variations in crime. You will learn how to handle date and time data, visualize temporal changes, and create animated maps to illustrate crime trends dynamically. \n:::\n\n\n::: {.callout-tip}\n#### Before you start\n\nOpen RStudio or -- if you already have RStudio open -- click `Session` then `Restart R`. Make sure you're working inside the Crime Mapping RStudio project you created in @sec-create-project, then you're ready to start mapping.\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Introduction\n\nUnderstanding how crime varies over time is just as important as understanding how it varies between places. Very few places are hotspots of crime all the time -- business districts might be hotspots of pickpocketing in the daytime but deserted at night, while a nearby entertainment district may be quiet in the daytime but a violence hotspot at night.\n\nCrime varies over time in lots of ways. For example, there was a long-term drop in many types of crime in many countries starting in the mid 1990s, e.g. [residential burglary in England and Wales dropped by 67% between 1993 and 2008](https://crimesciencejournal.biomedcentral.com/articles/10.1186/s40163-016-0051-z) while the number of [homicides in New York City dropped almost 90% from 2,245 in 1990 to 289 in 2018](https://www.brennancenter.org/our-work/analysis-opinion/takeaways-2019-crime-data-major-american-cities).\n\nThere are also short-term variations in crime. Many types of crime are more common at some types of year than others (known as *seasonal variation*). In Chicago, for example, assaults, residential burglaries and personal robberies all vary throughout the year, with assaults in particular being consistently higher in summer than winter.\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n<p class=\"full-width-image\"><img src=\"../images/chicago_seasonal_variation.png\" alt=\"Chart showing that assaults, personal robberies and residential burglaries in Chicago all vary by seasonally throughout the year.\"></p>\n\nIt is also important to understand short-term variation in crime. For example, both property damage and sexual violence in Chicago peaks at weekends, while there are fewer shoplifting offences on Sundays when some shops are closed or have shorter opening hours.\n\n<p class=\"full-width-image\"><img src=\"../images/chicago_weekly_variation.png\" alt=\"Chart showing that property damage, sexual violence and shoplifting in Chicago all vary by day of the week.\"></p>\n\nUnderstanding variation in crime over time is important because we can use the temporal concentration of crime to focus efforts to respond to crime most effectively. For example, imagine we wanted to deploy police patrols to a hotspot to respond to a particular crime problem. Such patrols could be very effective if they were targeted at the times when crimes were most likely to happen or completely useless if the officers were deployed at the wrong day or the wrong time.\n\nIn this chapter we will learn how to incorporate variation over time into our analysis of where crime happens, including making animated maps like this one:\n\n<p class=\"centered-image\"><img src=\"../images/chicago_downtown_agg_assaults.gif\" alt=\"Animated map showing how the density of aggravated assaults in Chicago varies throughout the hours of the day.\"></p>\n\n\n::: {.callout-quiz .callout}\n#### Analysing temporal variation in crime\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n**Is it important to think about variation over time when analysing crime patterns?**\n\n<div class='webex-radiogroup' id='radio_CDBVMWUYMD'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CDBVMWUYMD\" value=\"\"></input> <span>No, because hotspots of crime are usually hotspots at all times</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CDBVMWUYMD\" value=\"answer\"></input> <span>Yes, because many crime hotspots are only hotspots some of the time</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CDBVMWUYMD\" value=\"\"></input> <span>No, because spatial variation in crime is usually much more important than temporal variation</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CDBVMWUYMD\" value=\"\"></input> <span>Yes, because crime prevention depends more on when crime occurrs than on where it occurrs</span></label></div>\n\n\n**Which of the following statements about seasonal variations in crime is correct?**\n\n<div class='webex-radiogroup' id='radio_NMBLENFUVU'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NMBLENFUVU\" value=\"\"></input> <span>Almost all types of crime are more common in the winter than in the summer</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NMBLENFUVU\" value=\"\"></input> <span>Almost all types of crime are more common in the summer than in the winter</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NMBLENFUVU\" value=\"answer\"></input> <span>Different types of crime are more common at different times of year</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NMBLENFUVU\" value=\"\"></input> <span>Most types of crime occur at the same frequency at all times of year</span></label></div>\n\n\n\n:::\n\n\n\n## Handling dates in R\n\n<p class=\"full-width-image\"><img src=\"../images/lubridate_cartoon.jpg\" alt=\"Cartoon showing little monsters feeding lubridate functions into a Back-to-the-Future-style car with the licence plate LUBRDAT.\"></p>\n\nAt a very basic level, computers can store data in two ways: they can store numbers and they can store text. This makes storing dates slightly complicated, because dates aren't completely like numbers and they aren't completely like text either. Dates aren't like numbers because you can't do normal maths with dates (e.g. what date is the 29th of January plus one month?) and aren't like text because you can do some maths with them (e.g. it is easy to calculate three days from today). Dates are especially complicated because they can be written as text in so many different ways. For example 17 January can be represented in all of these ways, all of them equally valid (although some are specific to particular countries):\n\n  * 17/01/2025\n  * 17.01.25\n  * 1/17/2025\n  * 2025-01-17\n  * 17 Jan 25\n  * 17 January 2025\n  * January 17th 2025\n\n\n<a href=\"https://lubridate.tidyverse.org/\" title=\"lubridate website\"><img src=\"../images/lubridate.png\" class=\"right-side-image\"></a>\n\nR deals with this problem by _storing_ dates internally as if they were numbers and _displaying_ them (e.g. in the console or in a Quarto document) as if they were text, by default in the format `2025-03-18`. Fortunately, we don't have to worry about how dates and times are stored internally in R because we can use the [lubridate package](https://lubridate.tidyverse.org/) to work with them. lubridate contains functions for working with dates, including extracting parts of a date with functions such as `month()` and converting text to date values with functions like `ymd()`.\n\nBecause of the special nature of dates, if we want to work with a date variable (for example to create a chart of crime over time) it is important that it is stored as a date, not as text or as a number. Many R functions for reading data, including `read_csv()`, `read_tsv()` and `read_excel()`, will try to recognise columns of data that contain dates and times stored in common formats. These will automatically be stored as date variables when the data is loaded. \n\nIf R does not recognise automatically that a value contains a date, we can convert it to a date by using the date-parsing functions from lubridate. Which function to use depends on the order in which the components of the date (e.g. day, month and year) appear in the variable. For example, to convert the text \"17 January 1981\" to a date format we can use the `dmy()` function because the **d**ay of the month comes first, the **m**onth next and then the **y**ear. Similarly, converting the text \"01/17/81\" needs the function `mdy()`. Note that the lubridate date-parsing functions are able convert both numeric and text-based months, and to ignore elements that aren't needed for the conversation, such as weekday names.\n\nIf a date is stored in multiple columns in a dataset, e.g. one column for the year, one column for the month and one column for the day, we can create a single date column using the `make_date()` function to combine them. Similarly, we can create a date-time column using the `make_datetime()` function. For example, imagine we have a dataset of crimes called `thefts`:\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"nyqlbdojot\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#nyqlbdojot table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#nyqlbdojot thead, #nyqlbdojot tbody, #nyqlbdojot tfoot, #nyqlbdojot tr, #nyqlbdojot td, #nyqlbdojot th {\n  border-style: none;\n}\n\n#nyqlbdojot p {\n  margin: 0;\n  padding: 0;\n}\n\n#nyqlbdojot .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#nyqlbdojot .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#nyqlbdojot .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#nyqlbdojot .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#nyqlbdojot .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#nyqlbdojot .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#nyqlbdojot .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#nyqlbdojot .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#nyqlbdojot .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#nyqlbdojot .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#nyqlbdojot .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#nyqlbdojot .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#nyqlbdojot .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#nyqlbdojot .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#nyqlbdojot .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#nyqlbdojot .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#nyqlbdojot .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#nyqlbdojot .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#nyqlbdojot .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nyqlbdojot .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#nyqlbdojot .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#nyqlbdojot .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#nyqlbdojot .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nyqlbdojot .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#nyqlbdojot .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#nyqlbdojot .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#nyqlbdojot .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nyqlbdojot .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#nyqlbdojot .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#nyqlbdojot .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#nyqlbdojot .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#nyqlbdojot .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#nyqlbdojot .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nyqlbdojot .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#nyqlbdojot .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nyqlbdojot .gt_left {\n  text-align: left;\n}\n\n#nyqlbdojot .gt_center {\n  text-align: center;\n}\n\n#nyqlbdojot .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#nyqlbdojot .gt_font_normal {\n  font-weight: normal;\n}\n\n#nyqlbdojot .gt_font_bold {\n  font-weight: bold;\n}\n\n#nyqlbdojot .gt_font_italic {\n  font-style: italic;\n}\n\n#nyqlbdojot .gt_super {\n  font-size: 65%;\n}\n\n#nyqlbdojot .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#nyqlbdojot .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#nyqlbdojot .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#nyqlbdojot .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#nyqlbdojot .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#nyqlbdojot .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#nyqlbdojot .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#nyqlbdojot .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#nyqlbdojot div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"year\">year</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"month_of_year\">month_of_year</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"day_of_month\">day_of_month</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"hour\">hour</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"minute\">minute</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"x\">x</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"y\">y</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"year\" class=\"gt_row gt_right\">2020</td>\n<td headers=\"month_of_year\" class=\"gt_row gt_right\">9</td>\n<td headers=\"day_of_month\" class=\"gt_row gt_right\">2</td>\n<td headers=\"hour\" class=\"gt_row gt_right\">18</td>\n<td headers=\"minute\" class=\"gt_row gt_right\">0</td>\n<td headers=\"x\" class=\"gt_row gt_right\">494582.9</td>\n<td headers=\"y\" class=\"gt_row gt_right\">5457918</td></tr>\n    <tr><td headers=\"year\" class=\"gt_row gt_right\">2020</td>\n<td headers=\"month_of_year\" class=\"gt_row gt_right\">9</td>\n<td headers=\"day_of_month\" class=\"gt_row gt_right\">3</td>\n<td headers=\"hour\" class=\"gt_row gt_right\">0</td>\n<td headers=\"minute\" class=\"gt_row gt_right\">0</td>\n<td headers=\"x\" class=\"gt_row gt_right\">491616.0</td>\n<td headers=\"y\" class=\"gt_row gt_right\">5459278</td></tr>\n    <tr><td headers=\"year\" class=\"gt_row gt_right\">2020</td>\n<td headers=\"month_of_year\" class=\"gt_row gt_right\">9</td>\n<td headers=\"day_of_month\" class=\"gt_row gt_right\">3</td>\n<td headers=\"hour\" class=\"gt_row gt_right\">21</td>\n<td headers=\"minute\" class=\"gt_row gt_right\">0</td>\n<td headers=\"x\" class=\"gt_row gt_right\">494921.9</td>\n<td headers=\"y\" class=\"gt_row gt_right\">5456620</td></tr>\n    <tr><td headers=\"year\" class=\"gt_row gt_right\">2020</td>\n<td headers=\"month_of_year\" class=\"gt_row gt_right\">9</td>\n<td headers=\"day_of_month\" class=\"gt_row gt_right\">3</td>\n<td headers=\"hour\" class=\"gt_row gt_right\">23</td>\n<td headers=\"minute\" class=\"gt_row gt_right\">0</td>\n<td headers=\"x\" class=\"gt_row gt_right\">487343.6</td>\n<td headers=\"y\" class=\"gt_row gt_right\">5457417</td></tr>\n    <tr><td headers=\"year\" class=\"gt_row gt_right\">2020</td>\n<td headers=\"month_of_year\" class=\"gt_row gt_right\">9</td>\n<td headers=\"day_of_month\" class=\"gt_row gt_right\">10</td>\n<td headers=\"hour\" class=\"gt_row gt_right\">13</td>\n<td headers=\"minute\" class=\"gt_row gt_right\">0</td>\n<td headers=\"x\" class=\"gt_row gt_right\">486631.2</td>\n<td headers=\"y\" class=\"gt_row gt_right\">5455385</td></tr>\n    <tr><td headers=\"year\" class=\"gt_row gt_right\">2020</td>\n<td headers=\"month_of_year\" class=\"gt_row gt_right\">9</td>\n<td headers=\"day_of_month\" class=\"gt_row gt_right\">13</td>\n<td headers=\"hour\" class=\"gt_row gt_right\">18</td>\n<td headers=\"minute\" class=\"gt_row gt_right\">0</td>\n<td headers=\"x\" class=\"gt_row gt_right\">484901.1</td>\n<td headers=\"y\" class=\"gt_row gt_right\">5456897</td></tr>\n    <tr><td headers=\"year\" class=\"gt_row gt_right\">2020</td>\n<td headers=\"month_of_year\" class=\"gt_row gt_right\">9</td>\n<td headers=\"day_of_month\" class=\"gt_row gt_right\">14</td>\n<td headers=\"hour\" class=\"gt_row gt_right\">16</td>\n<td headers=\"minute\" class=\"gt_row gt_right\">15</td>\n<td headers=\"x\" class=\"gt_row gt_right\">491116.9</td>\n<td headers=\"y\" class=\"gt_row gt_right\">5458996</td></tr>\n    <tr><td headers=\"year\" class=\"gt_row gt_right\">2020</td>\n<td headers=\"month_of_year\" class=\"gt_row gt_right\">9</td>\n<td headers=\"day_of_month\" class=\"gt_row gt_right\">22</td>\n<td headers=\"hour\" class=\"gt_row gt_right\">15</td>\n<td headers=\"minute\" class=\"gt_row gt_right\">50</td>\n<td headers=\"x\" class=\"gt_row gt_right\">498229.3</td>\n<td headers=\"y\" class=\"gt_row gt_right\">5453280</td></tr>\n    <tr><td headers=\"year\" class=\"gt_row gt_right\">2020</td>\n<td headers=\"month_of_year\" class=\"gt_row gt_right\">9</td>\n<td headers=\"day_of_month\" class=\"gt_row gt_right\">24</td>\n<td headers=\"hour\" class=\"gt_row gt_right\">22</td>\n<td headers=\"minute\" class=\"gt_row gt_right\">0</td>\n<td headers=\"x\" class=\"gt_row gt_right\">496839.3</td>\n<td headers=\"y\" class=\"gt_row gt_right\">5450338</td></tr>\n    <tr><td headers=\"year\" class=\"gt_row gt_right\">2020</td>\n<td headers=\"month_of_year\" class=\"gt_row gt_right\">9</td>\n<td headers=\"day_of_month\" class=\"gt_row gt_right\">28</td>\n<td headers=\"hour\" class=\"gt_row gt_right\">13</td>\n<td headers=\"minute\" class=\"gt_row gt_right\">30</td>\n<td headers=\"x\" class=\"gt_row gt_right\">491827.1</td>\n<td headers=\"y\" class=\"gt_row gt_right\">5459080</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n\nWe could use the three columns `year`, `month_of_year` and `day_of_month` to create a column containing the full date using the code:\n\n\n\n\n::: {.cell filename='Hypothetical code'}\n\n```{.r .cell-code}\nthefts |> \n  mutate(\n    date = make_date(year = year, month = month_of_year, day = day_of_month)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,840 × 8\n    year month_of_year day_of_month  hour minute       x        y date      \n   <dbl>         <dbl>        <dbl> <dbl>  <dbl>   <dbl>    <dbl> <date>    \n 1  2020             9            1     0      0 490778. 5458771. 2020-09-01\n 2  2020             9            1     0      0 492552. 5456983. 2020-09-01\n 3  2020             9            1     0      0 495975. 5456581. 2020-09-01\n 4  2020             9            1     0      0 498185. 5453781. 2020-09-01\n 5  2020             9            1     0      0 490318. 5454515. 2020-09-01\n 6  2020             9            1     0      0 493661. 5458708. 2020-09-01\n 7  2020             9            1     0      0 492757. 5458792. 2020-09-01\n 8  2020             9            1     0      0 497944. 5458721. 2020-09-01\n 9  2020             9            1     1      0 489018. 5457169. 2020-09-01\n10  2020             9            1     2      8 493537. 5454987. 2020-09-01\n# ℹ 1,830 more rows\n```\n\n\n:::\n:::\n\n\n\n\nOnce we have converted dates stored as text to dates stored as dates, R understands that they are dates and we can do things like compare them. So while running `\"Sat 17 January 1981\" == \"01/17/81\"` to test if two dates are the same would give the answer `FALSE` (because the two pieces of text are different), once we've converted the text to date values R can tell that the two dates are the same:\n\n\n\n\n::: {.cell filename='R Console'}\n\n```{.r .cell-code}\n# This code returns TRUE only because the two pieces of text are identical\n\"Sat 17 January 1981\" == \"Sat 17 January 1981\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n::: {.cell filename='R Console'}\n\n```{.r .cell-code}\n# This code returns FALSE because the two pieces of text are different, even\n# though the dates they represent are the same\n\"Sat 17 January 1981\" == \"01/17/81\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n::: {.cell filename='R Console'}\n\n```{.r .cell-code}\n# This code returns TRUE because R knows they are dates and so compares them as\n# dates, finding that the two dates are the same\ndmy(\"Sat 17 January 1981\") == mdy(\"01/17/81\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n\n\n### Working with dates\n\nWhen analysing dates and times, it is often useful to be able to extract date or time portions. We can do this with the lubridate functions `year()`, `month()`, `wday()` (for day of the week), `mday()` (for day of the month), `yday()` (for day of the year, counting from 1 January), `hour()`, `minute()` and `second()`, each of which extracts the relevant portion of a date or time as a number. The `month()` and `wday()` functions are slightly different, because they can also return the day or month name as text by specifying the argument `label = TRUE`. We can see this by extracting the different portions of the current date and time, which we can retrieve with the `now()` function from lubridate.\n\n\n\n\n\n::: {.cell filename='R Console'}\n\n```{.r .cell-code}\nmessage(\"Current year: \", year(now()))\nmessage(\"Current month (as a number): \", month(now()))\nmessage(\"Current month (as text, abbreviated): \", month(now(), label = TRUE))\nmessage(\"Current month (as text): \", month(now(), label = TRUE, abbr = FALSE))\nmessage(\"Current day of the year (days since 1 Jan): \", yday(now()))\nmessage(\"Current day of the month: \", mday(now()))\nmessage(\"Current day of the week (as a number): \", wday(now()))\nmessage(\"Current day of the week (as text): \", wday(now(), label = TRUE))\nmessage(\"Current hour of the day: \", hour(now()))\nmessage(\"Current minute: \", minute(now()))\nmessage(\"Current second: \", second(now()))\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent year: 2025\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent month (as a number): 3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent month (as text, abbreviated): Mar\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent month (as text): March\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent day of the year (days since 1 Jan): 77\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent day of the month: 18\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent day of the week (as a number): 3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent day of the week (as text): Tue\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent hour of the day: 12\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent minute: 43\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent second: 4.4679479598999\n```\n\n\n:::\n:::\n\n\n\n\n\nIt is sometimes useful to be able to add to or subtract from dates. For example, if you wanted to filter a dataset so that only records from the past 28 days were included, you would need to work out the date 28 days ago. We can do this with a group of functions from lubridate that store a period of time that we can then add to or subtract from an existing date. These functions are `years()`, `months()`, `weeks()`, `days()`, `hours()`, `minutes()`, and `seconds()`. \n\n\n::: {.callout-important}\n#### Remember which lubridate functions extract parts of a date and which manipulate them\n\nIn the lubridate package, functions that are used to _extract_ parts of a date are _singular_, e.g. `day()`, `month()`, `year()`. Functions that are used to _manipulate_ dates by adding or subtracting from them are _plural_, e.g. `days()`, `months()`, `years()`. So, for example, you would use the code `month(now())` to extract the month (as a number between 1 and 12) from the current date but the code `now() + months(1)` to find out what the date and time will be one month from now.\n:::\n\n\nTo subtract 28 days from today's date (which we can retrieve with the `today()` function), we would use `today() - days(28)`.\n\n\n\n\n::: {.cell filename='R Console'}\n\n```{.r .cell-code}\nmessage(str_glue(\"Today is {today()} and 28 days ago was {today() - days(28)}\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nToday is 2025-03-18 and 28 days ago was 2025-02-18\n```\n\n\n:::\n:::\n\n\n\n\nAdding or subtracting periods from dates can be very useful when combined with the `filter()` function from the `dplyr()` package. For example, if we had a dataset of crimes stored in an object called `crimes` and wanted to extract only those that occurred in the most-recent seven days, we could do this:\n\n\n\n\n::: {.cell filename='Hypothetical code'}\n\n```{.r .cell-code}\nfilter(crimes, occur_date >= today() - days(7))\n```\n:::\n\n\n\n\n\n\n\nIf we wanted to extract crimes that occurred between two dates, we can use the `between()` function from dplyr, which returns either `TRUE` or `FALSE` depending on whether each item in the first argument is between the values given in the second and third arguments (inclusive).\n\nWhen filtering based on dates or times, it is important to understand that R can store dates in two ways: as a *date* object or as a *date-time* object (shown as `<dttm>` when we print a tibble). Date variables store only a date with no time, while date-time variables always include a time component, even if the data doesn't contain any information about time. If we store a variable that only has information about the date of an event as a date-time variable, R will silently add the time midnight to each date. This is important because if we compare a date variable to a date-time variable, R will silently convert the dates to date-times with the times set to midnight. If we are trying to filter crimes between two times, this might not be what we want. For example, if we used the code:\n\n\n\n\n\n::: {.cell filename='Hypothetical code'}\n\n```{.r .cell-code}\nbetween(offence_date, ymd(\"2021-01-01\"), ymd(\"2021-01-31\"))\n```\n:::\n\n\n\n\n\nto extract all the crimes that occurred in January 2021, that would work as we expected only if `offence_date` was a date variable. If the `offence_date` column instead held dates *and* times, R would filter the data *as if* we had specified:\n\n\n\n\n\n::: {.cell filename='Hypothetical code'}\n\n```{.r .cell-code}\nbetween(offence_date, ymd_hm(\"2021-01-01 00:00\"), ymd_hm(\"2021-01-31 00:00\"))\n```\n:::\n\n\n\n\nwhich would exclude any crimes that occurred on 31 January (except those occurring at exactly midnight). To deal with this problem, we can either check to make sure the variables we are filtering on are date variables, convert them to date variables using the `as_date()` function, or assume that they might be date-time variables and specify the exact time that we want as the end of our range. For example, specifying:\n\n\n\n\n\n::: {.cell filename='Hypothetical code'}\n\n```{.r .cell-code}\nbetween(offence_date, ymd_hm(\"2021-01-01 00:00\"), ymd_hm(\"2021-01-31 23:59\"))\n```\n:::\n\n\n\n\n\nor\n\n\n\n\n\n::: {.cell filename='Hypothetical code'}\n\n```{.r .cell-code}\nbetween(as_date(offence_date), ymd(\"2021-01-01\"), ymd(\"2021-01-31\"))\n```\n:::\n\n\n\n\n\nwould allow us to select all the crimes occurring in January 2021.\n\n\n::: {.callout-quiz .callout}\n#### Handling dates in R\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n**What function from the lubridate package would you use to convert \"17/01/2025\" into a proper date format?**\n\n<div class='webex-radiogroup' id='radio_CFYSFBYOJB'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CFYSFBYOJB\" value=\"\"></input> <span>`mdy(\"17/01/2025\")`</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CFYSFBYOJB\" value=\"answer\"></input> <span>`dmy(\"17/01/2025\")`</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CFYSFBYOJB\" value=\"\"></input> <span>`ymd(\"17/01/2025\")`</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CFYSFBYOJB\" value=\"\"></input> <span>`parse_date(\"17/01/2025\")`</span></label></div>\n\n\n\n**How can you extract the month from a date variable in R?**\n\n<div class='webex-radiogroup' id='radio_MODQJEPIJM'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_MODQJEPIJM\" value=\"\"></input> <span>`extract_month(date)`</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_MODQJEPIJM\" value=\"\"></input> <span>`get_month(date)`</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_MODQJEPIJM\" value=\"answer\"></input> <span>`month(date)`</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_MODQJEPIJM\" value=\"\"></input> <span>`date_month(date)`</span></label></div>\n\n\n\n:::\n\n\n\n## Showing change over time\n\nOne common task in crime analysis is to show how crime changes over time. The simplest way to do this is to produce a *time-series chart*. For example, we can see how the frequency of aggravated assaults recorded by police in Chicago has \nchanged over time:\n\n\n<p class=\"full-width-image\"><img src=\"../images/chicago_assault_trend.png\" alt=\"Chart showing that the weekly frequency of aggravated assaults in Chicago from 2010 to 2019, including seasonal increases each summer and lower frequency of assaults from 2013 to 2015.\"></p>\n\n\nIn this section we will learn how to construct a time-series chart like this. To illustrate this process, we will use an object called `assaults` that contains records of aggravated assaults in Chicago from 2010 to 2019.\n\nOpen a new R script file and save it as `chapter16a.R`. Add this code to the file and run it.\n\n\n\n\n\n::: {.cell filename='chapter16a.R'}\n\n```{.r .cell-code}\n# Load packages\npacman::p_load(ggspatial, sf, sfhotspot, slider, tidyverse)\n\n# Load Chicago aggravated assault data\nassaults <- read_csv(\"https://mpjashby.github.io/crimemappingdata/chicago_aggravated_assaults.csv.gz\")\n\n# Load dataset of Chicago Police Department (CPD) district boundaries\ncpd_districts <- read_sf(\"https://mpjashby.github.io/crimemappingdata/chicago_police_districts.kml\") |> \n  janitor::clean_names() |> \n  # Transform this object to use a suitable local co-ordinate reference system\n  st_transform(\"EPSG:26916\")\n\n# Create a separate dataset holding just the boundaries of the three CPD \n# districts covering the downtown area\ncpd_central <- filter(cpd_districts, name %in% c(\"1\", \"12\", \"18\"))\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 148636 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): loc_cat\ndbl  (3): longitude, latitude, district\ndttm (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n\n\nThe first task in charting the frequency of crime is to choose a temporal *unit of analysis*. For example, the chart above counts the number of crimes each *week*. Weeks are often a good choice as units for counting crimes, since all weeks are the same length and because many human activities have a weekly cycle (e.g. people do different things at weekends than on weekdays, even though which days count as weekdays differs across cultures).\n\n\n::: {.callout-important}\n#### Months are usually a bad choice of temporal unit of analysis\n\nMonths are much less useful than weeks as a temporal unit of analysis because months differ in length, so monthly counts of crime will look like they show some variation even if the amount of crime occurring each day remains constant. For example, if exactly 10 crimes occur every day throughout February and March, there will be 280 or 290 crimes in February (depending on whether it is a leap year) but 310 in March. In these circumstances, it will look like the volume of crime increased by 11% between February and March, not because the rate at which crimes occurred increased but because March is 11% longer than February.\n\nMonths are also less useful because they contain different numbers of each day of the week (e.g. one month might have four Fridays while the next has five) and crimes are typically concentrated on particular days of the week (more on that later). **Avoid using monthly counts of crime** unless you have no choice because the only data you have available is monthly counts.\n:::\n\n\nTo count the number of crimes occurring each week we can use the `count()` function from the dplyr package. But before doing that, we have to allocate each crime to a week so that we can then count those weeks rather than counting days. To do this we use the `floor_date()` function from the lubridate package. This function rounds dates down to the start of a specified unit of time, in this case a week. By default, `floor_date()` treats Sunday as the start of the week and so if the specified unit of time is a week, all dates will be rounded down to the date of the previous Sunday.\n\n`floor_date()` works on date variables, so if we want to use it on a date-time variable we should first convert it to a date variable using the `as_date()` function from lubridate. So to convert a date-time stored in a variable called `date` into the date of the first day of that week, we would use the code `floor_date(as_date(date), unit = \"week\")`.\n\nOne complication of counting incidents by week is that our data might not fit neatly into calendar weeks. For example, if we have data for a particular year and that year started on a Tuesday, the first weekly count will only have data for five days and it will look like there were fewer crimes that week in comparison to other weeks. This could be misleading, since this week only looks like it has less crime because we don't have data for the whole week. The same problem can happen with the last week of data, too. To deal with this, after counting the crimes by week we will remove the first and last row of the data using the `slice()` function from the dplyr package.\n\n\n\n\n\n::: {.cell filename='chapter16a.R'}\n\n```{.r .cell-code}\n# Count number of aggravated assaults each week\nassault_weekly_counts <- assaults |> \n  # Convert offence dates so that it appears each offence happened on the first\n  # day (Sunday) of the week\n  mutate(week_date = floor_date(as_date(date), unit = \"week\")) |> \n  # Count the number of assaults each week\n  count(week_date, name = \"count\") |> \n  # The code `(n() - 1)` gives us the row number of the second-to-last row in \n  # the data because `n()` returns the number of rows in the data. Note the\n  # parentheses!\n  slice(2:(n() - 1))\n```\n:::\n\n::: {.cell filename='R Console'}\n\n```{.r .cell-code}\nhead(assault_weekly_counts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  week_date  count\n  <date>     <int>\n1 2010-01-03   234\n2 2010-01-10   300\n3 2010-01-17   303\n4 2010-01-24   257\n5 2010-01-31   276\n6 2010-02-07   264\n```\n\n\n:::\n:::\n\n\n\n\n\nNow we have weekly counts of aggravated assaults, we can plot them on a chart. The simplest way to do this would be to create a line chart using `ggplot()` with `geom_line()`.\n\n\n\n\n\n::: {.cell filename='R Console'}\n\n```{.r .cell-code}\nggplot(assault_weekly_counts, aes(x = week_date, y = count)) +\n  geom_line() +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThis plot is fine, but there are several things that we can do to make it better. Most importantly, there seems to be lots of short-term fluctuation in the frequency of crime (e.g. from one week to another). While this variation is real, we often refer to it as *noise* because it can obscure the *signal* of longer-term trends (this terminology originally came to statistics -- and therefore crime analysis -- from radio engineering and has become common over time).\n\nWe can reduce the visual impact of this short-term variation on our plot by adding a line showing a *moving average* (also called a *rolling average* or *rolling mean*) of the count of crime over time. A moving average is the average (or mean) of the count of crimes in the current week and a given number of adjacent (in this case, previous), weeks.\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n<p class=\"full-width-image\"><img src=\"../images/moving_averages.png\" alt=\"Chart showing that moving averages are calculated by averaging the current week's count with the counts from a given number of previous weeks.\"></p>\n\n\nSince moving averages show the average count of crime over several weeks, they are less influenced by week-to-week variation. To calculate a moving average we have to choose how many weeks to include (known as the *window* of the moving average). The more weeks we include in the window, the smoother the values will appear from week to week and the more short-term variation will be obscured. There is a balance to be struck between making longer-term trends clear and obscuring genuine short-term variation, so you should experiment with different window lengths to ensure you are not over-smoothing.\n\nWe can calculate moving averages in R with the `slide_dbl()` function from the [slider package](https://davisvaughan.github.io/slider/) (so called because its functions slide along a series of values). `slide_dbl()` can calculate several types of moving averages, so we specify that it should use the `mean()` function to calculate the average by specifying `.f = mean` (note the lack of parentheses after `mean`). We use the `.before` argument (note the `.`) to specify how many weeks *before the current week* to include in our moving average. So if we wanted to calculate a four-week moving average (i.e. the current week and the previous three weeks), we would specify `.before = 3`. \nWe also specify `.complete = TRUE` to stop `slide_dbl()` from trying to calculate averages for the first few weeks in our data, because we don't have the necessary data from previous weeks (i.e. before the start of our data) that we would need to make these averages accurate. `slide_dbl()` will use `NA` as the moving average value for those weeks, so we later need to specify `na.rm = TRUE` to tell `ggplot()` to ignore these when we plot the data.\n\nOnce we've calculated a moving average, we can show this using the line on our chart and show the individual weekly counts as small light-grey dots to show how much short-term variation there is in the data.\n\n\n\n\n\n::: {.cell filename='chapter16a.R'}\n\n```{.r .cell-code}\n# Create plot of weekly assault counts with moving average\nassault_weekly_counts |> \n  # Calculate moving average\n  mutate(moving_avg = slide_dbl(count, mean, .before = 3, .complete = TRUE)) |> \n  ggplot() +\n  # Specify which columns in the data will control which parts of the chart\n  aes(x = week_date) +\n  # Add points showing weekly counts of assaults\n  geom_point(aes(y = count), colour = \"grey75\", size = 0.75) +\n  # Add line showing moving average\n  geom_line(\n    aes(y = moving_avg, colour = \"black\"), \n    na.rm = TRUE, \n    key_glyph = \"timeseries\"\n  ) +\n  # Specify how dates should be shown on the x axis\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%b\\n%Y\") +\n  # Make sure y axis starts at zero\n  scale_y_continuous(limits = c(0, NA)) +\n  # Add legend to explain that the line shows a moving average\n  scale_colour_identity(\n    labels = c(\"black\" = \"four-week moving average\"),\n    guide = guide_legend()\n  ) +\n  # Add labels\n  labs(\n    x = NULL,\n    y = \"weekly count of aggravated assaults\",\n    colour = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    panel.grid.minor.x = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n\n\nYou can experiment with the effect of setting a longer or shorter window for the moving average by specifying larger or smaller values of the `.before` argument to `slide_dbl()`. For example, create an eight-week moving average by specifying\n`.before = 7`. What would happen to the apparent seasonal variation in the number of assaults (visible in the chart above) if you create an *annual moving average* by specifying `.before = 52`?\n\nYou may have noticed that in the code above we have also made some changes to the appearance of the plot to make it easier to read. Specifically, we have:\n\n  * Added a title for the *y* axis and removed the *x* axis and legend titles using the `labs()` function. This is because the axis labels (e.g. 'Jan 2010') make it clear what the _x_ axis shows.\n  * Changed the labels on the *x* axis using `scale_x_date()`. In this case, we have used the argument `date_breaks = \"1 year\"` to specify that we want a label at the start of each year and the argument `date_labels = \"%b\\n%Y\"` to specify that we want each label to consist of an abbreviated month name (using the code `%b`), a new line (the code `\\n` as in a previous chapter)  and a four-digit year (using the code `%Y`). You can find a full list of codes used that can be used to specify different parts of a date and time by typing `?strptime` in the R Console.\n  * Removed some of the vertical grid lines by setting the `panel.grid.minor.x` argument to `theme()` to equal `element_blank()`.\n  * Forced the *y* axis to begin at zero by specifying `limits = c(0, NA)`, remembering that `NA` in this context means to use the default value.\n  * Specified that we want the black line to be represented in the legend by a line that looks like a time series by specifying `key_glyph = \"timeseries\"`.\n    \nWe have also added a legend to explain what the black line shows. The code need to do this is slightly awkward, since `ggplot()` would not normally produce a legend for aesthetics (in this case, the colour of the line) that have only \none value. To force `ggplot()` to add a legend, we:\n\n  1. Specify the colour of the line (i.e. `colour = \"black\"`) not as an argument to the function `geom_line()` as we normally would but as one of the aesthetics specified using `aes()`. \n  2. Specify that `ggplot()` should treat the value `colour = \"black\"` as a literal colour name rather than as a reference to a column in the data (which is how the arguments to `aes()` are normally interpreted). To do this we add `scale_colour_identity()` to the `ggplot()` stack, because *identity* is the jargon used in R to say 'keep this value exactly as it is'. \n  3. Within `scale_colour_identity()`, specify a label to correspond to the black line by setting the `labels` argument. \n  4. Specify `guide = guide_legend()` to tell `ggplot()` to add a legend corresponding to the black line because aesthetics styled using functions in the `scale_*_identity()` family do not produce a legend entry by default.\n\nDoing all this is obviously tedious, but makes for a better chart.\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Why does this `ggplot()` stack have three calls to `aes()`?\n\nThe `aes()` function is used to specify which columns in the data will control which parts of the chart. We can use `aes()` in two ways. If we add `aes()` directly to the stack just after `ggplot()`, that will specify which columns in the data will control the appearance of _all_ the layers on the chart. Conversely, if we specify `aes()` inside one of the `geom_*()` family of functions, that will only affect the appearance of that specific layer.\n\nIn the code above, we use `aes()` first to specify that the horizontal position of data in _all_ the layers should be controlled by the `week_date` column in the data. We then use `aes()` inside both `geom_point()` and `geom_line()` to specify which (different) columns in the data should be used to control the vertical position of the points and lines.\n:::\n\n\n### Showing repeating patterns over time\n\nWe have already seen that there is seasonal variation in the number of aggravated assaults in Chicago. As is very common for assaults, there are more offences in the summer and fewer in the winter. We can see this in the time-series chart we have already produced, but it's hard to see the detail. For example, we might want to know how consistent this seasonal variation is across different years. Is it, for example, consistent enough that the local police might want to restrict the number of officers who can take holidays in certain weeks of the year to maximise the number of officers available when violent crime is likely to be highest?\n\nTo do this we can create a *seasonal chart*. This can be used to show any type of repeating variation, but is often used to show patterns across a year (hence the name). To create a seasonal plot we need to add a variable to our data specifying which year each weekly count belongs to, which we can do by using the `year()` function to extract the year from the offence dates. We can do this at the same time as we calculate the moving averages. Once we've done that, we can specify that we want our chart to have a separate line for each year by setting `group = year` inside the `aes()` function that controls how the data are shown on the chart, making each year a different colour using `colour = year`.\n\n\n\n\n\n::: {.cell filename='R Console'}\n\n```{.r .cell-code}\n# Create a seasonal plot of aggravated assaults\nassault_weekly_counts |> \n  mutate(\n    # Create a four-week moving average\n    moving_avg = slide_dbl(count, mean, .before = 3, .complete = TRUE),\n    # Create a new column showing just the year\n    year = year(week_date)\n  ) |>\n  ggplot() +\n  # Specify which columns in the data should control which parts of the chart\n  aes(x = week_date, y = moving_avg, colour = year, group = year) +\n  # Add lines\n  geom_line(na.rm = TRUE, key_glyph = \"timeseries\") +\n  # Specify how dates should be shown on the x axis\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%b\\n%Y\") +\n  # Make sure y axis starts at zero\n  scale_y_continuous(limits = c(0, NA)) +\n  # Specify that the legend should be labelled at the minimum and maximum values\n  scale_colour_continuous(breaks = c(2010, 2019)) +\n  # Add labels\n  labs(\n    x = NULL,\n    y = \"weekly count of aggravated assaults\",\n    colour = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor.x = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThis chart might not look like you expected it to. Although the grouping of the lines by year has worked (there is a break between the lines at the start of each year), it's no easier to compare the seasonal patterns across years. Comparing years would be much easier if we superimpose the weekly counts for each year on top of one another.\n\nTo do this, we need to trick `ggplot()` into plotting all the weekly counts as if they occurred in a single year, so the counts appear in the same locations on the horizontal axis of the chart, whichever year they occurred in. We can do this by creating a pseudo-date value for each weekly count which has the same month and day of the month as the original date, but a single year across all the rows in the data. We will create this pseudo date by extracting the month and day of the month using `month()` and `mday()`, then creating a new date with `make_date()`. We will also change the labels on the horizontal axis using the  date-formatting code `%e\\n%b` -- `%e` means the day of the month and `%b` means the abbreviated name of the month.\n\nAdd this code to the end of your R script file and run it.\n\n\n\n\n\n::: {.cell filename='chapter16a.R'}\n\n```{.r .cell-code}\n# Create a seasonal plot of aggravated assaults\nassault_weekly_counts |> \n  mutate(\n    # Create a four-week moving average\n    moving_avg = slide_dbl(count, mean, .before = 3, .complete = TRUE),\n    # Create a new column showing just the year\n    year = year(week_date),\n    # By only specifying the `month` and `day` arguments to `make_date()` we\n    # will create a date in 1970 (the year that R uses by default), but that \n    # doesn't matter because we are not going to show the year on the chart\n    pseudo_date = make_date(month = month(week_date), day = mday(week_date))\n  ) |> \n  ggplot() +\n  # Specify which columns in the data should control which parts of the chart\n  aes(x = pseudo_date, y = moving_avg, colour = year, group = year) +\n  # Add lines\n  geom_line(na.rm = TRUE, key_glyph = \"timeseries\") +\n  # Specify how dates should be shown on the x axis\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%e\\n%b\") +\n  # Make sure y axis starts at zero\n  scale_y_continuous(limits = c(0, NA)) +\n  # Specify that the legend should be labelled at the minimum and maximum values\n  scale_colour_continuous(breaks = c(2010, 2019)) +\n  # Add labels\n  labs(\n    x = NULL,\n    y = \"weekly count of aggravated assaults\",\n    colour = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor.x = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n\n\nFrom this chart we can see that assaults consistently peak in July, although in one year they peaked slightly earlier in late June and in one year slightly later in August. At the other end of the year, weekly counts of assaults are almost always least frequent in late January and throughout February before starting to increase quite rapidly in March.\n\nAs well as showing seasonal variation, we can use the same technique to understand variation over other periods of time. For example, since we know a lot of human activities follow weekly patterns, we might want to produce a chart showing the number of crimes in each hour on each day of the week.\n\nTo do this, we:\n\n  1. Extract the weekday and hour components of each date using `wday()` and `hour()`.\n  2. Count the total number of crimes occurring in each hour of each day *across all ten years of the data* using `count()`.\n  3. Create a pseudo-date-time using `make_datetime()`.\n\nWe can do this in a single piece of code. Add this R code to the R script file just after the code that creates the `assault_weekly_counts` object. Remember to run this chunk of code.\n\n\n\n\n\n::: {.cell filename='chapter16a.R'}\n\n```{.r .cell-code}\n# Create counts of assaults by hours of the day and week\nassault_hourly_counts <- assaults |> \n  # Extract day of the week and hour of the day from the date column\n  mutate(wday = wday(date, label = TRUE), hour = hour(date)) |> \n  # Count crimes for each hour of each day of the week\n  count(wday, hour, name = \"count\") |> \n  # By only setting the `hour` argument to `make_datetime()` we will create a\n  # date-time on 1 January 1970, but that doesn't matter because we will not \n  # show the date on the chart\n  mutate(pseudo_date = make_datetime(hour = hour))\n```\n:::\n\n\n\n\n\nWe can now create a chart with appropriate labels on the horizontal axis and a suitable qualitative colour scheme to show the days of the week using `scale_colour_brewer()`.\n\n\n\n\n\n::: {.cell filename='R Console'}\n\n```{.r .cell-code}\n# Create chart of assaults by hour of the day for each day of the week\nggplot(assault_hourly_counts) +\n  # Specify which columns in the data should control each part of the chart\n  aes(x = pseudo_date, y = count, colour = wday, group = wday) +\n  # Add lines\n  geom_line(key_glyph = \"timeseries\") +\n  # Specify how dates should be shown on the x axis\n  scale_x_datetime(date_breaks = \"2 hours\", date_labels = \"%H:%M\") +\n  # Make sure y axis starts at zero and labels have thousands separators\n  scale_y_continuous(limits = c(0, NA), labels = scales::comma_format()) +\n  # Specify a qualitative colour scheme should be used\n  scale_colour_brewer(type = \"qual\") +\n  # Add labels\n  labs(\n    x = NULL,\n    y = \"hourly total of aggravated assaults, 2010-2019\",\n    colour = NULL\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n\n\nOn this chart you can see that there are two distinct temporal patterns of assaults on different days of the week. Between Mondays and Thursdays, assaults peak between about 14:00 and 21:00 before reducing to a very-low level at about 05:00. At the weekend, the picture is different: assaults peak between midnight and 02:00 on both Saturdays and Sundays (i.e. very late on Friday and Saturday evenings). In fact, there are more aggravated assaults between midnight and 3am on Saturdays and Sundays than at any other time of the week.\n\nThis chart probably uses the maximum number of different colours for days of the week that we could use before some of the colours became too similar to one another to be distinguishable. But even with this many colours, it might not be easy for a colour-blind person to translate between the colours of the lines and the colours in the legend. When you find that there are too many colours on a chart, this is a good sign that you should consider using small-multiple charts instead. Fortunately, we can do this by adding a column to the data specifying whether each day is a weekday or on a weekend, then adding `facet_grid()` to our `ggplot()` stack. \n\nAdd this code to the end of your R script file and run it.\n\n\n\n\n\n::: {.cell filename='chapter16a.R'}\n\n```{.r .cell-code}\n# Create chart of assaults by hour of the day for each day of the week\nassault_hourly_counts |> \n  # Create a new column specifying if each day if a weekday or weekend\n  mutate(weekend = if_else(wday %in% c(\"Sat\", \"Sun\"), \"Sat–Sun\", \"Mon–Fri\")) |> \n  ggplot() +\n  # Specify which columns in the data should control each part of the chart\n  aes(x = pseudo_date, y = count, colour = wday) +\n  # Add lines\n  geom_line(linewidth = 1) +\n  # Assign the facets to rows so that we can compare the same time on different\n  # days more easily (change `rows` to `cols` to see the alternative)\n  facet_grid(rows = vars(weekend)) +\n  # Specify how dates should be shown on the x axis\n  scale_x_datetime(date_breaks = \"2 hours\", date_labels = \"%H:%M\") +\n  # Make sure y axis starts at zero and labels have thousands separators\n  scale_y_continuous(limits = c(0, NA), labels = scales::comma_format()) +\n  # Specify a qualitative colour scheme should be used\n  scale_colour_brewer(type = \"qual\") +\n  # Add labels\n  labs(\n    x = NULL,\n    y = \"hourly total of aggravated assaults, 2010-2019\",\n    fill = NULL\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThis shows the two distinct patterns (weekdays and weekends) more clearly, while also letting us see that Friday is not like other weekdays since the peak in assaults continues later in the evening. Now that we've created this chart using `facet_grid()`, we could also add columns to show the same patterns in different areas, such as police districts or local neighbourhoods, or during different seasons.\n\n\n::: {.callout-quiz .callout}\n#### Showing change over time\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n**Which of the following is an example of a repeating pattern in crime data?**\n\n<div class='webex-radiogroup' id='radio_LLIFWRIJUA'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LLIFWRIJUA\" value=\"\"></input> <span>A one-time spike in burglary due to a major event</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LLIFWRIJUA\" value=\"\"></input> <span>A steady decline in homicide rates over 10 years</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LLIFWRIJUA\" value=\"answer\"></input> <span>An increase in shoplifting before major holidays each year</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LLIFWRIJUA\" value=\"\"></input> <span>A sudden crime wave in an area with no prior incidents</span></label></div>\n\n\n\n**How can temporal analysis of crime deal with the multiple ways in which crime varies over time?**\n\n<div class='webex-radiogroup' id='radio_GDXZXUGRYN'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_GDXZXUGRYN\" value=\"\"></input> <span>By examining a single week&apos;s worth of data</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_GDXZXUGRYN\" value=\"\"></input> <span>By only focusing on yearly statistics</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_GDXZXUGRYN\" value=\"\"></input> <span>By assuming all crime trends follow a predictable cycle</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_GDXZXUGRYN\" value=\"answer\"></input> <span>By analyzing each type of temporal variation (e.g. seasonal, weekly) separately</span></label></div>\n\n\n\n**What does a moving average help with when analysing crime trends?**\n\n<div class='webex-radiogroup' id='radio_FKBKYSNYIV'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FKBKYSNYIV\" value=\"answer\"></input> <span>It smooths out short-term fluctuations to highlight longer-term trends</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FKBKYSNYIV\" value=\"\"></input> <span>It removes all variations in crime data</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FKBKYSNYIV\" value=\"\"></input> <span>It replaces the need for crime maps</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FKBKYSNYIV\" value=\"\"></input> <span>It predicts the exact time and location of future crimes</span></label></div>\n\n\n\n:::\n\n\n\n## How to map change over time\n\nTime-series or seasonal charts are often the best way to show change in the frequency of crime over time. But it can also be useful to show maps of the patterns of crimes at different points in time. We might, for example, want to show the density of crime in an area for different periods in time.\n\nChoosing how to divide up time into periods is an important step in this process, because in doing so we are converting a continuous variable (time) into a number of categories (periods of time). Whenever we convert an continuous variable to a categorical one we inevitably lose information. For example, if we decided to categorise the maximum temperature every day as being either 'hot' or 'cold', we would lose a lot of information about whether a particular day was moderately hot, very hot, etc. The same is true of time, since by splitting time into periods (hours, days, weeks, etc.) we lose information about variations within each period. This is inevitable, since we can't produce infinite maps showing all the infinite moments in time, but it is the reason why choosing periods carefully is important.\n\nWhen choosing a period over which to count crime, it is important not to just use default periods like the day from 00:00 to 23:59 just because that is the standard definition of a day. As we saw in the previous section, the peaks of many types of crime like assaults cross over the boundaries between days because the peak frequency is late in the evening. For this reason it may be better to, for example, define a day as a period from 05:00 to 04:59 and count the number of crimes within each day according to that definition. This takes advantage of the fact that very few crimes concentrate in the early hours of the morning.\n\nSometimes, it will be easy to choose periods because they will be dictated by the purpose for which you're creating the map. In this section we will create separate maps showing the density of aggravated assaults in a part of Chicago for each of the standard Chicago Police shifts of 06:00 to 13:59, 14:00 to 21:59 and 22:00 to 05:59 (bearing in mind that the actual hours some officers work may differ slightly).\n\nTo do this, we will estimate the density of assaults separately for each shift period, the combine the three density layers and plot them on small-multiple maps. First, we create a new object containing data for the Chicago Police districts we are interested in with a column showing which police shift each assault occurred in. \n\nWe can construct this column using the `case_when()` function from dplyr. `case_when()` allows us to specify any number of tests that we can apply to our data -- when a test is passed the function assigns the corresponding label to that row (the label is separated from the test by a tilde character `~`). `case_when()` is like `case_match()`, but for when we need to test for more-complicated things than just whether a variable has a particular value. \n\nAdd this code to your R script file just after the code that creates the `assault_hourly_counts` object. Remember to run the code.\n\n\n\n\n\n::: {.cell filename='chapter16a.R'}\n\n```{.r .cell-code}\n# Calculate number of assaults by shift\nassaults_by_shift <- assaults |> \n  # Restrict counts to just the central area of Chicago\n  filter(district %in% c(1, 12, 18)) |> \n  mutate(\n    shift = case_when(\n      between(hour(date), 6, 13) ~ \"06:00 to 13:59\",\n      between(hour(date), 14, 21) ~ \"14:00 to 21:59\",\n      hour(date) >= 22 | hour(date) < 6 ~ \"22:00 to 05:59\",\n      TRUE ~ NA\n    )\n  )|> \n  # Convert the data to an SF object\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = \"EPSG:4326\") |> \n  # Transform it to a co-ordinate reference system based on metres\n  st_transform(\"EPSG:26916\")\n```\n:::\n\n\n\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Why did we include `TRUE ~ NA_character_` in `case_when()`?\n\n`case_when()` uses a series of true/false tests to create a variable, usually based on the values of other columns in the data. To make sure that every row in the dataset is matched by at least one of the tests, it is common practice to include a final test that is always true. The easiest way to do this is to simply create a test with the fixed value `TRUE`, since `TRUE` is always true!\n\nThis catch-all test must be the last test within the `case_when()` function, because `case_when()` runs the tests in the order in which they are given and stops testing a given row in the data as soon as a test produces a true value.\n\nIn this case, we will set the label for this last test to be `NA` to catch any rows that have missing values of `date` or aren't matched by any of our tests. Since our tests between them cover all the hours of the day, there shouldn't be any rows that are not matched by at-least one test, but including a catch-all test makes it easier to catch any problems with our code.\n\nThere's lot's more to learn about the `case_when()` function: you can find out more by looking at the [`case_when()` page on the dplyr package website](https://dplyr.tidyverse.org/reference/case_when.html).\n\n:::\n\n\n\n\n\n::: {.cell filename='R Console'}\n\n```{.r .cell-code}\nhead(assaults_by_shift)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 444951.9 ymin: 4635831 xmax: 449271.4 ymax: 4641406\nProjected CRS: NAD83 / UTM zone 16N\n# A tibble: 6 × 5\n  date                loc_cat    district shift                  geometry\n  <dttm>              <chr>         <dbl> <chr>               <POINT [m]>\n1 2010-01-01 00:30:00 hotel             1 22:00 to 05… (448202.2 4635831)\n2 2010-01-01 01:45:00 street           18 22:00 to 05…   (446518 4641406)\n3 2010-01-01 01:48:00 hotel             1 22:00 to 05… (448202.2 4635831)\n4 2010-01-01 02:00:00 government       18 22:00 to 05… (449271.4 4637966)\n5 2010-01-01 02:59:00 leisure          12 22:00 to 05… (444951.9 4637265)\n6 2010-01-01 05:00:00 residence        18 22:00 to 05… (447278.5 4639968)\n```\n\n\n:::\n:::\n\n\n\n\n\nThe next step is to produce a kernel density (KDE) layer for assaults occurring in each shift. In a previous chapter we learned how to do this using the sfhotspot package. We could run the `hotspot_kde()` function from that package three times to create the KDE layers for each shift, but there is a simpler way to apply the same function to different parts of a dataset using the `group_modify()` function from `dplyr`.\n\nNormally, when we use a function to modify a dataset, that function is applied to the dataset as a whole. With `group_modify()`, we can apply a function to different parts of a dataset separately but still get the result as a single tibble with a column showing which group each row relates to (which is what we need to produce a map).\n\n`group_modify()` needs two inputs. The first is a _grouped_ dataset. We already know how to specify which column in a dataset represents which group each row is in using the `group_by()` function. The second input to `group_modify()` is the\nname of the function we want to use to modify each group in the data. The only complication is that we have to provide the details of the function that `group_modify()` should use in a slightly unusual format called an _anonymous function_. You can see this in the block of code below. You do not need to understand the details of how an anonymous function works, but you should note two things:\n\n  1. Anonymous functions start with the `~` character.\n  2. In an anonymous function used within `group_modify()`, you can use the special place-holder value `.x` (note the dot) to represent the data in each group.\n     \nSo this code:\n\n\n\n\n::: {.cell filename='Hypothetical code'}\n\n```{.r .cell-code}\nsome_data |> \n  group_by(some_variable) |> \n  group_modify(~ hotspot_kde(.x))\n```\n:::\n\n\n\n\nThis code means 'take the dataset `some_data`, group it according to the values in the `some_variable` column and apply the `hotspot_kde()` function separately to each group'. The only thing left for us to do then is to use `ungroup()` to remove \nthe grouping from the result produced by `group_modify()` and convert that result back to an SF object using `st_as_sf()`. Don't worry about specifying any arguments to `st_as_sf()` – R will extract information such as the co-ordinate reference system from the `geometry` column of the data automatically.\n\nAdd this code to the `chapter16a.R` code file just after the code that creates the `assaults_by_shift` object. Remember to run the code.\n\n\n\n\n\n::: {.cell filename='chapter16a.R'}\n\n```{.r .cell-code}\n# Estimate density of assaults for each CPD shift\nkde_by_shift <- assaults_by_shift |> \n  # Group dataset by which shift the occurred in\n  group_by(shift) |> \n  # Separately estimate density of assaults for each shift\n  group_modify(\n    ~ hotspot_kde(.x, cell_size = 200, bandwidth_adjust = 0.5, quiet = TRUE)\n  ) |> \n  # Ungroup the dataset\n  ungroup() |> \n  # Convert the result to an SF object (because although `hotspot_kde()` returns\n  # an SF object, `group_modify()` silently converts it to a tibble)\n  st_as_sf() |> \n  # Clip the result to the boundary of the three central police districts\n  st_intersection(cpd_central)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n```\n\n\n:::\n:::\n\n\n\n\n\n:::  {.callout-tip collapse=\"true\"}\n#### How do anonymous functions work?\n\nAnonymous functions in R (and in many other programming languages) are a compact way of creating a new function that we can then immediately use to modify a dataset.\n\nWe can create our own functions in R by using the `function()` function. For example, if we wanted to create our own version of the `head()` function that printed the first 10 rows of a dataset – rather than the default six rows printed by `head()` – we could create a function called `head10()`:\n\n\n\n\n::: {.cell filename='Hypothetical code'}\n\n```{.r .cell-code}\nhead10 <- function(x) {\n  head(x, n = 10)\n}\n```\n:::\n\n\n\n\nWhen we call the new `head10()` function on a dataset, R will take whatever data we provide to that function and run all the code inside the braces `{}` above using that data. We can use this new function anywhere in our code _after_ we've created it. For example, if we had a dataset called `some_data` we could view the first 10 rows of it by creating an then using our new function:\n\n\n\n\n::: {.cell filename='Hypothetical code'}\n\n```{.r .cell-code}\nhead10 <- function(x) {\n  head(x, n = 10)\n}\n\nhead10(some_data)\n```\n:::\n\n\n\n\nNote that _inside_ our new function, the dataset is referred to by the name that we gave it in the parentheses `()` after the word `function`, _not_ by the name of the dataset itself. This is important because it means our custom function will work regardless of what a particular dataset is called.\n\nWe could include lots of lines of code inside our new function, but in this case there is just one – `head(x, n = 10)`. When we want to create a function that consists of a single line of code, we can dispense with the braces and put the whole function on one line:\n\n\n\n\n::: {.cell filename='Hypothetical code'}\n\n```{.r .cell-code}\nhead10 <- function(x) head(x, n = 10)\n\nhead10(some_data)\n```\n:::\n\n\n\n\nCreating a new function and giving it a name is useful if we want to use the function several times in our code. But in the case of the function we need to provide to `group_modify()` in our code, we only need to use the new function once. In this case, we can dispense with the need to give our new function a name, and instead create an anonymous function. To do this, we replace `function(x)` with the `~` character.\n\nThis makes the definition of our custom function even faster, but means we can only use it inside a function such as `group_modify()` or `map()` that needs a function definition to work. Using an anonymous function also means we need some way of referring to our dataset inside the new function, since we don't have the opportunity to define it inside parentheses after the word `function`. Fortunately, `group_modify()` understands that if we refer to `.x` (note the dot) inside our anonymous function, that should be interpreted as referring to our dataset.\n\nThere is a lot more you could learn about creating your own functions in R. If you are interested, you might want to [work through this lesson on Creating Functions](https://swcarpentry.github.io/r-novice-inflammation/02-func-R/).\n\n:::\n\n\nIf we look at the result produced by this code, we can see that it looks like the output produced by `hotspot_kde()` except there is an extra column that we can use to distinguish the KDE value for each cell for each of the three shifts. We can use this column together with `facet_wrap()` to create a separate map for each shift.\n\n\n\n\n\n::: {.cell filename='R Console'}\n\n```{.r .cell-code}\nhead(kde_by_shift)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 5 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 446980 ymin: 4637342 xmax: 447685.6 ymax: 4637558\nProjected CRS: NAD83 / UTM zone 16N\n# A tibble: 6 × 6\n  shift              n   kde name  description                          geometry\n  <chr>          <dbl> <dbl> <chr> <chr>                           <POLYGON [m]>\n1 06:00 to 13:59     0  56.7 18    District 18 ((447085.6 4637358, 447085.6 463…\n2 06:00 to 13:59     4  77.1 18    District 18 ((447085.6 4637358, 447112.6 463…\n3 06:00 to 13:59     0  47.1 18    District 18 ((447085.6 4637558, 447085.6 463…\n4 06:00 to 13:59     0  63.9 18    District 18 ((447085.6 4637558, 447285.6 463…\n5 06:00 to 13:59     2  91.7 18    District 18 ((447285.6 4637558, 447485.6 463…\n6 06:00 to 13:59     4 122.  18    District 18 ((447485.6 4637558, 447685.6 463…\n```\n\n\n:::\n:::\n\n\n\n\n\nNow we have a KDE layer for each shift, we can create three maps for the three shifts by adding `facet_wrap()` to a `ggplot()` stack.\n\n\n\n\n\n::: {.cell filename='R Console'}\n\n```{.r .cell-code}\n# Add density map of assaults by shift\nggplot() +\n  # Add base map\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  # Add density layer\n  geom_sf(aes(fill = kde), data = kde_by_shift, alpha = 0.75, colour = NA) +\n  # Add district boundaries\n  geom_sf(data = cpd_central, colour = \"grey33\", fill = NA) +\n  # Specify a separate map for each shift\n  facet_wrap(vars(shift)) +\n  # Specify details of legend\n  scale_fill_distiller(\n    breaks = range(pull(kde_by_shift, kde)),\n    labels = c(\"lower\", \"higher\"),\n    direction = 1\n  ) +\n  # Add labels\n  labs(fill = \"density of aggravated assaults\") +\n  theme_void() +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(hjust = 1)\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n\n\n\nOn this map we can see that some places have a relatively high density of assaults throughout all three shifts, but others only have a high density at certain times. We can perhaps make this clearer by highlighting the grid cells with the highest estimated density of assaults during each shift. We can do this using the `slice_max()` function from dplyr, which allows us to extract the rows in a dataset with the highest values of a particular variable. In this case we will use `slice_max()` together with `group_by()` to get the rows with the highest values _separately for each shift_ rather than those with the highest values across all three shifts combined.\n\n\n\n\n\n::: {.cell filename='chapter16a.R'}\n\n```{.r .cell-code}\n# Create new dataset containing just the cells in each shift with the highest\n# KDE values\nkde_shift_highest <- kde_by_shift |> \n  group_by(shift) |> \n  slice_max(order_by = kde, n = 10)\n\n# Add density map of assaults by shift\nggplot() +\n  # Add base map\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  # Add density layer\n  geom_sf(aes(fill = kde), data = kde_by_shift, alpha = 0.75, colour = NA) +\n  # Add layer highlighting cells with highest density on each shift\n  geom_sf(\n    aes(fill = kde), \n    data = kde_shift_highest, \n    alpha = 0.75, \n    colour = \"red2\",\n    fill = NA\n  ) +\n  # Add district boundaries\n  geom_sf(data = cpd_central, colour = \"grey33\", fill = NA) +\n  # Specify a separate map for each shift\n  facet_wrap(vars(shift)) +\n  # Specify details of legend\n  scale_fill_distiller(\n    breaks = range(pull(kde_by_shift, kde)),\n    labels = c(\"lower\", \"higher\"),\n    direction = 1\n  ) +\n  # Add labels\n  labs(fill = \"density of aggravated assaults\") +\n  theme_void() +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(hjust = 1)\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n\n\nThis map makes it very clear that the grid cells with the highest densities of aggravated assaults are very similar in the daytime and evening shifts, in both places being concentrated in the downtown area known as The Loop. For the overnight shift, however, the cells with the highest densities are on the other side of the Chicago River in the River North neighbourhood. A map like this might be particularly useful if the resources available to respond to a crime problem were very limited and so could only be deployed in the places where the problem was worst -- this is often the case because crime-prevention resources *are* often very limited.\n\n\n::: {.callout-quiz .callout}\n#### Mapping temporal change\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n**What is one way to effectively compare crime patterns over different time periods on a map?**\n\n<div class='webex-radiogroup' id='radio_UOWBUGBVBQ'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UOWBUGBVBQ\" value=\"answer\"></input> <span>Using a series of small-multiple maps, each representing a different time period</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UOWBUGBVBQ\" value=\"\"></input> <span>Using a single map with all time periods combined into one dataset</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UOWBUGBVBQ\" value=\"\"></input> <span>Ignoring temporal differences and only focusing on spatial patterns</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UOWBUGBVBQ\" value=\"\"></input> <span>Only mapping crime data from the most recent year</span></label></div>\n\n\n\n**What is the primary purpose of the `group_modify()` function in R?**\n\n<div class='webex-radiogroup' id='radio_OLVBZYKPEZ'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_OLVBZYKPEZ\" value=\"\"></input> <span>To filter out specific groups in a grouped data frame</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_OLVBZYKPEZ\" value=\"\"></input> <span>To summarize grouped data into a single-row output per group</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_OLVBZYKPEZ\" value=\"answer\"></input> <span>To apply the same function to each group in a grouped data frame and return a modified data frame</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_OLVBZYKPEZ\" value=\"\"></input> <span>To convert a grouped data frame into a list</span></label></div>\n\n\n\n**What is the `facet_wrap()` function from the ggplot2 package used for?**\n\n<div class='webex-radiogroup' id='radio_MHGNQMGELD'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_MHGNQMGELD\" value=\"\"></input> <span>To change the color scheme of a ggplot visualization</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_MHGNQMGELD\" value=\"answer\"></input> <span>To split a single plot into multiple panels based on a categorical variable</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_MHGNQMGELD\" value=\"\"></input> <span>To overlay multiple datasets on a single plot</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_MHGNQMGELD\" value=\"\"></input> <span>To adjust the width and height of a single plot</span></label></div>\n\n\n\n:::\n\n\n\n## Making animated maps\n\nThe small-multiple map we have produced of aggravated-assault hotspots in Chicago is useful, especially for policing because it uses periods based on police shifts. But aggregating crimes into only three temporal periods inevitably throws away a lot of information about when crime happens. For example, at what time of night does the area of highest assault density move across the river from The Loop to River North?\n\nWe could produce a series of small-multiple maps showing shorter periods (meaning more small multiples). For example, we could show one small-multiple map for each hour of the day. However, this would make each map very small and it would be hard to see the details of locations on each map.\n\nOne alternative is to produce an animated map with each frame in the animation representing the map for each hour. We can do this using the [gganimate package](https://gganimate.com/).\n\nThe first step in producing an animated map is to create a KDE layer for each hour of the day. The code for this is the same as for the code we have already used to produce the KDE layers for each shift, except that we create a variable for hour of the day rather than police shift. Because an animated map of hours of the day needs 24 KDE layers, in this case it is particularly useful to use `group_modify()` to avoid having to create 24 different objects and then binding them together.\n\nSince the code to make animated maps is quite long, and our script file is fairly long already, let's start a new script file to store the code needed to make an animated map. Restart R (`Session > Restart R`), open a new script file and save it as `chapter16b.R`. \n\nCopy this code into that file and run the code. There is quite a lot of code here, but all of it is code we have seen earlier in this chapter.\n\n\n::: {.callout-important}\n#### This code will take a while to run\n\nThis code estimates the density of crime in each grid cell 24 times (once for each hour of the day) so it is likely the code will take a few minutes to run. How long it takes to run will depend on the speed of your computer.\n:::\n\n\n\n\n\n::: {.cell filename='chapter16b.R'}\n\n```{.r .cell-code}\n# PREPARE ----------------------------------------------------------------------\n\n# Load packages\npacman::p_load(gganimate, ggspatial, sf, sfhotspot, tidyverse)\n\n# Load Chicago aggravated assault data\nassaults <- read_csv(\"https://mpjashby.github.io/crimemappingdata/chicago_aggravated_assaults.csv.gz\")\n\n# Load dataset of Chicago Police Department (CPD) district boundaries\ncpd_districts <- read_sf(\"https://mpjashby.github.io/crimemappingdata/chicago_police_districts.kml\") |> \n  janitor::clean_names() |> \n  # Transform this object to use a suitable local co-ordinate reference system\n  st_transform(\"EPSG:26916\")\n\n# Create a separate dataset holding just the boundaries of the three CPD \n# districts covering the downtown area\ncpd_central <- filter(cpd_districts, name %in% c(\"1\", \"12\", \"18\"))\n\n\n# WRANGLE ----------------------------------------------------------------------\n\n# Create a version of the dataset with a column showing which hour the assault\n# occurred in\nassaults_by_hour <- assaults |> \n  # Keep only the CPD districts in downtown Chicago we are interested in\n  filter(district %in% c(1, 12, 18)) |> \n  # Create nicely formatted labels to represent each hour\n  mutate(\n    hour_name = str_pad(hour(date), width = 2, pad = \"0\"),\n    hour_name = str_glue(\"{hour_name}:00 to {hour_name}:59\")\n  ) |> \n  # Convert the data to an SF object\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = \"EPSG:4326\") |> \n  # Convert the data to a suitable co-ordinate system for Chicago\n  st_transform(\"EPSG:26916\")\n\n# Create a grid to be used by all the KDE layers, otherwise `hotspot_kde()` will\n# generate each grid based on the convex hull of the assaults occurring in each\n# hour and each grid will be slightly different (which would make the animation\n# flicker)\ncentral_grid <- hotspot_grid(cpd_central, cell_size = 200)\n\n# Calculate KDE layer for each hour of the day\nhour_layers <- assaults_by_hour |> \n  group_by(hour_name) |> \n  group_modify(\n    ~ hotspot_kde(.x, grid = central_grid, bandwidth_adjust = 0.5, quiet = TRUE)\n  ) |> \n  ungroup() |> \n  st_as_sf() |> \n  st_intersection(cpd_central)\n\n# Extract only the 10 cells with the highest density in each hour\nhour_highest <- hour_layers |> \n  group_by(hour_name) |> \n  slice_max(order_by = kde, n = 10)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 148636 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): loc_cat\ndbl  (3): longitude, latitude, district\ndttm (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n```\n\n\n:::\n:::\n\n\n\n\n\nTo create an animated map using the `hour_layers` and `hour_highest` objects, we use the `transition_states()` function from the gganimate package. `transition_states()` works in a similar way to `facet_wrap()`, in that when added to a `ggplot()` stack it splits the chart or map up into a separate map for each value of one of the variables in the data (in this case, the hour of the day). The only difference is that while `facet_wrap()` arranges those separate maps next to one another, `transition_states()` arranges them into an animation.\n\nAdd this code to your script file and run it.\n\n\n\n\n\n::: {.cell filename='chapter16b.R'}\n\n```{.r .cell-code}\n# VISUALISE --------------------------------------------------------------------\n\nchicago_downtown_kde_map <- ggplot() +\n  # Add base map\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  # Add density of assaults\n  geom_sf(aes(fill = kde), data = hour_layers, alpha = 0.75, colour = NA) +\n  # Add layer showing cells with highest density of assaults\n  geom_sf(data = hour_highest, alpha = 0.75, colour = \"red2\", fill = NA) +\n  # Add CPD district boundaries\n  geom_sf(data = cpd_central, colour = \"grey33\", fill = NA) +\n  # Specify that each hour should be a separate frame in an animation\n  transition_states(states = hour_name) +\n  # Specify details of legend\n  scale_fill_distiller(\n    breaks = range(pull(hour_layers, kde)),\n    labels = c(\"lower\", \"higher\"),\n    direction = 1\n  ) +\n  # Add labels\n  labs(\n    title = \"Aggravated assaults in downtown Chicago, 2010-2019\",\n    subtitle = \"Areas with most aggravated assaults:\\n{closest_state}\",\n    caption = \"Data from Chicago Police\",\n    fill = \"density of\\naggravated\\nassaults\"\n  ) +\n  theme_void()\n```\n:::\n\n\n\n\n\nThere is one other feature of gganimate we have used in the code used to make this map. You might have noticed that in the map `subtitle` is the code `{closest_state}`. This is a special code that gganimate will replace with the current value of the variable in the data that is used to control which facet appears in each frame of the animation. So for this map, `{closest_state}` will be replaced in the animation with the value of the `hour_name` variable in the data for each frame in the animation.\n\nOne difference between animated maps and other maps we have created in previous chapters is that most of the controls that influence how a map is animated are not contained in a function we add to the `ggplot()` stack, but are instead included in the separate `animate()` function. `animate()` takes a `ggplot()` stack that includes the `transition_states()` function and converts it into the final animation. Among other things, `animate()` controls the type of file the animation will be saved in (by default, an animated GIF), the height and width of the plot and so on.\n\nOne important element that is controlled by `animate()` is the speed of the animation. Controlling the length of the animation is important because if the animation is too quick, it will be hard for readers to see where the hotspots in each hour are. The `fps` (_frames per second_) argument can be used to control how quickly the animation moves between each state (in this case, each hour). The higher the value of `fps`, the longer the animation will take. So if we wanted the animation to last twice as long as the default value, we could use `fps = 2`. \n\nWe can save an animated map to a file by using `animate()` together with the `anim_save()` functions. `anim_save()` saves the animation created by `animate()` in a file. For example, if we stored the map created above in an object called `chicago_downtown_kde_map`, we could save it to an animated GIF file.\n\n\n\n\n\n::: {.cell filename='chapter16b.R'}\n\n```{.r .cell-code}\nanim_save(\n  filename = \"chicago_downtown_agg_assaults.gif\", \n  animation = animate(\n    plot = chicago_downtown_kde_map,\n    fps = 2,\n    height = 800, \n    width = 800, \n    units = \"px\"\n  )\n)\n```\n:::\n\n\n\n\n\n::: {.callout-quiz .callout}\n#### Animated maps\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n**What kind of crime data benefits most from being shown on an animated map?**\n\n<div class='webex-radiogroup' id='radio_NRBPJACLZE'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NRBPJACLZE\" value=\"\"></input> <span>Crimes that do not have clear temporal patterns</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NRBPJACLZE\" value=\"answer\"></input> <span>Crimes with clear time-based patterns</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NRBPJACLZE\" value=\"\"></input> <span>Crimes that only occur indoors</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NRBPJACLZE\" value=\"\"></input> <span>Crimes that have no spatial component</span></label></div>\n\n\n\n**Which of these considerations is particularly important then making animated maps?**\n\n<div class='webex-radiogroup' id='radio_EXJVSRCSRK'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EXJVSRCSRK\" value=\"answer\"></input> <span>The speed of the animation</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EXJVSRCSRK\" value=\"\"></input> <span>The number of colors used in the background</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EXJVSRCSRK\" value=\"\"></input> <span>The exact GPS coordinates of each crime</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EXJVSRCSRK\" value=\"\"></input> <span>The type of crime, but not when it happened</span></label></div>\n\n\n\n**What is an alternative to using an animated map for temporal crime analysis?**\n\n<div class='webex-radiogroup' id='radio_FQRPSWBDKO'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FQRPSWBDKO\" value=\"\"></input> <span>A single static crime map</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FQRPSWBDKO\" value=\"\"></input> <span>Ignoring time in crime analysis</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FQRPSWBDKO\" value=\"answer\"></input> <span>A series of maps showing different time periods</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FQRPSWBDKO\" value=\"\"></input> <span>Using a bar chart instead</span></label></div>\n\n\n\n:::\n\n\n\n## In summary\n\nIn this chapter we have learned how to incorporate change over time into our analysis of where crime happens. This is important because the distribution of crime across different places often varies at different times. Being aware of the importance of time when we make maps means we can do things like create small-multiple or animated maps for different time periods, which we could use to make sure that scarce crime-prevention resources are used at the right time as well as in the right place.\n\n\n::: {.box .reading}\nYou can learn more about:\n\n  * using the different functions in the lubridate package to [Do more with dates and times in R](https://lubridate.tidyverse.org/articles/lubridate.html) and\n  * animating different types of map and chart in different ways in [Getting Started with gganimate](https://gganimate.com/articles/gganimate.html).\n:::\n\n\n::: {.callout-quiz .callout}\n#### Check your knowledge: Revision questions\n\nAnswer these questions to check you have understood the main points covered in this chapter. Write between 50 and 100 words to answer each question.\n\n1. Why is it difficult for computers to deal with dates, and how does R solve this problem?\n2. How can we (a) extract and (b) manipulate date and time components in R?\n3. What are some challenges in visualizing crime trends over time, and how can they be addressed?\n4. How can seasonal variations in crime be identified and visualized?\n5. Why is it important to consider both spatial and temporal dimensions when analysing crime?\n:::\n\n\n::: {.credits}\n[Artwork by @allison_horst](https://twitter.com/allison_horst)\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}