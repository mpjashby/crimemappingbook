{
  "hash": "7505616fda833e9d0f3cb8b17321c996",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexecute:\n  freeze: auto\n---\n\n\n\n\n\n# Mapping crime over time {#sec-mapping-time}\n\n**Learn to show change over time on crime maps and charts**\n\n::: {.callout-important}\nThis chapter has not yet been updated for 2025, so some material is out of date. Check back for an update in mid-February 2025.\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Introduction\n\nUnderstanding how crime varies over time is just as important as understanding \nhow it varies between places. Very few places are hotspots of crime all the time \n– business districts might be hotspots of pickpocketing in the daytime but \ndeserted at night, while a nearby entertainment district may be quiet in the \ndaytime but a violence hotspot at night.\n\nCrime varies over time in lots of ways. For example, there was a long-term drop\nin many types of crime in many countries starting in the mid 1990s, e.g.\n[residential burglary in England and Wales dropped by 67% between 1993 and 2008](https://crimesciencejournal.biomedcentral.com/articles/10.1186/s40163-016-0051-z)\nwhile the number of \n[homicides in New York City dropped almost 90% from 2,245 in 1990 to 289 in 2018](https://www.brennancenter.org/our-work/analysis-opinion/takeaways-2019-crime-data-major-american-cities).\n\nThere are also short-term variations in crime. Many types of crime are more\ncommon at some types of year than others (known as *seasonal variation*). In\nChicago, for example, assaults, residential burglaries and personal robberies \nall vary throughout the year, with assaults in particular being consistently \nhigher in summer than winter.\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n<p class=\"full-width-image\"><img src=\"images/chicago_seasonal_variation.png\" alt=\"Chart showing that assaults, personal robberies and residential burglaries in Chicago all vary by seasonally throughout the year.\"></p>\n\nIt is also important to understand short-term variation in crime. For example,\nboth property damage and sexual violence in Chicago peaks at weekends, while \nthere are fewer shoplifting offences on Sundays when some shops are closed or\nhave shorter opening hours.\n\n<p class=\"full-width-image\"><img src=\"images/chicago_weekly_variation.png\" alt=\"Chart showing that property damage, sexual violence and shoplifting in Chicago all vary by day of the week.\"></p>\n\nUnderstanding variation in crime over time is important because we can use the\ntemporal concentration of crime to focus efforts to respond to crime most\neffectively. For example, imagine we wanted to deploy police patrols to a \nhotspot to respond to a particular crime problem. Such patrols could be very \neffective if they were targeted at the times when crimes were most likely to \nhappen or completely useless if the officers were deployed at the wrong day or \nthe wrong time.\n\nIn this tutorial we will learn how to incorporate variation over time into our\nanalysis of where crime happens, including making animated maps like this one:\n\n<p class=\"centered-image\"><img src=\"https://github.com/mpjashby/crimemapping/raw/main/inst/tutorials/16_mapping_time/images/chicago_downtown_agg_assaults.gif\" alt=\"Animated map showing how the density of aggravated assaults in Chicago varies throughout the hours of the day.\"></p>\n\n\n\n## Handling dates in R\n\n<p class=\"full-width-image\"><img src=\"images/lubridate_cartoon.jpg\" alt=\"Cartoon showing little monsters feeding lubridate functions into a Back-to-the-Future-style car with the licence plate LUBRDAT.\"></p>\n\nAt a very basic level, computers can store data in two days: they can store \nnumbers and they can store text. This makes storing dates slightly complicated, \nbecause dates aren't completely like numbers and they aren't completely like \ntext either. Dates aren't like numbers because you can't do normal maths with \ndates (e.g. what date is the 29th of January plus one month?) and aren't like \ntext because you can do some maths with them (e.g. it is easy to calculate three \ndays from today). Dates are especially complicated because they can be written \nas text in so many different ways. For example 17 January can be represented in \nall of these ways, all of them equally valid (although some are specific to \nparticular countries):\n\n  * 17/01/2025\n  * 17.01.25\n  * 1/17/2025\n  * 2025-01-17\n  * 17 Jan 25\n  * 17 January 2025\n  * January 17th 2025\n\n\n<a href=\"https://lubridate.tidyverse.org/\" title=\"lubridate website\"><img src=\"images/lubridate.png\" class=\"right-side-image\"></a>\n\nR deals with this problem by _storing_ dates internally as if they were numbers \nand _displaying_ them (e.g. in the console or in a Quarto document) as if they \nwere text, by default in the format `2025-01-07`. Fortunately, we don't have \nto worry about how dates and times are stored internally in R because we can use \nthe [`lubridate` package](https://lubridate.tidyverse.org/) to work with them. \n`lubridate` contains functions for working with dates, including extracting \nparts of a date with functions such as `month()` and converting text \nto date values with functions like `ymd()`.\n\nBecause of the special nature of dates, if we want to work with a date variable\n(for example to create a chart of crime over time) it is important that it is\nstored as a date, not as text or as a number. Many R functions for reading data, \nincluding `read_csv()`, `read_tsv()` and `read_excel()`, will try to recognise \ncolumns of data that contain dates and times stored in common formats. These \nwill automatically be stored as date variables when the data is loaded. \n\nIf R does not recognise automatically that a value contains a date, we can\nconvert it to a date by using the date-parsing functions from `lubridate`. Which \nfunction to use depends on the order in which the components of the date (e.g. \nday, month and year) appear in the variable. For example, to convert the text \n\"Saturday 17 January 1981\" to a date format we can use the `dmy()` function \nbecause the **d**ay of the month comes first, the **m**onth next and then the \n**y**ear. Similarly, converting the text \"01/17/81\" needs the function `mdy()`. \nNote that the `lubridate` date-parsing functions are able convert both numeric \nand text-based months, and to ignore elements that aren't needed, such as \nweekday names.\n\nIf a date is stored in multiple columns in a dataset, e.g. one column for the \nyear, one column for the month and one column for the day, we can create a \nsingle date column using the `make_date()` function to combine them. Similarly, \nwe can create a date-time column using the `make_datetime()` function. For \nexample, if we have a dataset of crimes called `thefts`:\n\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nlibrary(lubridate)\n\nthefts |>  \n  mutate(\n    date = make_date(year = year, month = month_of_year, day = day_of_month)\n  ) |>  \n  select(day_of_month, month_of_year, year, date)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,840 × 4\n   day_of_month month_of_year  year date      \n          <dbl>         <dbl> <dbl> <date>    \n 1            1             9  2020 2020-09-01\n 2            1             9  2020 2020-09-01\n 3            1             9  2020 2020-09-01\n 4            1             9  2020 2020-09-01\n 5            1             9  2020 2020-09-01\n 6            1             9  2020 2020-09-01\n 7            1             9  2020 2020-09-01\n 8            1             9  2020 2020-09-01\n 9            1             9  2020 2020-09-01\n10            1             9  2020 2020-09-01\n# ℹ 1,830 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\nNote that in this dataset, the `date` variable we have just created has the type\n`<date>`.\n\nOnce we have converted dates stored as text to dates stored as dates, R \nunderstands that they are dates and we can do things like compare them. So while\nrunning `\"Sat 17 January 1981\" == \"01/17/81\"` to test if two dates are the same\nwould give the answer `FALSE` (because the two pieces of text are different),\nonce we've converted the text to date values R can tell that the two dates are\nthe same:\n\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\n# This code returns TRUE only because the two pieces of text are identical\n\"Sat 17 January 1981\" == \"Sat 17 January 1981\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\n# This code returns FALSE because the two pieces of text are different, even\n# though the dates they represent are the same\n\"Sat 17 January 1981\" == \"01/17/81\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n\n```{.r .cell-code}\n# This code returns TRUE because R knows they are dates and so compares them as\n# dates, finding that the two dates are the same\ndmy(\"Sat 17 January 1981\") == mdy(\"01/17/81\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n\n\n\n### Working with dates\n\nWhen analysing dates and times, it is often useful to be able to extract \ndate or time portions. We can do this with the `lubridate` functions `year()`, \n`month()`, `wday()` (for day of the week), `mday()` (for day of the month), \n`yday()` (for day of the year, counting from 1 January), `hour()`, `minute()` \nand `second()`, each of which extracts the relevant portion of a date or time as \na number. The `month()` and `wday()` functions are slightly different, because \nthey can also return the day or month name as text by specifying the argument \n`label = TRUE`. We can see this by extracting the different portions of the \ncurrent date and time, which we can retrieve with the `now()` function from \n`lubridate`.\n\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nmessage(\"Current year: \", year(now()))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent year: 2025\n```\n\n\n:::\n\n```{.r .cell-code}\nmessage(\"Current month (as a number): \", month(now()))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent month (as a number): 1\n```\n\n\n:::\n\n```{.r .cell-code}\nmessage(\"Current month (as text, abbreviated): \", month(now(), label = TRUE))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent month (as text, abbreviated): Jan\n```\n\n\n:::\n\n```{.r .cell-code}\nmessage(\"Current month (as text): \", month(now(), label = TRUE, abbr = FALSE))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent month (as text): January\n```\n\n\n:::\n\n```{.r .cell-code}\nmessage(\"Current day of the year (days since 1 Jan): \", yday(now()))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent day of the year (days since 1 Jan): 7\n```\n\n\n:::\n\n```{.r .cell-code}\nmessage(\"Current day of the month: \", mday(now()))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent day of the month: 7\n```\n\n\n:::\n\n```{.r .cell-code}\nmessage(\"Current day of the week (as a number): \", wday(now()))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent day of the week (as a number): 3\n```\n\n\n:::\n\n```{.r .cell-code}\nmessage(\"Current day of the week (as text): \", wday(now(), label = TRUE))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent day of the week (as text): Tue\n```\n\n\n:::\n\n```{.r .cell-code}\nmessage(\"Current hour of the day: \", hour(now()))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent hour of the day: 14\n```\n\n\n:::\n\n```{.r .cell-code}\nmessage(\"Current minute: \", minute(now()))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent minute: 10\n```\n\n\n:::\n\n```{.r .cell-code}\nmessage(\"Current second: \", second(now()))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCurrent second: 40.7392361164093\n```\n\n\n:::\n:::\n\n\n\n\n\nIt is sometimes useful to be able to add to or subtract from dates. For example,\nif you wanted to filter a dataset so that only records from the past 28 days\nwere included, you would need to work out the date 28 days ago. We can do this\nwith a group of functions from `lubridate` that store a period of time that we\ncan then add to or subtract from an existing date. These functions are \n`years()`, `months()`, `weeks()`, `days()`, `hours()`, `minutes()`, and \n`seconds()`. \n\n\n::: {.box .notewell}\n\nIn the `lubridate` package, functions that are used to _extract_ parts of a date\nare _singular_, e.g. `day()`, `month()`, `year()`. Functions that are used to\n_manipulate_ dates by adding or subtracting from them are _plural_, e.g. \n`days()`, `months()`, `years()`. So, for example, you would use the code\n`month(now())` to extract the month (as a number between 1 and 12) from the \ncurrent date but the code `now() + months(1)` to find out what the date and time\nwill be one month from now.\n\n:::\n\n\nTo subtract 28 days from today's date (which we can retrieve with the `today()` \nfunction), we would use `today() - days(28)`.\n\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nmessage(str_glue(\"Today is {today()} and 28 days ago was {today() - days(28)}\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nToday is 2025-01-07 and 28 days ago was 2024-12-10\n```\n\n\n:::\n:::\n\n\n\n\n\nAdding or subtracting periods from dates can be very useful when combined with\nthe `filter()` function from the `dplyr()` package. For example, if we had a\ndataset of crimes stored in an object called `crimes` and wanted to extract only \nthose that occurred in the most-recent seven days, we could do this:\n\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nfilter(crimes, occur_date >= today() - days(7))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 52 × 5\n   incident_key occur_date murder longitude latitude\n          <dbl> <date>     <lgl>      <dbl>    <dbl>\n 1    192545751 2025-01-04 FALSE      -73.9     40.8\n 2    193418291 2025-01-02 FALSE      -73.9     40.8\n 3    193694861 2024-12-31 FALSE      -73.9     40.9\n 4    194817576 2025-01-04 FALSE      -73.8     40.9\n 5    195013387 2025-01-02 FALSE      -73.9     40.8\n 6    196000890 2025-01-01 FALSE      -73.9     40.9\n 7    196315233 2025-01-06 FALSE      -73.9     40.8\n 8    196414298 2025-01-03 FALSE      -73.9     40.8\n 9    196525187 2025-01-04 TRUE       -73.9     40.8\n10    196582020 2025-01-02 FALSE      -73.9     40.8\n# ℹ 42 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\nIf we wanted to extract crimes that occurred between two dates, we can use the\n`between()` function from `dplyr`, which returns either `TRUE` or `FALSE` \ndepending on whether each item in the first argument is between the values given\nin the second and third arguments (inclusive).\n\n\n::: {.tutorial}\n\nFor example, complete the following code by replacing the text `____` and \n`____` with `ymd()` functions to extract only crimes occurring between \n3 and 31 December 2024 inclusive.\n\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nfilter(crimes, between(occur_date, ____, ____))\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in parse(text = input): <text>:1:37: unexpected input\n1: filter(crimes, between(occur_date, __\n                                        ^\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add the dates to the following code in YYYY-MM-DD format (because you are \n# using the function `ymd()`)\nfilter(crimes, between(occur_date, ymd(\"\"), ymd(\"\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 0 × 5\n# ℹ 5 variables: incident_key <dbl>, occur_date <date>, murder <lgl>,\n#   longitude <dbl>, latitude <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n\n:::\n\n\nWhen filtering based on dates or times, it is important to understand that R can\nstore dates in two ways: as a *date* object or as a *date-time* object (shown \nas `<dttm>` when we print a tibble). Date variables store only a date with no \ntime, while date-time variables always include a time component, even if the \ndata doesn't contain any information about time. If we store a variable that \nonly has information about the date of an event as a date-time variable, R will \nsilently add the time midnight to each date. This is important because if we \ncompare a date variable to a date-time variable, R will silently convert the \ndates to date-times with the times set to midnight. If we are trying to filter \ncrimes between two times, this might not be what we want. For example, if we \nused the code:\n\n```r\nbetween(offence_date, ymd(\"2021-01-01\"), ymd(\"2021-01-31\"))\n```\n\nto extract all the crimes that occurred in January 2021, that would work as we \nexpected only if `offence_date` was a date variable. If the `offence_date` \ncolumn instead held dates *and* times, R would filter the data *as if* we had \nspecified:\n\n```r\nbetween(offence_date, ymd_hm(\"2021-01-01 00:00\"), ymd_hm(\"2021-01-31 00:00\"))\n```\n\nwhich would exclude any crimes that occurred on 31 January (except those\noccurring at exactly midnight). To deal with this problem, we can either check\nto make sure the variables we are filtering on are date variables, convert them\nto date variables using the `as_date()` function, or assume that they might be \ndate-time variables and specify the exact time that we want as the end of our \nrange. For example, specifying:\n\n```r\nbetween(offence_date, ymd_hm(\"2021-01-01 00:00\"), ymd_hm(\"2021-01-31 23:59\"))\n```\n\nor\n\n```r\nbetween(as_date(offence_date), ymd(\"2021-01-01\"), ymd(\"2021-01-31\"))\n```\n\nwould allow us to select all the crimes occurring in January 2021.\n\n\n\n\n## Showing change over time\n\nOne common task in crime analysis is to show how crime changes over time. The\nsimplest way to do this is to produce a *time-series chart*. For example, we can\nsee how the frequency of aggravated assaults recorded by police in Chicago has \nchanged over time:\n\n<p class=\"full-width-image\"><img src=\"images/chicago_assault_trend.png\" alt=\"Chart showing that the weekly frequency of aggravated assaults in Chicago from 2010 to 2019, including seasonal increases each summer and lower frequency of assaults from 2013 to 2015.\"></p>\n\nIn this section we will learn how to construct a time-series chart like this. To \nillustrate this process, we will use an object called `assaults` that contains \nrecords of aggravated assaults in Chicago from 2010 to 2019.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"vpbaamaknb\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#vpbaamaknb table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#vpbaamaknb thead, #vpbaamaknb tbody, #vpbaamaknb tfoot, #vpbaamaknb tr, #vpbaamaknb td, #vpbaamaknb th {\n  border-style: none;\n}\n\n#vpbaamaknb p {\n  margin: 0;\n  padding: 0;\n}\n\n#vpbaamaknb .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#vpbaamaknb .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#vpbaamaknb .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#vpbaamaknb .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#vpbaamaknb .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#vpbaamaknb .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vpbaamaknb .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#vpbaamaknb .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#vpbaamaknb .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#vpbaamaknb .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#vpbaamaknb .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#vpbaamaknb .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#vpbaamaknb .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#vpbaamaknb .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#vpbaamaknb .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#vpbaamaknb .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#vpbaamaknb .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#vpbaamaknb .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#vpbaamaknb .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vpbaamaknb .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#vpbaamaknb .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#vpbaamaknb .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#vpbaamaknb .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vpbaamaknb .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#vpbaamaknb .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#vpbaamaknb .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vpbaamaknb .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vpbaamaknb .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#vpbaamaknb .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vpbaamaknb .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#vpbaamaknb .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vpbaamaknb .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#vpbaamaknb .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vpbaamaknb .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#vpbaamaknb .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vpbaamaknb .gt_left {\n  text-align: left;\n}\n\n#vpbaamaknb .gt_center {\n  text-align: center;\n}\n\n#vpbaamaknb .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#vpbaamaknb .gt_font_normal {\n  font-weight: normal;\n}\n\n#vpbaamaknb .gt_font_bold {\n  font-weight: bold;\n}\n\n#vpbaamaknb .gt_font_italic {\n  font-style: italic;\n}\n\n#vpbaamaknb .gt_super {\n  font-size: 65%;\n}\n\n#vpbaamaknb .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#vpbaamaknb .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#vpbaamaknb .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#vpbaamaknb .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#vpbaamaknb .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#vpbaamaknb .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#vpbaamaknb .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#vpbaamaknb .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#vpbaamaknb div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"date\">date</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"loc_cat\">loc_cat</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"longitude\">longitude</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"latitude\">latitude</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"district\">district</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"date\" class=\"gt_row gt_right\">2010-01-01 00:05:00</td>\n<td headers=\"loc_cat\" class=\"gt_row gt_left\">residence</td>\n<td headers=\"longitude\" class=\"gt_row gt_right\">-87.6277</td>\n<td headers=\"latitude\" class=\"gt_row gt_right\">41.7922</td>\n<td headers=\"district\" class=\"gt_row gt_right\">2</td></tr>\n    <tr><td headers=\"date\" class=\"gt_row gt_right\">2010-01-01 00:12:00</td>\n<td headers=\"loc_cat\" class=\"gt_row gt_left\">street</td>\n<td headers=\"longitude\" class=\"gt_row gt_right\">-87.6683</td>\n<td headers=\"latitude\" class=\"gt_row gt_right\">41.7513</td>\n<td headers=\"district\" class=\"gt_row gt_right\">6</td></tr>\n    <tr><td headers=\"date\" class=\"gt_row gt_right\">2010-01-01 00:30:00</td>\n<td headers=\"loc_cat\" class=\"gt_row gt_left\">hotel</td>\n<td headers=\"longitude\" class=\"gt_row gt_right\">-87.6242</td>\n<td headers=\"latitude\" class=\"gt_row gt_right\">41.8727</td>\n<td headers=\"district\" class=\"gt_row gt_right\">1</td></tr>\n    <tr><td headers=\"date\" class=\"gt_row gt_right\">2010-01-01 00:30:00</td>\n<td headers=\"loc_cat\" class=\"gt_row gt_left\">street</td>\n<td headers=\"longitude\" class=\"gt_row gt_right\">-87.6478</td>\n<td headers=\"latitude\" class=\"gt_row gt_right\">41.7536</td>\n<td headers=\"district\" class=\"gt_row gt_right\">6</td></tr>\n    <tr><td headers=\"date\" class=\"gt_row gt_right\">2010-01-01 00:54:00</td>\n<td headers=\"loc_cat\" class=\"gt_row gt_left\">street</td>\n<td headers=\"longitude\" class=\"gt_row gt_right\">-87.6446</td>\n<td headers=\"latitude\" class=\"gt_row gt_right\">41.7720</td>\n<td headers=\"district\" class=\"gt_row gt_right\">7</td></tr>\n    <tr><td headers=\"date\" class=\"gt_row gt_right\">2010-01-01 01:15:00</td>\n<td headers=\"loc_cat\" class=\"gt_row gt_left\">street</td>\n<td headers=\"longitude\" class=\"gt_row gt_right\">-87.7311</td>\n<td headers=\"latitude\" class=\"gt_row gt_right\">41.8984</td>\n<td headers=\"district\" class=\"gt_row gt_right\">11</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n\nThe first task in charting the frequency of crime is to choose a temporal *unit \nof analysis*. For example, the chart above counts the number of crimes each\n*week*. Weeks are often a good choice as units for counting crimes, since all\nweeks are the same length and because many human activities have a weekly cycle\n(e.g. people do different things at weekends than on weekdays, even though\nwhich days count as weekdays differs across cultures). \n\n\n::: {.box .notewell}\n\nMonths are much less useful than weeks as a temporal unit of analysis because \nmonths differ in length, so monthly counts of crime will look like they show\nsome variation even if the amount of crime occurring each day remains constant.\nFor example, if exactly 10 crimes occur every day throughout February and March,\nthere will be 280 or \n290 crimes in February (depending on \nwhether it is a leap year) but 310 in \nMarch. In these circumstances, it will look like the volume of crime increased \nby 11% between February\nand March, not because the rate at which crimes occurred increased but because\nMarch is 11% longer than\nFebruary.\n\nMonths are also less useful because they contain different numbers of each day \nof the week (e.g. one month might have four Fridays while the next has five) and \ncrimes are typically concentrated on particular days of the week (more on that \nlater). **Avoid using monthly counts of crime** unless you have no choice \nbecause the only data you have available is monthly counts.\n\n:::\n\n\nTo count the number of crimes occurring each week we can use the `count()`\nfunction from the `dplyr` package. But before doing that, we have to allocate\neach crime to a week so that we can then count those weeks rather than counting\ndays. To do this we use the `floor_date()` function from the `lubridate` \npackage. This function rounds dates down to the start of a specified unit of \ntime, in this case a week. By default, `floor_date()` treats Sunday as the start \nof the week and so if the specified unit of time is a week, all dates will be \nrounded down to the date of the previous Sunday.\n\n`floor_date()` works on date variables, so if we want to use it on a date-time\nvariable we should first convert it to a date variable using the `as_date()`\nfunction from `lubridate`. So to convert a date-time stored in a variable called\n`date` into the date of the first day of that week, we would use the code\n`floor_date(as_date(date), unit = \"week\")`.\n\nOne complication of counting incidents by week is that our data might not fit\nneatly into calendar weeks. For example, if we have data for a particular year\nand that year started on a Tuesday, the first weekly count will only have data\nfor five days and it will look like there were fewer crimes that week in \ncomparison to other weeks. This could be misleading, since this week only looks\nlike it has less crime because we don't have data for the whole week. The same \nproblem can happen with the last week of data, too. To deal with this, after \ncounting the crimes by week we will remove the first and last row of the data \nusing the `slice()` function from the `dplyr` package.\n\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nassault_weekly_counts <- assaults |> \n  mutate(week_date = floor_date(as_date(date), unit = \"week\")) |> \n  count(week_date, name = \"count\") |> \n  # The code `(n() - 1)` gives us the row number of the second-to-last row in \n  # the data because `n()` returns the number of rows in the data. Note the\n  # parentheses!\n  slice(2:(n() - 1))\n\nhead(assault_weekly_counts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  week_date  count\n  <date>     <int>\n1 2010-01-03   234\n2 2010-01-10   300\n3 2010-01-17   303\n4 2010-01-24   257\n5 2010-01-31   276\n6 2010-02-07   264\n```\n\n\n:::\n:::\n\n\n\n\n\nNow we have weekly counts of aggravated assaults, we can plot them on a chart.\nThe simplest way to do this would be to create a line chart using `ggplot()`\nwith `geom_line()`.\n\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nggplot(assault_weekly_counts, aes(x = week_date, y = count)) +\n  geom_line() +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/change-exercise2-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThis plot is fine, but there are several things that we can do to make it \nbetter. Most importantly, there seems to be lots of short-term fluctuation in \nthe frequency of crime (e.g. from one week to another). While this variation is \nreal, we often refer to it as *noise* because it can obscure the *signal* of\nlonger-term trends (this terminology originally came to statistics -- and \ntherefore crime analysis -- from radio engineering and has become common over \ntime).\n\nWe can reduce the visual impact of this short-term variation on our plot by\nadding a line showing a *moving average* (also called a *rolling average* or\n*rolling mean*) of the count of crime over time. A moving average is the average\n(or mean) of the count of crimes in the current week and a given number of \nadjacent (in this case, previous), weeks.\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n<p class=\"full-width-image\"><img src=\"images/moving_averages.png\" alt=\"Chart showing that moving averages are calculated by averaging the current week's count with the counts from a given number of previous weeks.\"></p>\n\nSince moving averages show the average count of crime over several weeks, they \nare less influenced by week-to-week variation. To calculate a moving average we \nhave to choose how many weeks to include (known as the *window* of the moving\naverage). The more weeks we include in the window, the smoother the values will \nappear from week to week and the more short-term variation will be obscured. \nThere is a balance to be struck between making longer-term trends clear and \nobscuring genuine short-term variation, so you should experiment with different \nwindow lengths to ensure you are not over-smoothing.\n\nWe can calculate moving averages in R with the `slide_dbl()` function from the \n[`slider` package](https://davisvaughan.github.io/slider/) (so called because \nits functions slide along a series of values). `slide_dbl()` can calculate \nseveral types of moving averages, so we specify that it should use the `mean()`\nfunction to calculate the average by specifying `.f = mean` (note the lack of\nparentheses after `mean`). We use the `.before` argument (note the `.`) to \nspecify how many weeks *before the current week* to include in our moving \naverage. So if we wanted to calculate a four-week moving average (i.e. the \ncurrent week and the previous three weeks), we would specify `.before = 3`. \nWe also specify `.complete = TRUE` to stop `slide_dbl()` from trying to \ncalculate averages for the first few weeks in our data, because we don't have \nthe necessary data from previous weeks (i.e. before the start of our data) that \nwe would need to make these averages accurate. `slide_dbl()` will use `NA` as \nthe moving average value for those weeks, so we later need to specify \n`na.rm = TRUE` to tell `ggplot()` to ignore these when we plot the data.\n\nOnce we've calculated a moving average, we can show this using the line on our\nchart and show the individual weekly counts as small light-grey dots to show how \nmuch short-term variation there is in the data.\n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='27'}\n\n```{.r .cell-code}\nlibrary(slider)\n\nassault_weekly_counts |> \n  mutate(moving_avg = slide_dbl(count, mean, .before = 3, .complete = TRUE)) |> \n  ggplot() +\n  geom_point(aes(x = week_date, y = count), colour = \"grey75\", size = 0.75) +\n  geom_line(\n    aes(x = week_date, y = moving_avg, colour = \"black\"), \n    na.rm = TRUE, \n    key_glyph = \"timeseries\"\n  ) +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%b\\n%Y\") +\n  scale_y_continuous(limits = c(0, NA)) +\n  scale_colour_identity(\n    labels = c(\"black\" = \"four-week moving average\"),\n    guide = guide_legend()\n  ) +\n  labs(\n    x = NULL,\n    y = \"weekly count of aggravated assaults\",\n    colour = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    panel.grid.minor.x = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/change-exercise3-1.png){width=672}\n:::\n:::\n\n\n\n\n\nExperiment with the effect of setting a longer or shorter window for the moving\naverage by specifying larger or smaller values of the `.before` argument to\n`slide_dbl()`. For example, create an eight-week moving average by specifying\n`.before = 7`. What happens to the apparent seasonal variation in the number of\nassaults if you create an *annual moving average* by specifying `.before = 52`?\n\nYou may have noticed that in this code we have also made some changes to the\nappearance of the plot to make it easier to read. Specifically, we have:\n\n  * Added a title for the *y* axis and removed the *x* axis and legend titles\n    using the `labs()` function.\n  * Changed the labels on the *x* axis using `scale_x_date()`. In this case, we\n    have used the argument `date_breaks = \"1 year\"` to specify that we want a\n    label at the start of each year and the argument `date_labels = \"%b\\n%Y\"` to\n    specify that we want each label to consist of an abbreviated month name \n    (using the code `%b`), a new line (the code `\\n` as in a previous tutorial) \n    and a four-digit year (using the code `%Y`). You can find a full list of \n    codes used that can be used to specify different parts of a date and time by \n    typing `?strptime` in the R console.\n  * Removed some of the vertical grid lines by setting the `panel.grid.minor.x` \n    argument to `theme()` to equal `element_blank()`.\n  * Forced the *y* axis to begin at zero by specifying `limits = c(0, NA)`,\n    remembering that `NA` in this context means to use the default value.\n  * Specified that we want the black line to be represented in the legend by a\n    line that looks like a time series by specifying `key_glyph = \"timeseries\"`.\n    \nWe have also added a legend to explain what the black line shows. The code\nneed to do this is slightly awkward, since `ggplot()` would not normally produce\na legend for aesthetics (in this case, the colour of the line) that have only \none value. To force `ggplot()` to add a legend, we:\n\n  1. Specify the colour of the line (i.e. `colour = \"black\"`) not as an argument \n     to the function `geom_line()` as we normally would but as one of the \n     aesthetics specified using `aes()`. \n  2. Specify that `ggplot()` should treat the value `colour = \"black\"` as a \n     literal colour name rather than as a reference to a column in the data\n     (which is how the arguments to `aes()` are normally interpreted). To do \n     this we add `scale_colour_identity()` to the `ggplot()` stack, because \n     *identity* is the jargon used in R to say 'keep this value exactly as it \n     is'. \n  3. Within `scale_colour_identity()`, specify a label to correspond to \n     the black line by setting the `labels` argument. \n  4. Specify `guide = guide_legend()` to tell `ggplot()` to add a legend\n     corresponding to the black line because aesthetics styled using functions\n     in the `scale_*_identity()` family do not produce a legend entry by \n     default.\n\nDoing all this is obviously tedious, but makes for a better chart.\n\n\n### Showing repeating patterns over time\n\nWe have already seen that there is seasonal variation in the number of \naggravated assaults in Chicago. As is very common for assaults, there are more\noffences in the summer and fewer in the winter. We can see this in the \ntime-series chart we have already produced, but it's hard to see the detail. For\nexample, we might want to know how consistent this seasonal variation is across\ndifferent years. Is it, for example, consistent enough that the local police\nmight want to restrict the number of officers who can take holidays in certain\nweeks of the year to maximise the number of officers available when crime is\nlikely to be highest?\n\nTo do this we can create a *seasonal chart*. This can be used to show any type\nof repeating variation, but is often used to show patterns across a year (hence\nthe name). To create a seasonal plot we need to add a variable to our data \nspecifying which year each weekly count belongs to, which we can do by using the\n`year()` function to extract the year from the offence dates. We can do this at \nthe same time as we calculate the moving averages. Once we've done that, we can \nspecify that we want our chart to have a separate line for each year by setting\n`group = year` inside the `aes()` function that controls how the data are shown\non the chart, making each year a different colour using `colour = year`.\n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='20'}\n\n```{.r .cell-code}\nassault_weekly_counts |> \n  mutate(\n    moving_avg = slide_dbl(count, mean, .before = 3, .complete = TRUE),\n    year = year(week_date)\n  ) |> \n  ggplot(aes(x = week_date, y = moving_avg, colour = year, group = year)) +\n  geom_line(na.rm = TRUE, key_glyph = \"timeseries\") +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%b\\n%Y\") +\n  scale_y_continuous(limits = c(0, NA)) +\n  scale_colour_continuous(breaks = c(2010, 2019)) +\n  labs(\n    x = NULL,\n    y = \"weekly count of aggravated assaults\",\n    colour = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor.x = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/change-exercise4-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThe result might not be what you expected. Although the grouping of the lines by\nyear has worked (there is a break between the lines at the start of each year),\nit's no easier to compare the seasonal patterns across years. Comparing years \nwould be much easier if we superimpose the weekly counts for each year on top of \none another.\n\nTo do this, we need to trick `ggplot()` into plotting all the weekly counts as\nif they occurred in a single year, so the counts appear in the same locations on\nthe horizontal axis of the chart, whichever year they occurred in. We can do \nthis by creating a pseudo-date value for each weekly count which has the same\nmonth and day of the month as the original date, but a single year across all \nthe rows in the data. We will create this pseudo date by extracting the month\nand day of the month using `month()` and `mday()`, then creating a new date with\n`make_date()`. We will also change the labels on the horizontal axis using the \ndate-formatting code `%e\\n%b` -- `%e` means the day of the month and `%b` means \nthe abbreviated name of the month.\n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='24'}\n\n```{.r .cell-code}\nassault_weekly_counts |> \n  mutate(\n    moving_avg = slide_dbl(count, mean, .before = 3, .complete = TRUE),\n    year = year(week_date),\n    # By only specifying the `month` and `day` arguments to `make_date()` we\n    # will create a date in 1970 (the year that R uses by default), but that \n    # doesn't matter because we are not going to show the year on the chart\n    pseudo_date = make_date(month = month(week_date), day = mday(week_date))\n  ) |> \n  ggplot(aes(x = pseudo_date, y = moving_avg, colour = year, group = year)) +\n  geom_line(na.rm = TRUE, key_glyph = \"timeseries\") +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%e\\n%b\") +\n  scale_y_continuous(limits = c(0, NA)) +\n  scale_colour_continuous(breaks = c(2010, 2019)) +\n  labs(\n    x = NULL,\n    y = \"weekly count of aggravated assaults\",\n    colour = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor.x = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/change-exercise5-1.png){width=672}\n:::\n:::\n\n\n\n\n\nFrom this chart we can see that assaults consistently peak in July, although in\none year they peaked slightly earlier in late June and in one year slightly \nlater in August. At the other end of the year, weekly counts of assaults are \nalmost always least frequent in late January and throughout February before\nstarting to increase quite rapidly in March.\n\nAs well as showing seasonal variation, we can use the same technique to \nunderstand variation over other periods of time. For example, since we know a\nlot of human activities follow weekly patterns, we might want to produce a chart\nshowing the number of crimes in each hour on each day of the week.\n\nTo do this, we:\n\n  1. Extract the weekday and hour components of each date using `wday()` and\n     `hour()`.\n  2. Count the total number of crimes occurring in each hour of each day *across \n     all ten years of the data* using `count()`.\n  3. Create a pseudo-date-time using `make_datetime()`.\n  4. Create a chart with appropriate labels on the horizontal axis and a \n     suitable qualitative colour scheme to show the days of the week using \n     `scale_colour_brewer()`.\n\nWe can do this in a single piece of code.     \n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='23'}\n\n```{.r .cell-code}\nassault_hourly_counts <- assaults |> \n  mutate(wday = wday(date, label = TRUE), hour = hour(date)) |> \n  count(wday, hour, name = \"count\") |> \n  # By only setting the `hour` argument to `make_datetime()` we will create a\n  # date-time on 1 January 1970, but that doesn't matter because we will not \n  # show the date on the chart\n  mutate(pseudo_date = make_datetime(hour = hour))\n\nggplot(\n  assault_hourly_counts, \n  aes(x = pseudo_date, y = count, colour = wday, group = wday)\n) +\n  geom_line(key_glyph = \"timeseries\") +\n  scale_x_datetime(date_breaks = \"2 hours\", date_labels = \"%H:%M\") +\n  scale_y_continuous(limits = c(0, NA), labels = scales::comma_format()) +\n  scale_colour_brewer(type = \"qual\") +\n  labs(\n    x = NULL,\n    y = \"hourly total of aggravated assaults, 2010-2019\",\n    colour = NULL\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/change-exercise6-1.png){width=672}\n:::\n:::\n\n\n\n\n\nOn this chart you can see that there are two distinct temporal patterns of\nassaults on different days of the week. Between Mondays and Thursdays, assaults\npeak between about 14:00 and 21:00 before reducing to a very-low level at about\n05:00. At the weekend, the picture is different: assaults peak between midnight\nand 02:00 on both Saturdays and Sundays (i.e. very late on Friday and Saturday\nevenings).\n\nThis chart probably uses the maximum number of different colours for days of the\nweek that we could use before some of the colours became too similar to one\nanother to be distinguishable. But even with this many colours, it might not be\neasy for a colour-blind person to translate between the colours of the lines and\nthe colours in the legend. When you find that there are too many colours on a \nchart, this is a good sign that you should consider using small-multiple charts\ninstead. Fortunately, we can do this by adding a column to the data specifying\nwhether each day is a weekday or on a weekend, then adding `facet_grid()` to our\n`ggplot()` stack. \n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='19'}\n\n```{.r .cell-code}\nassault_hourly_counts |> \n  mutate(weekend = if_else(wday %in% c(\"Sat\", \"Sun\"), \"Sat–Sun\", \"Mon–Fri\")) |> \n  ggplot(aes(x = pseudo_date, y = count, colour = wday)) +\n  geom_line(linewidth = 1) +\n  # Assign the facets to rows so that we can compare the same time on different\n  # days more easily (change `rows` to `cols` to see the alternative)\n  facet_grid(rows = vars(weekend)) +\n  scale_x_datetime(date_breaks = \"2 hours\", date_labels = \"%H:%M\") +\n  scale_y_continuous(limits = c(0, NA), labels = scales::comma_format()) +\n  scale_fill_brewer(type = \"qual\") +\n  labs(\n    x = NULL,\n    y = \"hourly total of aggravated assaults, 2010-2019\",\n    fill = NULL\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/change-exercise7-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThis shows the two distinct patterns (weekdays and weekends) more clearly, while\nalso letting us see that Friday is not like other weekdays since the peak in\nassaults continues later in the evening. Now that we've created this chart using\n`facet_grid()`, we could also add columns to show the same patterns in \ndifferent areas, such as police districts or local neighbourhoods, or during\ndifferent seasons.\n\n\n\n## How to map change over time\n\nTime-series or seasonal charts are often the best way to show change in the \nfrequency of crime over time. But it can also be useful to show maps of the\npatterns of crimes at different points in time. We might, for example, want to \nshow the density of crime in an area for different periods in time.\n\nChoosing how to divide up time into periods is an important step in this \nprocess, because in doing so we are converting a continuous variable (time) into\na number of categories (periods of time). Whenever we convert an continuous\nvariable to a categorical one we inevitably lose information. For example, if we\ndecided to categorise the maximum temperature every day as being either 'hot' or \n'cold', we would lose a lot of information about whether a particular day was\nmoderately hot, very hot, etc. The same is true of time, since by splitting time\ninto periods (hours, days, weeks, etc.) we lose information about variations\nwithin each period. This is inevitable, since we can't produce infinite maps \nshowing all the infinite moments in time, but it's the reason why choosing \nperiods carefully is important.\n\nWhen choosing a period over which to count crime, it is important not to just \nuse default periods like the day from 00:00 to 23:59 just because that is the\nstandard definition of a day. As we saw in the previous section, the peaks of\nmany types of crime like assaults cross over the boundaries between days because\nthe peak frequency is late in the evening. For this reason it may be better to, \nfor example, define a day as a period from 05:00 to 04:59 and count the number \nof crimes within each day according to that definition. This takes advantage of\nthe fact that very few crimes concentrate in the early hours of the morning.\n\nSometimes, it will be easy to choose periods because they will be dictated by\nthe purpose for which you're creating the map. In this section we will create\nseparate maps showing the density of aggravated assaults in a part of Chicago \nfor each of the standard Chicago Police shifts of 06:00 to 13:59, 14:00 to 21:59 \nand 22:00 to 05:59 (bearing in mind that the actual hours some officers work may \ndiffer slightly).\n\nTo do this, we will estimate the density of assaults separately for each shift\nperiod, the combine the three density layers and plot them on small-multiple\nmaps. First, we create a new object containing data for the Chicago Police\ndistricts we are interested in with a column showing which police shift each\nassault occurred in. \n\nWe can construct this column using the `case_when()` function from `dplyr`.\n`case_when()` allows us to specify any number of tests that we can apply to our\ndata -- when a test is passed the function assigns the corresponding label to\nthat row (the label is separated from the test by a tilde character `~`).\n`case_when()` is like `recode()`, but for when we need to test for\nmore-complicated things than just whether a variable has a particular value. \n\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nassaults_by_shift <- assaults |> \n  filter(district %in% c(1, 12, 18)) |> \n  mutate(\n    shift = case_when(\n      between(hour(date), 6, 13) ~ \"06:00 to 13:59\",\n      between(hour(date), 14, 21) ~ \"14:00 to 21:59\",\n      hour(date) >= 22 | hour(date) < 6 ~ \"22:00 to 05:59\",\n      TRUE ~ NA_character_\n    )\n  )|> \n  # Convert the data to an SF object\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = \"EPSG:4326\") |> \n  # Transform it to a co-ordinate reference system based on metres\n  st_transform(\"EPSG:26916\")\n\nhead(assaults_by_shift)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 444951.9 ymin: 4635831 xmax: 449271.4 ymax: 4641406\nProjected CRS: NAD83 / UTM zone 16N\n# A tibble: 6 × 5\n  date                loc_cat    district shift                  geometry\n  <dttm>              <chr>         <dbl> <chr>               <POINT [m]>\n1 2010-01-01 00:30:00 hotel             1 22:00 to 05… (448202.2 4635831)\n2 2010-01-01 01:45:00 street           18 22:00 to 05…   (446518 4641406)\n3 2010-01-01 01:48:00 hotel             1 22:00 to 05… (448202.2 4635831)\n4 2010-01-01 02:00:00 government       18 22:00 to 05… (449271.4 4637966)\n5 2010-01-01 02:59:00 leisure          12 22:00 to 05… (444951.9 4637265)\n6 2010-01-01 05:00:00 residence        18 22:00 to 05… (447278.5 4639968)\n```\n\n\n:::\n:::\n\n\n\n\n\n\n<div class=\"box extra-detail\">\n\n<h5 id=\"map-box1-title\" class=\"box-title\">Why did we include `TRUE ~ NA_character_` in `case_when()`?</h5>\n\n<div id=\"map-box1\" class=\"box-content\">\n\n`case_when()` uses a series of true/false tests to create a variable, usually\nbased on the values of other columns in the data. To make sure that every row\nin the dataset is matched by at least one of the tests, it is common practice to\ninclude a final test that is always true. The easiest way to do this is to \nsimply create a test with the fixed value `TRUE`, since `TRUE` is always true!\nThis catch-all test must be the last test within the `case_when()` function,\nbecause `case_when()` runs the tests in the order in which they are given and\nstops testing a given row in the data as soon as a test produces a true value.\n\nIn this case, we will set the label for this last test to be `NA` (in fact, the\nspecial value `NA_character_` because `case_when()` only accepts labels that are \ncharacters) to catch any rows that have missing values of `date` or aren't \nmatched by any of our tests. Since our tests between them cover all the hours of\nthe day, there shouldn't be any rows that are not matched by at-least one test,\nbut including a catch-all test makes it easier to catch any problems with our \ncode.\n\nThere's lot's more to learn about the `case_when()` function: you can find out\nmore by looking at the [`case_when()` page on the package website](https://dplyr.tidyverse.org/reference/case_when.html).\n\n\n</div>\n\n</div>\n\n<script>\n$(\"#map-box1-title\").click(function () { $(\"#map-box1\").toggle(\"slow\") })\n</script>\n\n\nThe next step is to produce a kernel density (KDE) layer for assaults occurring\nin each shift. In a previous tutorial we learned how to do this using the \n`sfhotspot` package. We could run the `hotspot_kde()` function from that package \nthree times to create the KDE layers for each shift, but there is a simpler way\nto apply the same function to different parts of a dataset using the \n`group_modify()` function from `dplyr`.\n\nNormally, when we use a function to modify a dataset, that function is applied\nto the dataset as a whole. With `group_modify()`, we can apply a function to\ndifferent parts of a dataset separately but still get the result as a single\ntibble with a column showing which group each row relates to (which is what we \nneed to produce a map).\n\n`group_modify()` needs two inputs. The first is a _grouped_ dataset. We already\nknow how to specify which column in a dataset represents which group each row is\nin using the `group_by()` function. The second input to `group_modify()` is the\nname of the function we want to use to modify each group in the data. The only\ncomplication is that we have to provide the details of the function that \n`group_modify()` should use in a slightly unusual format called an _anonymous\nfunction_. You can see this in the block of code below. You do not need to \nunderstand the details of how an anonymous function works, but you should note\ntwo things:\n\n  1. Anonymous functions start with the `~` character.\n  2. In an anonymous function used within `group_modify()`, you can use the\n     special value `.x` (note the dot) to represent the data in each group.\n     \nSo this code:\n\n```r\nsome_data |> \n  group_by(some_variable) |> \n  group_modify(~ hotspot_kde(.x))\n```\n\nMeans 'take the dataset `some_data`, group it according to the values in the\n`some_variable` column and apply the `hotspot_kde()` function separately to each\ngroup'. The only thing left for us to do then is to use `ungroup()` to remove \nthe grouping from the result produced by `group_modify()` and convert that\nresult back to an SF object using `st_as_sf()`. Don't worry about specifying any\narguments to `st_as_sf()` – R will extract information such as the co-ordinate\nreference system from the `geometry` column of the data automatically.\n\n\n\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nlibrary(sfhotspot)\n\nkde_by_shift <- assaults_by_shift |> \n  group_by(shift) |> \n  group_modify(\n    ~ hotspot_kde(.x, cell_size = 200, bandwidth_adjust = 0.75, quiet = TRUE)\n  ) |> \n  ungroup() |> \n  st_as_sf() |> \n  # Clip the result to the boundary of Chicago, which is already stored in the \n  # `cpd_central` object\n  st_intersection(cpd_central)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(kde_by_shift)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 446980 ymin: 4637342 xmax: 447685.6 ymax: 4637558\nProjected CRS: NAD83 / UTM zone 16N\n# A tibble: 6 × 5\n  shift              n   kde district_no                                geometry\n  <chr>          <dbl> <dbl>       <dbl>                           <POLYGON [m]>\n1 06:00 to 13:59     0  161.          18 ((447085.6 4637358, 447085.6 4637355, …\n2 06:00 to 13:59     4  204.          18 ((447085.6 4637358, 447112.6 4637358, …\n3 06:00 to 13:59     0  147.          18 ((447085.6 4637558, 447085.6 4637358, …\n4 06:00 to 13:59     0  186.          18 ((447085.6 4637558, 447285.6 4637558, …\n5 06:00 to 13:59     2  225.          18 ((447285.6 4637558, 447485.6 4637558, …\n6 06:00 to 13:59     4  257.          18 ((447485.6 4637558, 447685.6 4637558, …\n```\n\n\n:::\n:::\n\n\n\n\n\n\n<div class=\"box extra-detail\">\n\n<h5 id=\"map-box2-title\" class=\"box-title\">How to anonymous functions work?</h5>\n\n<div id=\"map-box2\" class=\"box-content\">\n\nAnonymous functions in R (and in many other programming languages) are a compact\nway of creating a new function that we can then immediately use to modify a\ndataset.\n\nWe can create our own functions in R by using the `function()` function. For\nexample, if we wanted to create our own version of the `head()` function that\nprinted the first 10 rows of a dataset – rather than the default six rows \nprinted by `head()` – we could create a function called `head10()`:\n\n```r\nhead10 <- function(x) {\n  head(x, n = 10)\n}\n```\n\nWhen we call the new `head10()` function on a dataset, R will take whatever data\nwe provide to that function and run all the code inside the braces `{}` above\nusing that data. We can use this new function anywhere in our code _after_ we've \ncreated it. For example, if we had a dataset called `some_data` we could view \nthe first 10 rows of it by creating an then using our new function:\n\n```r\nhead10 <- function(x) {\n  head(x, n = 10)\n}\n\nhead10(some_data)\n```\n\nNote that _inside_ our new function, the dataset is referred to by the name that\nwe gave it in the parentheses `()` after the word `function`, _not_ by the name\nof the dataset itself. This is important because it means our custom function \nwill work regardless of what a particular dataset is called.\n\nWe could include lots of lines of code inside our new function, but in this case \nthere is just one – `head(x, n = 10)`. When we want to create a function that\nconsists of a single line of code, we can dispense with the braces and put the \nwhole function on one line:\n\n```r\nhead10 <- function(x) head(x, n = 10)\n\nhead10(some_data)\n```\n\nCreating a new function and giving it a name is useful if we want to use the\nfunction several times in our code. But in the case of the function we need to\nprovide to `group_modify()` in our code, we only need to use the new function\nonce. In this case, we can dispense with the need to give our new function a \nname, and instead create an anonymous function. To do this, we replace \n`function(x)` with the `~` character.\n\nThis makes the definition of our custom function even faster, but means we can\nonly use it inside a function such as `group_modify()` or `map()` that needs a\nfunction definition to work. Using an anonymous function also means we need some \nway of referring to our dataset inside the new function, since we don't have the\nopportunity to define it inside parentheses after the word `function`. \nFortunately, `group_modify()` understands that if we refer to `.x` (note the \ndot) inside our anonymous function, that should be interpreted as referring to\nour dataset.\n\nThere is a lot more you could learn about creating your own functions in R. If\nyou are interested, you might want to [work through this lesson on Creating Functions](https://swcarpentry.github.io/r-novice-inflammation/02-func-R/).\n\n</div>\n\n</div>\n\n<script>\n$(\"#map-box2-title\").click(function () { $(\"#map-box2\").toggle(\"slow\") })\n</script>\n\nNow we have a KDE layer for each shift, we can create three maps for the three \nshifts by adding `facet_wrap()` to a `ggplot()` stack.\n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='30'}\n\n```{.r .cell-code}\nlibrary(ggspatial)\n\nggplot() +\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  geom_sf(\n    aes(fill = kde), \n    data = kde_by_shift, \n    alpha = 0.75, \n    colour = NA\n  ) +\n  geom_sf(\n    data = filter(cpd_districts, district_no %in% c(1, 12, 18)), \n    colour = \"grey33\", \n    fill = NA\n  ) +\n  facet_wrap(vars(shift)) +\n  scale_fill_distiller(\n    breaks = range(pull(kde_by_shift, kde)),\n    labels = c(\"lower\", \"higher\"),\n    direction = 1\n  ) +\n  labs(\n    fill = \"density of aggravated assaults\"\n  ) +\n  theme_void() +\n  theme(\n    legend.position = \"bottom\",\n    legend.title.align = 1\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `legend.title.align` argument of `theme()` is deprecated as of ggplot2\n3.5.0.\nℹ Please use theme(legend.title = element_text(hjust)) instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/map-exercise3-1.png){width=672}\n:::\n:::\n\n\n\n\n\nOn this map we can see that some places have a relatively high density of \nassaults throughout all three shifts, but others only have a high density at\ncertain times. We can perhaps make this clearer by only showing the grid cells\nwith the highest estimated density of assaults during each shift. We can do this\nusing the `slice_max()` function from `dplyr`, which allows us to extract the\nrows in a dataset with the highest values of a particular variable. In this case\nwe will use `slice_max()` together with `group_by()` to get the rows with the\nhighest values _separately for each shift_ rather than those with the highest \nvalues across all three shifts combined.\n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='21'}\n\n```{.r .cell-code}\nkde_shift_highest <- kde_by_shift |> \n  group_by(shift) |> \n  slice_max(order_by = kde, n = 10)\n\nggplot() +\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  geom_sf(\n    aes(fill = kde), \n    data = kde_shift_highest, \n    alpha = 0.75, \n    colour = NA,\n    fill = \"red2\"\n  ) +\n  geom_sf(\n    data = filter(cpd_districts, district_no %in% c(1, 12, 18)), \n    colour = \"grey33\", \n    fill = NA\n  ) +\n  facet_wrap(vars(shift)) +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/map-exercise4-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThis map makes it very clear that the grid cells with the highest densities of\naggravated assaults are very similar in the daytime and evening shifts, in both\nplaces being concentrated in the downtown area known as The Loop. For the \novernight shift, however, the cells with the highest densities are on the other\nside of the Chicago River in the River North neighbourhood. A map like this \nmight be particularly useful if the resources available to respond to a crime \nproblem were very limited and so could only be deployed in the places where the\nproblem was worst -- this is often the case because crime-prevention resources\n*are* often very limited.\n\n\n## Making animated maps\n\nThe small-multiple map we have produced of aggravated-assault hotspots in\nChicago is useful, especially for policing because it uses periods based on \npolice shifts. But aggregating crimes into only three temporal periods \ninevitably throws away a lot of information about when crime happens. For \nexample, at what time of night does the area of highest assault density move \nacross the river from The Loop to River North?\n\nWe could produce a series of small-multiple maps showing shorter periods \n(meaning more small multiples). For example, we could show one small-multiple\nmap for each hour of the day. However, this would make each map very small and\nit would be hard to see the details of locations on each map.\n\nOne alternative is to produce an animated map with each frame in the animation\nrepresenting the map for each hour. We can do this using the \n[`gganimate` package](https://gganimate.com/).\n\nThe first step in producing an animated map is to create a KDE layer for each\nhour of the day. The code for this is the same as for the code we have already\nused to produce the KDE layers for each shift, except that we create a variable\nfor hour of the day rather than police shift. Because an animated map of hours \nof the day needs 24 KDE layers, in this case it is particularly useful to use\n`group_modify()` to avoid having to create 24 different objects and then binding \nthem together.\n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='27'}\n\n```{.r .cell-code}\nlibrary(gganimate)\n\nassaults_by_hour <- assaults |> \n  filter(district %in% c(1, 12, 18)) |> \n  mutate(\n    # Create nicely formatted labels for each hour\n    hour_name = str_pad(hour(date), width = 2, pad = \"0\"),\n    hour_name = str_glue(\"{hour_name}:00 to {hour_name}:59\")\n  ) |> \n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = \"EPSG:4326\") |> \n  # Convert the data to a suitable co-ordinate system for Chicago\n  st_transform(\"EPSG:26916\")\n\nhour_layers <- assaults_by_hour |> \n  group_by(hour_name) |> \n  group_modify(\n    ~ hotspot_kde(.x, cell_size = 200, bandwidth_adjust = 0.75, quiet = TRUE)\n  ) |> \n  ungroup() |> \n  st_as_sf() |> \n  st_intersection(cpd_central)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n```\n\n\n:::\n\n```{.r .cell-code}\n# Extract only the 10 cells with the highest density in each hour\nhour_highest <- hour_layers |> \n  group_by(hour_name) |> \n  slice_max(order_by = kde, n = 10)\n```\n:::\n\n\n\n\n\n\n::: {.box .notewell .tutorial}\n\nIt is possible that this code will time out and give an error saying \n`Your code ran longer than the permitted timelimit for this exercise.` -- if \nthat happens then just continue with the rest of the tutorial as normal.\n\n:::\n\n\n::: {.box .notewell .book}\n\nThis code is likely to take a while to run, because it calculates KDE values\nseparately for every grid cell for each of 24 hours.\n\n:::\n\n\nWe can now use the `hour_highest` object as the basis for a new base map that\nonly includes the areas of the highest density (so they appear larger on the\nanimated map).\n\nTo create an animated map we use the `transition_states()` function from the\n`gganimate` package. `transition_states()` works in a similar way to \n`facet_wrap()`, in that when added to a `ggplot()` stack it splits the chart or \nmap up into a separate map for each value of one of the variables in the data \n(in this case, the hour of the day). The only difference is that while \n`facet_wrap()` arranges those separate maps next to one another, \n`transition_states()` arranges them into an animation.\n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='18'}\n\n```{.r .cell-code}\nggplot() +\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  geom_sf(\n    aes(fill = kde),\n    data = hour_highest, \n    alpha = 0.75, \n    colour = NA,\n    fill = \"red2\"\n  ) +\n  geom_sf(data = cpd_central, colour = \"grey33\", fill = NA) +\n  transition_states(states = hour_name) +\n  labs(\n    title = \"Aggravated assaults in downtown Chicago, 2010-2019\",\n    subtitle = \"Areas with most aggravated assaults:\\n{closest_state}\",\n    caption = \"Data from Chicago Police\"\n  ) +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/animated-exercise3-1.gif)\n:::\n:::\n\n\n\n\n\n\n<div class=\"box extra-detail tutorial\">\n\n<h5 id=\"animated-box1-title\" class=\"box-title\">I got an error starting `Your code ran longer than`</h5>\n\n<div id=\"animated-box1\" class=\"box-content\">\n\nThis code may take longer to run than is allowed for code inside an interactive \ntutorial. In which case, you may see the error \n`Your code ran longer than the permitted timelimit for this exercise`. If that \nhappens, you can\n[download the Chicago assaults data](https://mpjashby.github.io/crimemappingdata/chicago_aggravated_assaults.csv.gz) \nand create an animated map in an R script of your own using the code in the \nchunks above. For reference, this code should produce a map looking like this:\n\n<p class=\"centered-image\"><img src=\"https://github.com/mpjashby/crimemapping/raw/main/inst/tutorials/16_mapping_time/images/chicago_animated_highest.gif\" alt=\"Animated map showing how the areas of downtown Chicago with the highest density of aggravated assaults vary throughout the hours of the day.\"></p>\n\n</div>\n\n</div>\n\n<script>\n$(\"#animated-box1-title\").click(function () { $(\"#animated-box1\").toggle(\"slow\") })\n</script>\n\n\nThere is one other function of `gganimate` we have used in the code used to make\nthis map. You might have noticed that in the map `subtitle` is the code \n`{closest_state}`. This is a special code that `gganimate` will replace with the\ncurrent value of the variable in the data that is used to control which facet \nappears in each frame of the animation. So for this map, `{closest_state}` will\nbe replaced in the animation with the value of the `hour_name` variable in the \ndata for each frame in the animation.\n\nThis animated map is very sensitive to the number of grid cells we choose to \nextract (in the map above, 10 cells for each hour) -- it might look quite \ndifferent if we had chosen a different number. To show the density of crime in \nall of downtown Chicago, we can combine the base map and KDE layers we \nhave already created to produce another animated map.\n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='18'}\n\n```{.r .cell-code}\nggplot() +\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  geom_sf(aes(fill = kde), data = hour_layers, alpha = 0.75, colour = NA) +\n  geom_sf(data = cpd_central, colour = \"grey33\", fill = NA) +\n  transition_states(states = hour_name) +\n  scale_fill_distiller(\n    breaks = range(pull(hour_layers, kde)),\n    labels = c(\"lower\", \"higher\"),\n    direction = 1\n  ) +\n  labs(\n    title = \"Aggravated assaults in downtown Chicago, 2010-2019\",\n    subtitle = \"Density of aggravated assaults: {closest_state}\",\n    caption = \"Data from Chicago Police\",\n    fill = \"density of\\naggravated\\nassaults\"\n  ) +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/animated-exercise4-1.gif)\n:::\n:::\n\n\n\n\n\n\n::: {.tutorial}\n\nThis code typically takes a minute or so to finish running because it has to\ngenerate 24 maps and then stitch them together. It is unlikely that the code\nwill finish running before the maximum time that a chunk of code in an R \ntutorial is allowed to run for before automatically stopping. If you were to\nrun this code in RStudio, the map it would produce would look like this:\n\n<p class=\"centered-image\"><img src=\"https://github.com/mpjashby/crimemapping/raw/main/inst/tutorials/16_mapping_time/images/chicago_downtown_agg_assaults.gif\" alt=\"Animated map showing how the density of aggravated assaults in Chicago varies throughout the hours of the day.\"></p>\n\n:::\n\n\nWe can save an animated map to a file using the `animate()` and `anim_save()` \nfunctions. `animate()` controls the type of file the animation will be saved in\n(by default, an animated GIF), the height and width of the plot and so on.\n`anim_save()` then saves the animation in a file. For example, if we stored the \nmap created above in an object called `chicago_downtown_kde_map`, we could save \nit to an animated GIF file.\n\n```r\nanim_save(\n  filename = \"chicago_downtown_agg_assaults.gif\", \n  animation = animate(\n    plot = chicago_downtown_kde_map,\n    height = 800, \n    width = 800, \n    units = \"px\"\n  )\n)\n```\n\n\n\n## In summary\n\n::: {.box .welldone}\n\nIn this tutorial we have learned how to incorporate change over time into our \nanalysis of where crime happens. This is important because the distribution of\ncrime across different places often varies at different times. Being aware of\nthe importance of time when we make maps means we can do things like create\nsmall-multiple or animated maps for different time periods, which we could use\nto make sure that scarce crime-prevention resources are used at the right time\nas well as in the right place.\n\n:::\n\n\nThis is the complete code we need to create an animated map of aggravated \nassaults in Chicago. Think about how you could change it, or what extra\ninformation you could add, to make this map as useful as possible to different\ngroups of practitioners and policy makers.\n\n\n\n\n\n::: {.cell exercise='true' exercise.lines='72'}\n\n```{.r .cell-code}\n# Load packages\nlibrary(gganimate)\nlibrary(ggspatial)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(sfhotspot)\nlibrary(tidyverse)\n\n\n# Load data --------------------------------------------------------------------\n\n# Aggravated assaults, Chicago, 2010 to 2019\nassaults <- read_csv(\"https://mpjashby.github.io/crimemappingdata/chicago_aggravated_assaults.csv.gz\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 148636 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): loc_cat\ndbl  (3): longitude, latitude, district\ndttm (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Chicago Police districts 1, 12 and 18\ncpd_central <- read_sf(\"https://mpjashby.github.io/crimemappingdata/chicago_police_districts.kml\") |> \n  st_transform(\"EPSG:26916\") |> \n  mutate(district_no = as.numeric(Name)) |> \n  filter(district_no %in% c(1, 12, 18))\n\n\n# Wrangle data -----------------------------------------------------------------\n\n# Calculate number of assaults each hour\nhour_layers <- assaults |> \n  filter(district %in% c(1, 12, 18)) |> \n  mutate(\n    hour_name = str_pad(hour(date), width = 2, pad = \"0\"),\n    hour_name = str_glue(\"{hour_name}:00 to {hour_name}:59\")\n  ) |> \n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = \"EPSG:4326\") |> \n  st_transform(\"EPSG:26916\") |> \n  group_by(hour_name) |> \n  group_modify(\n    ~ hotspot_kde(.x, cell_size = 200, bandwidth_adjust = 0.75, quiet = TRUE)\n  ) |> \n  ungroup() |> \n  st_as_sf() |> \n  st_intersection(cpd_central)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n```\n\n\n:::\n\n```{.r .cell-code}\n# Create map ---------------------------------------------------------------------\nchicago_downtown_kde_map <- ggplot() +\n  annotation_map_tile(type = \"cartolight\", zoomin = 0, progress = \"none\") +\n  geom_sf(aes(fill = kde), data = hour_layers, alpha = 0.75, colour = NA) +\n  geom_sf(data = cpd_central, colour = \"grey33\", fill = NA) +\n  transition_states(states = hour_name) +\n  scale_fill_distiller(\n    breaks = range(pull(hour_layers, kde)),\n    labels = c(\"lower\", \"higher\"),\n    direction = 1\n  ) +\n  labs(\n    title = \"Aggravated assaults in downtown Chicago, 2010-2019\",\n    subtitle = \"Density of aggravated assaults: {closest_state}\",\n    caption = \"Data from Chicago Police\",\n    fill = \"density of\\naggravated\\nassaults\"\n  ) +\n  theme_void()\n\n\n# Save map ---------------------------------------------------------------------\nanim_save(\n  filename = \"chicago_downtown_agg_assaults.gif\", \n  animation = animate(\n    plot = chicago_downtown_kde_map,\n    height = 800, \n    width = 800, \n    units = \"px\"\n  )\n)\n```\n:::\n\n\n\n\n\n\n::: {.reading}\n\nYou can learn more about:\n\n  * using the different functions in the `lubridate` package to \n    [Do more with dates and times in R](https://lubridate.tidyverse.org/articles/lubridate.html) and\n  * animating different types of map and chart in different ways in\n    [Getting Started with `gganimate`](https://gganimate.com/articles/gganimate.html).\n\n:::\n\n\n<p class=\"credits\"><a href=\"https://twitter.com/allison_horst\">Artwork by @allison_horst</a></p>\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}